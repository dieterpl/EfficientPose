WARNING:tensorflow:From train.py:204: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:206: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2021-04-01 02:05:32.448832: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-04-01 02:05:32.453828: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2021-04-01 02:05:32.454203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd5da4dc20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-04-01 02:05:32.454291: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-04-01 02:05:32.454904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-04-01 02:05:32.695917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.696953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253
pciBusID: 0000:01:00.0
2021-04-01 02:05:32.697581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-04-01 02:05:32.700718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-04-01 02:05:32.703385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-04-01 02:05:32.704101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-04-01 02:05:32.706648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-04-01 02:05:32.708614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-04-01 02:05:32.713210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-01 02:05:32.713462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.714004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.714382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-04-01 02:05:32.714489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-04-01 02:05:32.748594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-01 02:05:32.748734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-04-01 02:05:32.748783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-04-01 02:05:32.748920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.749175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.749429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:32.749651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3681 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)
2021-04-01 02:05:32.751135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd5e3d2680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-04-01 02:05:32.751194: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 970, Compute Capability 5.2
WARNING:tensorflow:From /home/paul/miniconda3/envs/pose/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
WARNING:tensorflow:From /home/paul/miniconda3/envs/pose/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2021-04-01 02:05:43.322255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.322608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253
pciBusID: 0000:01:00.0
2021-04-01 02:05:43.322670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-04-01 02:05:43.322695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-04-01 02:05:43.322705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-04-01 02:05:43.322715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-04-01 02:05:43.322724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-04-01 02:05:43.322734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-04-01 02:05:43.322743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-01 02:05:43.322783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.323017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.323226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-04-01 02:05:43.323524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.323746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253
pciBusID: 0000:01:00.0
2021-04-01 02:05:43.323764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-04-01 02:05:43.323790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-04-01 02:05:43.323819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-04-01 02:05:43.323829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-04-01 02:05:43.323838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-04-01 02:05:43.323846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-04-01 02:05:43.323855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-01 02:05:43.323886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.324091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.324299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-04-01 02:05:43.324319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-01 02:05:43.324339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-04-01 02:05:43.324343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-04-01 02:05:43.324402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.324608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-01 02:05:43.324810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3681 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)
TensorBoard 1.15.0 at http://atlas:6006/ (Press CTRL+C to quit)
WARNING:tensorflow:From /media/tausch/CurrentProjects/RBO/EfficientPose/layers.py:298: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
{'dataset_type': 'linemod', 'rotation_representation': 'axis_angle', 'weights': 'efficientdet-d0.h5', 'freeze_backbone': False, 'no_freeze_bn': False, 'batch_size': 1, 'lr': 0.0001, 'no_color_augmentation': False, 'no_6dof_augmentation': False, 'phi': 0, 'gpu': None, 'epochs': 500, 'steps': 1790, 'snapshot_path': 'checkpoints/01_04_2021_02_05_32', 'tensorboard_dir': 'logs/01_04_2021_02_05_32', 'snapshots': True, 'evaluation': True, 'compute_val_loss': False, 'score_threshold': 0.5, 'validation_image_save_path': None, 'multiprocessing': False, 'workers': 4, 'max_queue_size': 10, 'linemod_path': './Linemod_preprocessed/', 'object_id': 16}

Creating the Generators...
Done!

Building the Model...



Model: "efficientpose"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            
__________________________________________________________________________________________________
stem_conv (Conv2D)              (None, 256, 256, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
stem_bn (BatchNormalization)    (None, 256, 256, 32) 128         stem_conv[0][0]                  
__________________________________________________________________________________________________
stem_activation (Activation)    (None, 256, 256, 32) 0           stem_bn[0][0]                    
__________________________________________________________________________________________________
block1a_dwconv (DepthwiseConv2D (None, 256, 256, 32) 288         stem_activation[0][0]            
__________________________________________________________________________________________________
block1a_bn (BatchNormalization) (None, 256, 256, 32) 128         block1a_dwconv[0][0]             
__________________________________________________________________________________________________
block1a_activation (Activation) (None, 256, 256, 32) 0           block1a_bn[0][0]                 
__________________________________________________________________________________________________
block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         
__________________________________________________________________________________________________
block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         
__________________________________________________________________________________________________
block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          
__________________________________________________________________________________________________
block1a_se_excite (Multiply)    (None, 256, 256, 32) 0           block1a_activation[0][0]         
                                                                 block1a_se_expand[0][0]          
__________________________________________________________________________________________________
block1a_project_conv (Conv2D)   (None, 256, 256, 16) 512         block1a_se_excite[0][0]          
__________________________________________________________________________________________________
block1a_project_bn (BatchNormal (None, 256, 256, 16) 64          block1a_project_conv[0][0]       
__________________________________________________________________________________________________
block2a_expand_conv (Conv2D)    (None, 256, 256, 96) 1536        block1a_project_bn[0][0]         
__________________________________________________________________________________________________
block2a_expand_bn (BatchNormali (None, 256, 256, 96) 384         block2a_expand_conv[0][0]        
__________________________________________________________________________________________________
block2a_expand_activation (Acti (None, 256, 256, 96) 0           block2a_expand_bn[0][0]          
__________________________________________________________________________________________________
block2a_dwconv (DepthwiseConv2D (None, 128, 128, 96) 864         block2a_expand_activation[0][0]  
__________________________________________________________________________________________________
block2a_bn (BatchNormalization) (None, 128, 128, 96) 384         block2a_dwconv[0][0]             
__________________________________________________________________________________________________
block2a_activation (Activation) (None, 128, 128, 96) 0           block2a_bn[0][0]                 
__________________________________________________________________________________________________
block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         
__________________________________________________________________________________________________
block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         
__________________________________________________________________________________________________
block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          
__________________________________________________________________________________________________
block2a_se_excite (Multiply)    (None, 128, 128, 96) 0           block2a_activation[0][0]         
                                                                 block2a_se_expand[0][0]          
__________________________________________________________________________________________________
block2a_project_conv (Conv2D)   (None, 128, 128, 24) 2304        block2a_se_excite[0][0]          
__________________________________________________________________________________________________
block2a_project_bn (BatchNormal (None, 128, 128, 24) 96          block2a_project_conv[0][0]       
__________________________________________________________________________________________________
block2b_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block2a_project_bn[0][0]         
__________________________________________________________________________________________________
block2b_expand_bn (BatchNormali (None, 128, 128, 144 576         block2b_expand_conv[0][0]        
__________________________________________________________________________________________________
block2b_expand_activation (Acti (None, 128, 128, 144 0           block2b_expand_bn[0][0]          
__________________________________________________________________________________________________
block2b_dwconv (DepthwiseConv2D (None, 128, 128, 144 1296        block2b_expand_activation[0][0]  
__________________________________________________________________________________________________
block2b_bn (BatchNormalization) (None, 128, 128, 144 576         block2b_dwconv[0][0]             
__________________________________________________________________________________________________
block2b_activation (Activation) (None, 128, 128, 144 0           block2b_bn[0][0]                 
__________________________________________________________________________________________________
block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         
__________________________________________________________________________________________________
block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         
__________________________________________________________________________________________________
block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          
__________________________________________________________________________________________________
block2b_se_excite (Multiply)    (None, 128, 128, 144 0           block2b_activation[0][0]         
                                                                 block2b_se_expand[0][0]          
__________________________________________________________________________________________________
block2b_project_conv (Conv2D)   (None, 128, 128, 24) 3456        block2b_se_excite[0][0]          
__________________________________________________________________________________________________
block2b_project_bn (BatchNormal (None, 128, 128, 24) 96          block2b_project_conv[0][0]       
__________________________________________________________________________________________________
block2b_drop (FixedDropout)     (None, 128, 128, 24) 0           block2b_project_bn[0][0]         
__________________________________________________________________________________________________
block2b_add (Add)               (None, 128, 128, 24) 0           block2b_drop[0][0]               
                                                                 block2a_project_bn[0][0]         
__________________________________________________________________________________________________
block3a_expand_conv (Conv2D)    (None, 128, 128, 144 3456        block2b_add[0][0]                
__________________________________________________________________________________________________
block3a_expand_bn (BatchNormali (None, 128, 128, 144 576         block3a_expand_conv[0][0]        
__________________________________________________________________________________________________
block3a_expand_activation (Acti (None, 128, 128, 144 0           block3a_expand_bn[0][0]          
__________________________________________________________________________________________________
block3a_dwconv (DepthwiseConv2D (None, 64, 64, 144)  3600        block3a_expand_activation[0][0]  
__________________________________________________________________________________________________
block3a_bn (BatchNormalization) (None, 64, 64, 144)  576         block3a_dwconv[0][0]             
__________________________________________________________________________________________________
block3a_activation (Activation) (None, 64, 64, 144)  0           block3a_bn[0][0]                 
__________________________________________________________________________________________________
block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         
__________________________________________________________________________________________________
block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         
__________________________________________________________________________________________________
block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          
__________________________________________________________________________________________________
block3a_se_excite (Multiply)    (None, 64, 64, 144)  0           block3a_activation[0][0]         
                                                                 block3a_se_expand[0][0]          
__________________________________________________________________________________________________
block3a_project_conv (Conv2D)   (None, 64, 64, 40)   5760        block3a_se_excite[0][0]          
__________________________________________________________________________________________________
block3a_project_bn (BatchNormal (None, 64, 64, 40)   160         block3a_project_conv[0][0]       
__________________________________________________________________________________________________
block3b_expand_conv (Conv2D)    (None, 64, 64, 240)  9600        block3a_project_bn[0][0]         
__________________________________________________________________________________________________
block3b_expand_bn (BatchNormali (None, 64, 64, 240)  960         block3b_expand_conv[0][0]        
__________________________________________________________________________________________________
block3b_expand_activation (Acti (None, 64, 64, 240)  0           block3b_expand_bn[0][0]          
__________________________________________________________________________________________________
block3b_dwconv (DepthwiseConv2D (None, 64, 64, 240)  6000        block3b_expand_activation[0][0]  
__________________________________________________________________________________________________
block3b_bn (BatchNormalization) (None, 64, 64, 240)  960         block3b_dwconv[0][0]             
__________________________________________________________________________________________________
block3b_activation (Activation) (None, 64, 64, 240)  0           block3b_bn[0][0]                 
__________________________________________________________________________________________________
block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         
__________________________________________________________________________________________________
block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         
__________________________________________________________________________________________________
block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          
__________________________________________________________________________________________________
block3b_se_excite (Multiply)    (None, 64, 64, 240)  0           block3b_activation[0][0]         
                                                                 block3b_se_expand[0][0]          
__________________________________________________________________________________________________
block3b_project_conv (Conv2D)   (None, 64, 64, 40)   9600        block3b_se_excite[0][0]          
__________________________________________________________________________________________________
block3b_project_bn (BatchNormal (None, 64, 64, 40)   160         block3b_project_conv[0][0]       
__________________________________________________________________________________________________
block3b_drop (FixedDropout)     (None, 64, 64, 40)   0           block3b_project_bn[0][0]         
__________________________________________________________________________________________________
block3b_add (Add)               (None, 64, 64, 40)   0           block3b_drop[0][0]               
                                                                 block3a_project_bn[0][0]         
__________________________________________________________________________________________________
block4a_expand_conv (Conv2D)    (None, 64, 64, 240)  9600        block3b_add[0][0]                
__________________________________________________________________________________________________
block4a_expand_bn (BatchNormali (None, 64, 64, 240)  960         block4a_expand_conv[0][0]        
__________________________________________________________________________________________________
block4a_expand_activation (Acti (None, 64, 64, 240)  0           block4a_expand_bn[0][0]          
__________________________________________________________________________________________________
block4a_dwconv (DepthwiseConv2D (None, 32, 32, 240)  2160        block4a_expand_activation[0][0]  
__________________________________________________________________________________________________
block4a_bn (BatchNormalization) (None, 32, 32, 240)  960         block4a_dwconv[0][0]             
__________________________________________________________________________________________________
block4a_activation (Activation) (None, 32, 32, 240)  0           block4a_bn[0][0]                 
__________________________________________________________________________________________________
block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         
__________________________________________________________________________________________________
block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         
__________________________________________________________________________________________________
block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          
__________________________________________________________________________________________________
block4a_se_excite (Multiply)    (None, 32, 32, 240)  0           block4a_activation[0][0]         
                                                                 block4a_se_expand[0][0]          
__________________________________________________________________________________________________
block4a_project_conv (Conv2D)   (None, 32, 32, 80)   19200       block4a_se_excite[0][0]          
__________________________________________________________________________________________________
block4a_project_bn (BatchNormal (None, 32, 32, 80)   320         block4a_project_conv[0][0]       
__________________________________________________________________________________________________
block4b_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4a_project_bn[0][0]         
__________________________________________________________________________________________________
block4b_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block4b_expand_conv[0][0]        
__________________________________________________________________________________________________
block4b_expand_activation (Acti (None, 32, 32, 480)  0           block4b_expand_bn[0][0]          
__________________________________________________________________________________________________
block4b_dwconv (DepthwiseConv2D (None, 32, 32, 480)  4320        block4b_expand_activation[0][0]  
__________________________________________________________________________________________________
block4b_bn (BatchNormalization) (None, 32, 32, 480)  1920        block4b_dwconv[0][0]             
__________________________________________________________________________________________________
block4b_activation (Activation) (None, 32, 32, 480)  0           block4b_bn[0][0]                 
__________________________________________________________________________________________________
block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         
__________________________________________________________________________________________________
block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         
__________________________________________________________________________________________________
block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          
__________________________________________________________________________________________________
block4b_se_excite (Multiply)    (None, 32, 32, 480)  0           block4b_activation[0][0]         
                                                                 block4b_se_expand[0][0]          
__________________________________________________________________________________________________
block4b_project_conv (Conv2D)   (None, 32, 32, 80)   38400       block4b_se_excite[0][0]          
__________________________________________________________________________________________________
block4b_project_bn (BatchNormal (None, 32, 32, 80)   320         block4b_project_conv[0][0]       
__________________________________________________________________________________________________
block4b_drop (FixedDropout)     (None, 32, 32, 80)   0           block4b_project_bn[0][0]         
__________________________________________________________________________________________________
block4b_add (Add)               (None, 32, 32, 80)   0           block4b_drop[0][0]               
                                                                 block4a_project_bn[0][0]         
__________________________________________________________________________________________________
block4c_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4b_add[0][0]                
__________________________________________________________________________________________________
block4c_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block4c_expand_conv[0][0]        
__________________________________________________________________________________________________
block4c_expand_activation (Acti (None, 32, 32, 480)  0           block4c_expand_bn[0][0]          
__________________________________________________________________________________________________
block4c_dwconv (DepthwiseConv2D (None, 32, 32, 480)  4320        block4c_expand_activation[0][0]  
__________________________________________________________________________________________________
block4c_bn (BatchNormalization) (None, 32, 32, 480)  1920        block4c_dwconv[0][0]             
__________________________________________________________________________________________________
block4c_activation (Activation) (None, 32, 32, 480)  0           block4c_bn[0][0]                 
__________________________________________________________________________________________________
block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         
__________________________________________________________________________________________________
block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         
__________________________________________________________________________________________________
block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          
__________________________________________________________________________________________________
block4c_se_excite (Multiply)    (None, 32, 32, 480)  0           block4c_activation[0][0]         
                                                                 block4c_se_expand[0][0]          
__________________________________________________________________________________________________
block4c_project_conv (Conv2D)   (None, 32, 32, 80)   38400       block4c_se_excite[0][0]          
__________________________________________________________________________________________________
block4c_project_bn (BatchNormal (None, 32, 32, 80)   320         block4c_project_conv[0][0]       
__________________________________________________________________________________________________
block4c_drop (FixedDropout)     (None, 32, 32, 80)   0           block4c_project_bn[0][0]         
__________________________________________________________________________________________________
block4c_add (Add)               (None, 32, 32, 80)   0           block4c_drop[0][0]               
                                                                 block4b_add[0][0]                
__________________________________________________________________________________________________
block5a_expand_conv (Conv2D)    (None, 32, 32, 480)  38400       block4c_add[0][0]                
__________________________________________________________________________________________________
block5a_expand_bn (BatchNormali (None, 32, 32, 480)  1920        block5a_expand_conv[0][0]        
__________________________________________________________________________________________________
block5a_expand_activation (Acti (None, 32, 32, 480)  0           block5a_expand_bn[0][0]          
__________________________________________________________________________________________________
block5a_dwconv (DepthwiseConv2D (None, 32, 32, 480)  12000       block5a_expand_activation[0][0]  
__________________________________________________________________________________________________
block5a_bn (BatchNormalization) (None, 32, 32, 480)  1920        block5a_dwconv[0][0]             
__________________________________________________________________________________________________
block5a_activation (Activation) (None, 32, 32, 480)  0           block5a_bn[0][0]                 
__________________________________________________________________________________________________
block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         
__________________________________________________________________________________________________
block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         
__________________________________________________________________________________________________
block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          
__________________________________________________________________________________________________
block5a_se_excite (Multiply)    (None, 32, 32, 480)  0           block5a_activation[0][0]         
                                                                 block5a_se_expand[0][0]          
__________________________________________________________________________________________________
block5a_project_conv (Conv2D)   (None, 32, 32, 112)  53760       block5a_se_excite[0][0]          
__________________________________________________________________________________________________
block5a_project_bn (BatchNormal (None, 32, 32, 112)  448         block5a_project_conv[0][0]       
__________________________________________________________________________________________________
block5b_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5a_project_bn[0][0]         
__________________________________________________________________________________________________
block5b_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block5b_expand_conv[0][0]        
__________________________________________________________________________________________________
block5b_expand_activation (Acti (None, 32, 32, 672)  0           block5b_expand_bn[0][0]          
__________________________________________________________________________________________________
block5b_dwconv (DepthwiseConv2D (None, 32, 32, 672)  16800       block5b_expand_activation[0][0]  
__________________________________________________________________________________________________
block5b_bn (BatchNormalization) (None, 32, 32, 672)  2688        block5b_dwconv[0][0]             
__________________________________________________________________________________________________
block5b_activation (Activation) (None, 32, 32, 672)  0           block5b_bn[0][0]                 
__________________________________________________________________________________________________
block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         
__________________________________________________________________________________________________
block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         
__________________________________________________________________________________________________
block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          
__________________________________________________________________________________________________
block5b_se_excite (Multiply)    (None, 32, 32, 672)  0           block5b_activation[0][0]         
                                                                 block5b_se_expand[0][0]          
__________________________________________________________________________________________________
block5b_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block5b_se_excite[0][0]          
__________________________________________________________________________________________________
block5b_project_bn (BatchNormal (None, 32, 32, 112)  448         block5b_project_conv[0][0]       
__________________________________________________________________________________________________
block5b_drop (FixedDropout)     (None, 32, 32, 112)  0           block5b_project_bn[0][0]         
__________________________________________________________________________________________________
block5b_add (Add)               (None, 32, 32, 112)  0           block5b_drop[0][0]               
                                                                 block5a_project_bn[0][0]         
__________________________________________________________________________________________________
block5c_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5b_add[0][0]                
__________________________________________________________________________________________________
block5c_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block5c_expand_conv[0][0]        
__________________________________________________________________________________________________
block5c_expand_activation (Acti (None, 32, 32, 672)  0           block5c_expand_bn[0][0]          
__________________________________________________________________________________________________
block5c_dwconv (DepthwiseConv2D (None, 32, 32, 672)  16800       block5c_expand_activation[0][0]  
__________________________________________________________________________________________________
block5c_bn (BatchNormalization) (None, 32, 32, 672)  2688        block5c_dwconv[0][0]             
__________________________________________________________________________________________________
block5c_activation (Activation) (None, 32, 32, 672)  0           block5c_bn[0][0]                 
__________________________________________________________________________________________________
block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         
__________________________________________________________________________________________________
block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         
__________________________________________________________________________________________________
block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          
__________________________________________________________________________________________________
block5c_se_excite (Multiply)    (None, 32, 32, 672)  0           block5c_activation[0][0]         
                                                                 block5c_se_expand[0][0]          
__________________________________________________________________________________________________
block5c_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block5c_se_excite[0][0]          
__________________________________________________________________________________________________
block5c_project_bn (BatchNormal (None, 32, 32, 112)  448         block5c_project_conv[0][0]       
__________________________________________________________________________________________________
block5c_drop (FixedDropout)     (None, 32, 32, 112)  0           block5c_project_bn[0][0]         
__________________________________________________________________________________________________
block5c_add (Add)               (None, 32, 32, 112)  0           block5c_drop[0][0]               
                                                                 block5b_add[0][0]                
__________________________________________________________________________________________________
block6a_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block5c_add[0][0]                
__________________________________________________________________________________________________
block6a_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block6a_expand_conv[0][0]        
__________________________________________________________________________________________________
block6a_expand_activation (Acti (None, 32, 32, 672)  0           block6a_expand_bn[0][0]          
__________________________________________________________________________________________________
block6a_dwconv (DepthwiseConv2D (None, 16, 16, 672)  16800       block6a_expand_activation[0][0]  
__________________________________________________________________________________________________
block6a_bn (BatchNormalization) (None, 16, 16, 672)  2688        block6a_dwconv[0][0]             
__________________________________________________________________________________________________
block6a_activation (Activation) (None, 16, 16, 672)  0           block6a_bn[0][0]                 
__________________________________________________________________________________________________
block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         
__________________________________________________________________________________________________
block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         
__________________________________________________________________________________________________
block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          
__________________________________________________________________________________________________
block6a_se_excite (Multiply)    (None, 16, 16, 672)  0           block6a_activation[0][0]         
                                                                 block6a_se_expand[0][0]          
__________________________________________________________________________________________________
block6a_project_conv (Conv2D)   (None, 16, 16, 192)  129024      block6a_se_excite[0][0]          
__________________________________________________________________________________________________
block6a_project_bn (BatchNormal (None, 16, 16, 192)  768         block6a_project_conv[0][0]       
__________________________________________________________________________________________________
block6b_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6a_project_bn[0][0]         
__________________________________________________________________________________________________
block6b_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6b_expand_conv[0][0]        
__________________________________________________________________________________________________
block6b_expand_activation (Acti (None, 16, 16, 1152) 0           block6b_expand_bn[0][0]          
__________________________________________________________________________________________________
block6b_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6b_expand_activation[0][0]  
__________________________________________________________________________________________________
block6b_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6b_dwconv[0][0]             
__________________________________________________________________________________________________
block6b_activation (Activation) (None, 16, 16, 1152) 0           block6b_bn[0][0]                 
__________________________________________________________________________________________________
block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         
__________________________________________________________________________________________________
block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         
__________________________________________________________________________________________________
block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          
__________________________________________________________________________________________________
block6b_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6b_activation[0][0]         
                                                                 block6b_se_expand[0][0]          
__________________________________________________________________________________________________
block6b_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6b_se_excite[0][0]          
__________________________________________________________________________________________________
block6b_project_bn (BatchNormal (None, 16, 16, 192)  768         block6b_project_conv[0][0]       
__________________________________________________________________________________________________
block6b_drop (FixedDropout)     (None, 16, 16, 192)  0           block6b_project_bn[0][0]         
__________________________________________________________________________________________________
block6b_add (Add)               (None, 16, 16, 192)  0           block6b_drop[0][0]               
                                                                 block6a_project_bn[0][0]         
__________________________________________________________________________________________________
block6c_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6b_add[0][0]                
__________________________________________________________________________________________________
block6c_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6c_expand_conv[0][0]        
__________________________________________________________________________________________________
block6c_expand_activation (Acti (None, 16, 16, 1152) 0           block6c_expand_bn[0][0]          
__________________________________________________________________________________________________
block6c_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6c_expand_activation[0][0]  
__________________________________________________________________________________________________
block6c_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6c_dwconv[0][0]             
__________________________________________________________________________________________________
block6c_activation (Activation) (None, 16, 16, 1152) 0           block6c_bn[0][0]                 
__________________________________________________________________________________________________
block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         
__________________________________________________________________________________________________
block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         
__________________________________________________________________________________________________
block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          
__________________________________________________________________________________________________
block6c_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6c_activation[0][0]         
                                                                 block6c_se_expand[0][0]          
__________________________________________________________________________________________________
block6c_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6c_se_excite[0][0]          
__________________________________________________________________________________________________
block6c_project_bn (BatchNormal (None, 16, 16, 192)  768         block6c_project_conv[0][0]       
__________________________________________________________________________________________________
block6c_drop (FixedDropout)     (None, 16, 16, 192)  0           block6c_project_bn[0][0]         
__________________________________________________________________________________________________
block6c_add (Add)               (None, 16, 16, 192)  0           block6c_drop[0][0]               
                                                                 block6b_add[0][0]                
__________________________________________________________________________________________________
block6d_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6c_add[0][0]                
__________________________________________________________________________________________________
block6d_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block6d_expand_conv[0][0]        
__________________________________________________________________________________________________
block6d_expand_activation (Acti (None, 16, 16, 1152) 0           block6d_expand_bn[0][0]          
__________________________________________________________________________________________________
block6d_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 28800       block6d_expand_activation[0][0]  
__________________________________________________________________________________________________
block6d_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block6d_dwconv[0][0]             
__________________________________________________________________________________________________
block6d_activation (Activation) (None, 16, 16, 1152) 0           block6d_bn[0][0]                 
__________________________________________________________________________________________________
block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         
__________________________________________________________________________________________________
block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         
__________________________________________________________________________________________________
block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          
__________________________________________________________________________________________________
block6d_se_excite (Multiply)    (None, 16, 16, 1152) 0           block6d_activation[0][0]         
                                                                 block6d_se_expand[0][0]          
__________________________________________________________________________________________________
block6d_project_conv (Conv2D)   (None, 16, 16, 192)  221184      block6d_se_excite[0][0]          
__________________________________________________________________________________________________
block6d_project_bn (BatchNormal (None, 16, 16, 192)  768         block6d_project_conv[0][0]       
__________________________________________________________________________________________________
block6d_drop (FixedDropout)     (None, 16, 16, 192)  0           block6d_project_bn[0][0]         
__________________________________________________________________________________________________
block6d_add (Add)               (None, 16, 16, 192)  0           block6d_drop[0][0]               
                                                                 block6c_add[0][0]                
__________________________________________________________________________________________________
block7a_expand_conv (Conv2D)    (None, 16, 16, 1152) 221184      block6d_add[0][0]                
__________________________________________________________________________________________________
block7a_expand_bn (BatchNormali (None, 16, 16, 1152) 4608        block7a_expand_conv[0][0]        
__________________________________________________________________________________________________
block7a_expand_activation (Acti (None, 16, 16, 1152) 0           block7a_expand_bn[0][0]          
__________________________________________________________________________________________________
block7a_dwconv (DepthwiseConv2D (None, 16, 16, 1152) 10368       block7a_expand_activation[0][0]  
__________________________________________________________________________________________________
block7a_bn (BatchNormalization) (None, 16, 16, 1152) 4608        block7a_dwconv[0][0]             
__________________________________________________________________________________________________
block7a_activation (Activation) (None, 16, 16, 1152) 0           block7a_bn[0][0]                 
__________________________________________________________________________________________________
block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         
__________________________________________________________________________________________________
block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         
__________________________________________________________________________________________________
block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          
__________________________________________________________________________________________________
block7a_se_excite (Multiply)    (None, 16, 16, 1152) 0           block7a_activation[0][0]         
                                                                 block7a_se_expand[0][0]          
__________________________________________________________________________________________________
block7a_project_conv (Conv2D)   (None, 16, 16, 320)  368640      block7a_se_excite[0][0]          
__________________________________________________________________________________________________
block7a_project_bn (BatchNormal (None, 16, 16, 320)  1280        block7a_project_conv[0][0]       
__________________________________________________________________________________________________
resample_p6/conv2d (Conv2D)     (None, 16, 16, 64)   20544       block7a_project_bn[0][0]         
__________________________________________________________________________________________________
resample_p6/bn (BatchNormalizat (None, 16, 16, 64)   256         resample_p6/conv2d[0][0]         
__________________________________________________________________________________________________
resample_p6/maxpool (MaxPooling (None, 8, 8, 64)     0           resample_p6/bn[0][0]             
__________________________________________________________________________________________________
resample_p7/maxpool (MaxPooling (None, 4, 4, 64)     0           resample_p6/maxpool[0][0]        
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 8, 8, 64)     0           resample_p7/maxpool[0][0]        
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode0/add (wB (None, 8, 8, 64)     2           resample_p6/maxpool[0][0]        
                                                                 up_sampling2d[0][0]              
__________________________________________________________________________________________________
activation (Activation)         (None, 8, 8, 64)     0           fpn_cells/cell_0/fnode0/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode0/op_afte (None, 8, 8, 64)     4736        activation[0][0]                 
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode1/resampl (None, 16, 16, 64)   20544       block7a_project_bn[0][0]         
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode0/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_0/fnode0/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode1/resampl (None, 16, 16, 64)   256         fpn_cells/cell_0/fnode1/resample_
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_0/fnode0/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode1/add (wB (None, 16, 16, 64)   2           fpn_cells/cell_0/fnode1/resample_
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 16, 64)   0           fpn_cells/cell_0/fnode1/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode1/op_afte (None, 16, 16, 64)   4736        activation_1[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode2/resampl (None, 32, 32, 64)   7232        block5c_add[0][0]                
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode1/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_0/fnode1/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode2/resampl (None, 32, 32, 64)   256         fpn_cells/cell_0/fnode2/resample_
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 64)   0           fpn_cells/cell_0/fnode1/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode2/add (wB (None, 32, 32, 64)   2           fpn_cells/cell_0/fnode2/resample_
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 64)   0           fpn_cells/cell_0/fnode2/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode2/op_afte (None, 32, 32, 64)   4736        activation_2[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode3/resampl (None, 64, 64, 64)   2624        block3b_add[0][0]                
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode2/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_0/fnode2/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode3/resampl (None, 64, 64, 64)   256         fpn_cells/cell_0/fnode3/resample_
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 64)   0           fpn_cells/cell_0/fnode2/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode3/add (wB (None, 64, 64, 64)   2           fpn_cells/cell_0/fnode3/resample_
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 64, 64, 64)   0           fpn_cells/cell_0/fnode3/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode3/op_afte (None, 64, 64, 64)   4736        activation_3[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode3/op_afte (None, 64, 64, 64)   256         fpn_cells/cell_0/fnode3/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode4/resampl (None, 32, 32, 64)   7232        block5c_add[0][0]                
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode4/resampl (None, 32, 32, 64)   256         fpn_cells/cell_0/fnode4/resample_
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 32, 32, 64)   0           fpn_cells/cell_0/fnode3/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode4/add (wB (None, 32, 32, 64)   3           fpn_cells/cell_0/fnode4/resample_
                                                                 fpn_cells/cell_0/fnode2/op_after_
                                                                 max_pooling2d[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 64)   0           fpn_cells/cell_0/fnode4/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode4/op_afte (None, 32, 32, 64)   4736        activation_4[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode5/resampl (None, 16, 16, 64)   20544       block7a_project_bn[0][0]         
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode4/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_0/fnode4/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode5/resampl (None, 16, 16, 64)   256         fpn_cells/cell_0/fnode5/resample_
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_0/fnode4/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode5/add (wB (None, 16, 16, 64)   3           fpn_cells/cell_0/fnode5/resample_
                                                                 fpn_cells/cell_0/fnode1/op_after_
                                                                 max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 16, 16, 64)   0           fpn_cells/cell_0/fnode5/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode5/op_afte (None, 16, 16, 64)   4736        activation_5[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode5/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_0/fnode5/op_after_
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           fpn_cells/cell_0/fnode5/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode6/add (wB (None, 8, 8, 64)     3           resample_p6/maxpool[0][0]        
                                                                 fpn_cells/cell_0/fnode0/op_after_
                                                                 max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 8, 8, 64)     0           fpn_cells/cell_0/fnode6/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode6/op_afte (None, 8, 8, 64)     4736        activation_6[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode6/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_0/fnode6/op_after_
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           fpn_cells/cell_0/fnode6/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode7/add (wB (None, 4, 4, 64)     2           resample_p7/maxpool[0][0]        
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 4, 4, 64)     0           fpn_cells/cell_0/fnode7/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode7/op_afte (None, 4, 4, 64)     4736        activation_7[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_0/fnode7/op_afte (None, 4, 4, 64)     256         fpn_cells/cell_0/fnode7/op_after_
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 64)     0           fpn_cells/cell_0/fnode7/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode0/add (wB (None, 8, 8, 64)     2           fpn_cells/cell_0/fnode0/op_after_
                                                                 up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 8, 8, 64)     0           fpn_cells/cell_1/fnode0/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode0/op_afte (None, 8, 8, 64)     4736        activation_8[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode0/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_1/fnode0/op_after_
__________________________________________________________________________________________________
up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_1/fnode0/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode1/add (wB (None, 16, 16, 64)   2           fpn_cells/cell_0/fnode1/op_after_
                                                                 up_sampling2d_5[0][0]            
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 64)   0           fpn_cells/cell_1/fnode1/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode1/op_afte (None, 16, 16, 64)   4736        activation_9[0][0]               
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode1/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_1/fnode1/op_after_
__________________________________________________________________________________________________
up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 64)   0           fpn_cells/cell_1/fnode1/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode2/add (wB (None, 32, 32, 64)   2           fpn_cells/cell_0/fnode2/op_after_
                                                                 up_sampling2d_6[0][0]            
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 64)   0           fpn_cells/cell_1/fnode2/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode2/op_afte (None, 32, 32, 64)   4736        activation_10[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode2/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_1/fnode2/op_after_
__________________________________________________________________________________________________
up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 64)   0           fpn_cells/cell_1/fnode2/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode3/add (wB (None, 64, 64, 64)   2           fpn_cells/cell_0/fnode3/op_after_
                                                                 up_sampling2d_7[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 64, 64, 64)   0           fpn_cells/cell_1/fnode3/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode3/op_afte (None, 64, 64, 64)   4736        activation_11[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode3/op_afte (None, 64, 64, 64)   256         fpn_cells/cell_1/fnode3/op_after_
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 64)   0           fpn_cells/cell_1/fnode3/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode4/add (wB (None, 32, 32, 64)   3           fpn_cells/cell_0/fnode2/op_after_
                                                                 fpn_cells/cell_1/fnode2/op_after_
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 64)   0           fpn_cells/cell_1/fnode4/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode4/op_afte (None, 32, 32, 64)   4736        activation_12[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode4/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_1/fnode4/op_after_
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_1/fnode4/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode5/add (wB (None, 16, 16, 64)   3           fpn_cells/cell_0/fnode1/op_after_
                                                                 fpn_cells/cell_1/fnode1/op_after_
                                                                 max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 64)   0           fpn_cells/cell_1/fnode5/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode5/op_afte (None, 16, 16, 64)   4736        activation_13[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode5/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_1/fnode5/op_after_
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 64)     0           fpn_cells/cell_1/fnode5/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode6/add (wB (None, 8, 8, 64)     3           fpn_cells/cell_0/fnode0/op_after_
                                                                 fpn_cells/cell_1/fnode0/op_after_
                                                                 max_pooling2d_6[0][0]            
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           fpn_cells/cell_1/fnode6/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode6/op_afte (None, 8, 8, 64)     4736        activation_14[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode6/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_1/fnode6/op_after_
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 64)     0           fpn_cells/cell_1/fnode6/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode7/add (wB (None, 4, 4, 64)     2           fpn_cells/cell_0/fnode7/op_after_
                                                                 max_pooling2d_7[0][0]            
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 4, 4, 64)     0           fpn_cells/cell_1/fnode7/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode7/op_afte (None, 4, 4, 64)     4736        activation_15[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_1/fnode7/op_afte (None, 4, 4, 64)     256         fpn_cells/cell_1/fnode7/op_after_
__________________________________________________________________________________________________
up_sampling2d_8 (UpSampling2D)  (None, 8, 8, 64)     0           fpn_cells/cell_1/fnode7/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode0/add (wB (None, 8, 8, 64)     2           fpn_cells/cell_1/fnode0/op_after_
                                                                 up_sampling2d_8[0][0]            
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           fpn_cells/cell_2/fnode0/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode0/op_afte (None, 8, 8, 64)     4736        activation_16[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode0/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_2/fnode0/op_after_
__________________________________________________________________________________________________
up_sampling2d_9 (UpSampling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_2/fnode0/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode1/add (wB (None, 16, 16, 64)   2           fpn_cells/cell_1/fnode1/op_after_
                                                                 up_sampling2d_9[0][0]            
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 64)   0           fpn_cells/cell_2/fnode1/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode1/op_afte (None, 16, 16, 64)   4736        activation_17[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode1/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_2/fnode1/op_after_
__________________________________________________________________________________________________
up_sampling2d_10 (UpSampling2D) (None, 32, 32, 64)   0           fpn_cells/cell_2/fnode1/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode2/add (wB (None, 32, 32, 64)   2           fpn_cells/cell_1/fnode2/op_after_
                                                                 up_sampling2d_10[0][0]           
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 64)   0           fpn_cells/cell_2/fnode2/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode2/op_afte (None, 32, 32, 64)   4736        activation_18[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode2/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_2/fnode2/op_after_
__________________________________________________________________________________________________
up_sampling2d_11 (UpSampling2D) (None, 64, 64, 64)   0           fpn_cells/cell_2/fnode2/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode3/add (wB (None, 64, 64, 64)   2           fpn_cells/cell_1/fnode3/op_after_
                                                                 up_sampling2d_11[0][0]           
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 64)   0           fpn_cells/cell_2/fnode3/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode3/op_afte (None, 64, 64, 64)   4736        activation_19[0][0]              
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode3/op_afte (None, 64, 64, 64)   256         fpn_cells/cell_2/fnode3/op_after_
__________________________________________________________________________________________________
translation_net/translation-0 ( multiple             4736        fpn_cells/cell_2/fnode3/op_after_
                                                                 fpn_cells/cell_2/fnode2/op_after_
                                                                 fpn_cells/cell_2/fnode1/op_after_
                                                                 fpn_cells/cell_2/fnode0/op_after_
                                                                 fpn_cells/cell_2/fnode7/op_after_
__________________________________________________________________________________________________
translation_net/translation-0-g (None, 64, 64, 64)   128         translation_net/translation-0[0][
__________________________________________________________________________________________________
lambda_5 (Lambda)               multiple             0           translation_net/translation-0-gn-
                                                                 translation_net/translation-1-gn-
                                                                 translation_net/translation-2-gn-
                                                                 translation_net/translation-0-gn-
                                                                 translation_net/translation-1-gn-
                                                                 translation_net/translation-2-gn-
                                                                 translation_net/translation-0-gn-
                                                                 translation_net/translation-1-gn-
                                                                 translation_net/translation-2-gn-
                                                                 translation_net/translation-0-gn-
                                                                 translation_net/translation-1-gn-
                                                                 translation_net/translation-2-gn-
                                                                 translation_net/translation-0-gn-
                                                                 translation_net/translation-1-gn-
                                                                 translation_net/translation-2-gn-
__________________________________________________________________________________________________
translation_net/translation-1 ( multiple             4736        lambda_5[0][0]                   
                                                                 lambda_5[3][0]                   
                                                                 lambda_5[6][0]                   
                                                                 lambda_5[9][0]                   
                                                                 lambda_5[12][0]                  
__________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 64)   0           fpn_cells/cell_2/fnode3/op_after_
__________________________________________________________________________________________________
translation_net/translation-1-g (None, 64, 64, 64)   128         translation_net/translation-1[0][
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode4/add (wB (None, 32, 32, 64)   3           fpn_cells/cell_1/fnode2/op_after_
                                                                 fpn_cells/cell_2/fnode2/op_after_
                                                                 max_pooling2d_8[0][0]            
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 64)   0           fpn_cells/cell_2/fnode4/add[0][0]
__________________________________________________________________________________________________
rotation_net/rotation-0 (Separa multiple             4736        fpn_cells/cell_2/fnode3/op_after_
                                                                 fpn_cells/cell_2/fnode2/op_after_
                                                                 fpn_cells/cell_2/fnode1/op_after_
                                                                 fpn_cells/cell_2/fnode0/op_after_
                                                                 fpn_cells/cell_2/fnode7/op_after_
__________________________________________________________________________________________________
translation_net/translation-2 ( multiple             4736        lambda_5[1][0]                   
                                                                 lambda_5[4][0]                   
                                                                 lambda_5[7][0]                   
                                                                 lambda_5[10][0]                  
                                                                 lambda_5[13][0]                  
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode4/op_afte (None, 32, 32, 64)   4736        activation_20[0][0]              
__________________________________________________________________________________________________
rotation_net/rotation-0-gn-3 (G (None, 64, 64, 64)   128         rotation_net/rotation-0[0][0]    
__________________________________________________________________________________________________
translation_net/translation-2-g (None, 64, 64, 64)   128         translation_net/translation-2[0][
__________________________________________________________________________________________________
translation_net/translation-0-g (None, 32, 32, 64)   128         translation_net/translation-0[1][
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode4/op_afte (None, 32, 32, 64)   256         fpn_cells/cell_2/fnode4/op_after_
__________________________________________________________________________________________________
lambda_3 (Lambda)               multiple             0           rotation_net/rotation-0-gn-3[0][0
                                                                 rotation_net/rotation-1-gn-3[0][0
                                                                 rotation_net/rotation-2-gn-3[0][0
                                                                 rotation_net/rotation-0-gn-4[0][0
                                                                 rotation_net/rotation-1-gn-4[0][0
                                                                 rotation_net/rotation-2-gn-4[0][0
                                                                 rotation_net/rotation-0-gn-5[0][0
                                                                 rotation_net/rotation-1-gn-5[0][0
                                                                 rotation_net/rotation-2-gn-5[0][0
                                                                 rotation_net/rotation-0-gn-6[0][0
                                                                 rotation_net/rotation-1-gn-6[0][0
                                                                 rotation_net/rotation-2-gn-6[0][0
                                                                 rotation_net/rotation-0-gn-7[0][0
                                                                 rotation_net/rotation-1-gn-7[0][0
                                                                 rotation_net/rotation-2-gn-7[0][0
__________________________________________________________________________________________________
max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 64)   0           fpn_cells/cell_2/fnode4/op_after_
__________________________________________________________________________________________________
rotation_net/rotation-1 (Separa multiple             4736        lambda_3[0][0]                   
                                                                 lambda_3[3][0]                   
                                                                 lambda_3[6][0]                   
                                                                 lambda_3[9][0]                   
                                                                 lambda_3[12][0]                  
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode5/add (wB (None, 16, 16, 64)   3           fpn_cells/cell_1/fnode1/op_after_
                                                                 fpn_cells/cell_2/fnode1/op_after_
                                                                 max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
rotation_net/rotation-1-gn-3 (G (None, 64, 64, 64)   128         rotation_net/rotation-1[0][0]    
__________________________________________________________________________________________________
translation_net/translation-1-g (None, 32, 32, 64)   128         translation_net/translation-1[1][
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 64)   0           fpn_cells/cell_2/fnode5/add[0][0]
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode5/op_afte (None, 16, 16, 64)   4736        activation_21[0][0]              
__________________________________________________________________________________________________
rotation_net/rotation-2 (Separa multiple             4736        lambda_3[1][0]                   
                                                                 lambda_3[4][0]                   
                                                                 lambda_3[7][0]                   
                                                                 lambda_3[10][0]                  
                                                                 lambda_3[13][0]                  
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode5/op_afte (None, 16, 16, 64)   256         fpn_cells/cell_2/fnode5/op_after_
__________________________________________________________________________________________________
rotation_net/rotation-2-gn-3 (G (None, 64, 64, 64)   128         rotation_net/rotation-2[0][0]    
__________________________________________________________________________________________________
rotation_net/rotation-0-gn-4 (G (None, 32, 32, 64)   128         rotation_net/rotation-0[1][0]    
__________________________________________________________________________________________________
translation_net/translation-2-g (None, 32, 32, 64)   128         translation_net/translation-2[1][
__________________________________________________________________________________________________
translation_net/translation-0-g (None, 16, 16, 64)   128         translation_net/translation-0[2][
__________________________________________________________________________________________________
max_pooling2d_10 (MaxPooling2D) (None, 8, 8, 64)     0           fpn_cells/cell_2/fnode5/op_after_
__________________________________________________________________________________________________
class_net/class-0 (SeparableCon multiple             4736        fpn_cells/cell_2/fnode3/op_after_
                                                                 fpn_cells/cell_2/fnode2/op_after_
                                                                 fpn_cells/cell_2/fnode1/op_after_
                                                                 fpn_cells/cell_2/fnode0/op_after_
                                                                 fpn_cells/cell_2/fnode7/op_after_
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode6/add (wB (None, 8, 8, 64)     3           fpn_cells/cell_1/fnode0/op_after_
                                                                 fpn_cells/cell_2/fnode0/op_after_
                                                                 max_pooling2d_10[0][0]           
__________________________________________________________________________________________________
class_net/class-0-bn-3 (BatchNo (None, 64, 64, 64)   256         class_net/class-0[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           fpn_cells/cell_2/fnode6/add[0][0]
__________________________________________________________________________________________________
box_net/box-0 (SeparableConv2D) multiple             4736        fpn_cells/cell_2/fnode3/op_after_
                                                                 fpn_cells/cell_2/fnode2/op_after_
                                                                 fpn_cells/cell_2/fnode1/op_after_
                                                                 fpn_cells/cell_2/fnode0/op_after_
                                                                 fpn_cells/cell_2/fnode7/op_after_
__________________________________________________________________________________________________
rotation_net/rotation-1-gn-4 (G (None, 32, 32, 64)   128         rotation_net/rotation-1[1][0]    
__________________________________________________________________________________________________
translation_net/translation-1-g (None, 16, 16, 64)   128         translation_net/translation-1[2][
__________________________________________________________________________________________________
lambda_1 (Lambda)               multiple             0           class_net/class-0-bn-3[0][0]     
                                                                 class_net/class-1-bn-3[0][0]     
                                                                 class_net/class-2-bn-3[0][0]     
                                                                 class_net/class-0-bn-4[0][0]     
                                                                 class_net/class-1-bn-4[0][0]     
                                                                 class_net/class-2-bn-4[0][0]     
                                                                 class_net/class-0-bn-5[0][0]     
                                                                 class_net/class-1-bn-5[0][0]     
                                                                 class_net/class-2-bn-5[0][0]     
                                                                 class_net/class-0-bn-6[0][0]     
                                                                 class_net/class-1-bn-6[0][0]     
                                                                 class_net/class-2-bn-6[0][0]     
                                                                 class_net/class-0-bn-7[0][0]     
                                                                 class_net/class-1-bn-7[0][0]     
                                                                 class_net/class-2-bn-7[0][0]     
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode6/op_afte (None, 8, 8, 64)     4736        activation_22[0][0]              
__________________________________________________________________________________________________
box_net/box-0-bn-3 (BatchNormal (None, 64, 64, 64)   256         box_net/box-0[0][0]              
__________________________________________________________________________________________________
class_net/class-1 (SeparableCon multiple             4736        lambda_1[0][0]                   
                                                                 lambda_1[3][0]                   
                                                                 lambda_1[6][0]                   
                                                                 lambda_1[9][0]                   
                                                                 lambda_1[12][0]                  
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode6/op_afte (None, 8, 8, 64)     256         fpn_cells/cell_2/fnode6/op_after_
__________________________________________________________________________________________________
lambda (Lambda)                 multiple             0           box_net/box-0-bn-3[0][0]         
                                                                 box_net/box-1-bn-3[0][0]         
                                                                 box_net/box-2-bn-3[0][0]         
                                                                 box_net/box-0-bn-4[0][0]         
                                                                 box_net/box-1-bn-4[0][0]         
                                                                 box_net/box-2-bn-4[0][0]         
                                                                 box_net/box-0-bn-5[0][0]         
                                                                 box_net/box-1-bn-5[0][0]         
                                                                 box_net/box-2-bn-5[0][0]         
                                                                 box_net/box-0-bn-6[0][0]         
                                                                 box_net/box-1-bn-6[0][0]         
                                                                 box_net/box-2-bn-6[0][0]         
                                                                 box_net/box-0-bn-7[0][0]         
                                                                 box_net/box-1-bn-7[0][0]         
                                                                 box_net/box-2-bn-7[0][0]         
__________________________________________________________________________________________________
class_net/class-1-bn-3 (BatchNo (None, 64, 64, 64)   256         class_net/class-1[0][0]          
__________________________________________________________________________________________________
max_pooling2d_11 (MaxPooling2D) (None, 4, 4, 64)     0           fpn_cells/cell_2/fnode6/op_after_
__________________________________________________________________________________________________
box_net/box-1 (SeparableConv2D) multiple             4736        lambda[0][0]                     
                                                                 lambda[3][0]                     
                                                                 lambda[6][0]                     
                                                                 lambda[9][0]                     
                                                                 lambda[12][0]                    
__________________________________________________________________________________________________
rotation_net/rotation-2-gn-4 (G (None, 32, 32, 64)   128         rotation_net/rotation-2[1][0]    
__________________________________________________________________________________________________
rotation_net/rotation-0-gn-5 (G (None, 16, 16, 64)   128         rotation_net/rotation-0[2][0]    
__________________________________________________________________________________________________
translation_net/translation-2-g (None, 16, 16, 64)   128         translation_net/translation-2[2][
__________________________________________________________________________________________________
translation_net/translation-0-g (None, 8, 8, 64)     128         translation_net/translation-0[3][
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode7/add (wB (None, 4, 4, 64)     2           fpn_cells/cell_1/fnode7/op_after_
                                                                 max_pooling2d_11[0][0]           
__________________________________________________________________________________________________
box_net/box-1-bn-3 (BatchNormal (None, 64, 64, 64)   256         box_net/box-1[0][0]              
__________________________________________________________________________________________________
class_net/class-2 (SeparableCon multiple             4736        lambda_1[1][0]                   
                                                                 lambda_1[4][0]                   
                                                                 lambda_1[7][0]                   
                                                                 lambda_1[10][0]                  
                                                                 lambda_1[13][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 4, 4, 64)     0           fpn_cells/cell_2/fnode7/add[0][0]
__________________________________________________________________________________________________
translation_net/translation-xy- multiple             1746        lambda_5[2][0]                   
                                                                 lambda_5[5][0]                   
                                                                 lambda_5[8][0]                   
                                                                 lambda_5[11][0]                  
                                                                 lambda_5[14][0]                  
__________________________________________________________________________________________________
translation_net/translation-z-i multiple             1161        lambda_5[2][0]                   
                                                                 lambda_5[5][0]                   
                                                                 lambda_5[8][0]                   
                                                                 lambda_5[11][0]                  
                                                                 lambda_5[14][0]                  
__________________________________________________________________________________________________
class_net/class-2-bn-3 (BatchNo (None, 64, 64, 64)   256         class_net/class-2[0][0]          
__________________________________________________________________________________________________
class_net/class-0-bn-4 (BatchNo (None, 32, 32, 64)   256         class_net/class-0[1][0]          
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode7/op_afte (None, 4, 4, 64)     4736        activation_23[0][0]              
__________________________________________________________________________________________________
box_net/box-2 (SeparableConv2D) multiple             4736        lambda[1][0]                     
                                                                 lambda[4][0]                     
                                                                 lambda[7][0]                     
                                                                 lambda[10][0]                    
                                                                 lambda[13][0]                    
__________________________________________________________________________________________________
rotation_net/rotation-1-gn-5 (G (None, 16, 16, 64)   128         rotation_net/rotation-1[2][0]    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     multiple             0           lambda_5[2][0]                   
                                                                 translation_net/translation-xy-in
                                                                 translation_net/translation-z-ini
                                                                 lambda_5[5][0]                   
                                                                 translation_net/translation-xy-in
                                                                 translation_net/translation-z-ini
                                                                 lambda_5[8][0]                   
                                                                 translation_net/translation-xy-in
                                                                 translation_net/translation-z-ini
                                                                 lambda_5[11][0]                  
                                                                 translation_net/translation-xy-in
                                                                 translation_net/translation-z-ini
                                                                 lambda_5[14][0]                  
                                                                 translation_net/translation-xy-in
                                                                 translation_net/translation-z-ini
__________________________________________________________________________________________________
translation_net/translation-1-g (None, 8, 8, 64)     128         translation_net/translation-1[3][
__________________________________________________________________________________________________
fpn_cells/cell_2/fnode7/op_afte (None, 4, 4, 64)     256         fpn_cells/cell_2/fnode7/op_after_
__________________________________________________________________________________________________
box_net/box-2-bn-3 (BatchNormal (None, 64, 64, 64)   256         box_net/box-2[0][0]              
__________________________________________________________________________________________________
box_net/box-0-bn-4 (BatchNormal (None, 32, 32, 64)   256         box_net/box-0[1][0]              
__________________________________________________________________________________________________
iterative_translation_subnet/it multiple             6707        concatenate_1[0][0]              
                                                                 concatenate_1[1][0]              
                                                                 concatenate_1[2][0]              
                                                                 concatenate_1[3][0]              
                                                                 concatenate_1[4][0]              
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 64, 64, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-1-bn-4 (BatchNo (None, 32, 32, 64)   256         class_net/class-1[1][0]          
__________________________________________________________________________________________________
rotation_net/rotation-2-gn-5 (G (None, 16, 16, 64)   128         rotation_net/rotation-2[2][0]    
__________________________________________________________________________________________________
rotation_net/rotation-0-gn-6 (G (None, 8, 8, 64)     128         rotation_net/rotation-0[3][0]    
__________________________________________________________________________________________________
lambda_4 (Lambda)               multiple             0           iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
                                                                 iterative_translation_subnet/iter
__________________________________________________________________________________________________
translation_net/translation-2-g (None, 8, 8, 64)     128         translation_net/translation-2[3][
__________________________________________________________________________________________________
translation_net/translation-0-g (None, 4, 4, 64)     128         translation_net/translation-0[4][
__________________________________________________________________________________________________
box_net/box-1-bn-4 (BatchNormal (None, 32, 32, 64)   256         box_net/box-1[1][0]              
__________________________________________________________________________________________________
iterative_translation_subnet/it multiple             4736        lambda_4[0][0]                   
                                                                 lambda_4[2][0]                   
                                                                 lambda_4[4][0]                   
                                                                 lambda_4[6][0]                   
                                                                 lambda_4[8][0]                   
__________________________________________________________________________________________________
rotation_net/rotation-init-pred multiple             2331        lambda_3[2][0]                   
                                                                 lambda_3[5][0]                   
                                                                 lambda_3[8][0]                   
                                                                 lambda_3[11][0]                  
                                                                 lambda_3[14][0]                  
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 64, 64, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 32, 32, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-2-bn-4 (BatchNo (None, 32, 32, 64)   256         class_net/class-2[1][0]          
__________________________________________________________________________________________________
class_net/class-0-bn-5 (BatchNo (None, 16, 16, 64)   256         class_net/class-0[2][0]          
__________________________________________________________________________________________________
concatenate (Concatenate)       multiple             0           lambda_3[2][0]                   
                                                                 rotation_net/rotation-init-predic
                                                                 lambda_3[5][0]                   
                                                                 rotation_net/rotation-init-predic
                                                                 lambda_3[8][0]                   
                                                                 rotation_net/rotation-init-predic
                                                                 lambda_3[11][0]                  
                                                                 rotation_net/rotation-init-predic
                                                                 lambda_3[14][0]                  
                                                                 rotation_net/rotation-init-predic
__________________________________________________________________________________________________
rotation_net/rotation-1-gn-6 (G (None, 8, 8, 64)     128         rotation_net/rotation-1[3][0]    
__________________________________________________________________________________________________
translation_net/translation-1-g (None, 4, 4, 64)     128         translation_net/translation-1[4][
__________________________________________________________________________________________________
box_net/box-2-bn-4 (BatchNormal (None, 32, 32, 64)   256         box_net/box-2[1][0]              
__________________________________________________________________________________________________
box_net/box-0-bn-5 (BatchNormal (None, 16, 16, 64)   256         box_net/box-0[2][0]              
__________________________________________________________________________________________________
iterative_rotation_subnet/itera multiple             6707        concatenate[0][0]                
                                                                 concatenate[1][0]                
                                                                 concatenate[2][0]                
                                                                 concatenate[3][0]                
                                                                 concatenate[4][0]                
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 64, 64, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 32, 32, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 16, 16, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-1-bn-5 (BatchNo (None, 16, 16, 64)   256         class_net/class-1[2][0]          
__________________________________________________________________________________________________
lambda_2 (Lambda)               multiple             0           iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
                                                                 iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
rotation_net/rotation-2-gn-6 (G (None, 8, 8, 64)     128         rotation_net/rotation-2[3][0]    
__________________________________________________________________________________________________
rotation_net/rotation-0-gn-7 (G (None, 4, 4, 64)     128         rotation_net/rotation-0[4][0]    
__________________________________________________________________________________________________
translation_net/translation-2-g (None, 4, 4, 64)     128         translation_net/translation-2[4][
__________________________________________________________________________________________________
box_net/box-1-bn-5 (BatchNormal (None, 16, 16, 64)   256         box_net/box-1[2][0]              
__________________________________________________________________________________________________
iterative_rotation_subnet/itera multiple             4736        lambda_2[0][0]                   
                                                                 lambda_2[2][0]                   
                                                                 lambda_2[4][0]                   
                                                                 lambda_2[6][0]                   
                                                                 lambda_2[8][0]                   
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 64, 64, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 32, 32, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 16, 16, 64)   128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 8, 8, 64)     128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-2-bn-5 (BatchNo (None, 16, 16, 64)   256         class_net/class-2[2][0]          
__________________________________________________________________________________________________
class_net/class-0-bn-6 (BatchNo (None, 8, 8, 64)     256         class_net/class-0[3][0]          
__________________________________________________________________________________________________
rotation_net/rotation-1-gn-7 (G (None, 4, 4, 64)     128         rotation_net/rotation-1[4][0]    
__________________________________________________________________________________________________
box_net/box-2-bn-5 (BatchNormal (None, 16, 16, 64)   256         box_net/box-2[2][0]              
__________________________________________________________________________________________________
box_net/box-0-bn-6 (BatchNormal (None, 8, 8, 64)     256         box_net/box-0[3][0]              
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 32, 32, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 16, 16, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 8, 8, 64)     128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 4, 4, 64)     128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-1-bn-6 (BatchNo (None, 8, 8, 64)     256         class_net/class-1[3][0]          
__________________________________________________________________________________________________
rotation_net/rotation-2-gn-7 (G (None, 4, 4, 64)     128         rotation_net/rotation-2[4][0]    
__________________________________________________________________________________________________
box_net/box-1-bn-6 (BatchNormal (None, 8, 8, 64)     256         box_net/box-1[3][0]              
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 16, 16, 64)   128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 8, 8, 64)     128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_translation_subnet/it (None, 4, 4, 64)     128         iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-2-bn-6 (BatchNo (None, 8, 8, 64)     256         class_net/class-2[3][0]          
__________________________________________________________________________________________________
class_net/class-0-bn-7 (BatchNo (None, 4, 4, 64)     256         class_net/class-0[4][0]          
__________________________________________________________________________________________________
box_net/box-2-bn-6 (BatchNormal (None, 8, 8, 64)     256         box_net/box-2[3][0]              
__________________________________________________________________________________________________
box_net/box-0-bn-7 (BatchNormal (None, 4, 4, 64)     256         box_net/box-0[4][0]              
__________________________________________________________________________________________________
iterative_translation_subnet/it multiple             1746        lambda_4[1][0]                   
                                                                 lambda_4[3][0]                   
                                                                 lambda_4[5][0]                   
                                                                 lambda_4[7][0]                   
                                                                 lambda_4[9][0]                   
__________________________________________________________________________________________________
iterative_translation_subnet/it multiple             1161        lambda_4[1][0]                   
                                                                 lambda_4[3][0]                   
                                                                 lambda_4[5][0]                   
                                                                 lambda_4[7][0]                   
                                                                 lambda_4[9][0]                   
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 8, 8, 64)     128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 4, 4, 64)     128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
add_1 (Add)                     multiple             0           translation_net/translation-xy-in
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-z-ini
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-xy-in
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-z-ini
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-xy-in
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-z-ini
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-xy-in
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-z-ini
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-xy-in
                                                                 iterative_translation_subnet/iter
                                                                 translation_net/translation-z-ini
                                                                 iterative_translation_subnet/iter
__________________________________________________________________________________________________
class_net/class-1-bn-7 (BatchNo (None, 4, 4, 64)     256         class_net/class-1[4][0]          
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, None, 2)      0           add_1[0][0]                      
                                                                 add_1[2][0]                      
                                                                 add_1[4][0]                      
                                                                 add_1[6][0]                      
                                                                 add_1[8][0]                      
__________________________________________________________________________________________________
reshape_4 (Reshape)             (None, None, 1)      0           add_1[1][0]                      
                                                                 add_1[3][0]                      
                                                                 add_1[5][0]                      
                                                                 add_1[7][0]                      
                                                                 add_1[9][0]                      
__________________________________________________________________________________________________
box_net/box-1-bn-7 (BatchNormal (None, 4, 4, 64)     256         box_net/box-1[4][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, None, 3)      0           reshape_3[0][0]                  
                                                                 reshape_4[0][0]                  
                                                                 reshape_3[1][0]                  
                                                                 reshape_4[1][0]                  
                                                                 reshape_3[2][0]                  
                                                                 reshape_4[2][0]                  
                                                                 reshape_3[3][0]                  
                                                                 reshape_4[3][0]                  
                                                                 reshape_3[4][0]                  
                                                                 reshape_4[4][0]                  
__________________________________________________________________________________________________
iterative_rotation_subnet/itera (None, 4, 4, 64)     128         iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
translation_raw_outputs (Concat (None, None, 3)      0           concatenate_2[0][0]              
                                                                 concatenate_2[1][0]              
                                                                 concatenate_2[2][0]              
                                                                 concatenate_2[3][0]              
                                                                 concatenate_2[4][0]              
__________________________________________________________________________________________________
class_net/class-2-bn-7 (BatchNo (None, 4, 4, 64)     256         class_net/class-2[4][0]          
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, None)]       0           translation_raw_outputs[0][0]    
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, None)]       0           translation_raw_outputs[0][0]    
__________________________________________________________________________________________________
box_net/box-2-bn-7 (BatchNormal (None, 4, 4, 64)     256         box_net/box-2[4][0]              
__________________________________________________________________________________________________
iterative_rotation_subnet/itera multiple             2331        lambda_2[1][0]                   
                                                                 lambda_2[3][0]                   
                                                                 lambda_2[5][0]                   
                                                                 lambda_2[7][0]                   
                                                                 lambda_2[9][0]                   
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, 49104)]      0           tf_op_layer_translation_regressio
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, 49104)]      0           tf_op_layer_translation_regressio
__________________________________________________________________________________________________
class_net/class-predict (Separa multiple             1161        lambda_1[2][0]                   
                                                                 lambda_1[5][0]                   
                                                                 lambda_1[8][0]                   
                                                                 lambda_1[11][0]                  
                                                                 lambda_1[14][0]                  
__________________________________________________________________________________________________
add (Add)                       multiple             0           rotation_net/rotation-init-predic
                                                                 iterative_rotation_subnet/iterati
                                                                 rotation_net/rotation-init-predic
                                                                 iterative_rotation_subnet/iterati
                                                                 rotation_net/rotation-init-predic
                                                                 iterative_rotation_subnet/iterati
                                                                 rotation_net/rotation-init-predic
                                                                 iterative_rotation_subnet/iterati
                                                                 rotation_net/rotation-init-predic
                                                                 iterative_rotation_subnet/iterati
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, 49104)]      0           tf_op_layer_translation_regressio
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, 49104)]      0           tf_op_layer_translation_regressio
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, None)]       0           translation_raw_outputs[0][0]    
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 6)]          0                                            
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, None, 1)      0           class_net/class-predict[0][0]    
                                                                 class_net/class-predict[1][0]    
                                                                 class_net/class-predict[2][0]    
                                                                 class_net/class-predict[3][0]    
                                                                 class_net/class-predict[4][0]    
__________________________________________________________________________________________________
box_net/box-predict (SeparableC multiple             2916        lambda[2][0]                     
                                                                 lambda[5][0]                     
                                                                 lambda[8][0]                     
                                                                 lambda[11][0]                    
                                                                 lambda[14][0]                    
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, None, 3)      0           add[0][0]                        
                                                                 add[1][0]                        
                                                                 add[2][0]                        
                                                                 add[3][0]                        
                                                                 add[4][0]                        
__________________________________________________________________________________________________
tf_op_layer_translation_regress [(None, 49104, 3)]   0           tf_op_layer_translation_regressio
                                                                 tf_op_layer_translation_regressio
                                                                 tf_op_layer_translation_regressio
__________________________________________________________________________________________________
tf_op_layer_strided_slice (Tens [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_strided_slice_1 (Te [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_strided_slice_5 (Te [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_strided_slice_2 (Te [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_strided_slice_3 (Te [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_strided_slice_4 (Te [(None,)]            0           input_2[0][0]                    
__________________________________________________________________________________________________
activation_24 (Activation)      (None, None, 1)      0           reshape_1[0][0]                  
                                                                 reshape_1[1][0]                  
                                                                 reshape_1[2][0]                  
                                                                 reshape_1[3][0]                  
                                                                 reshape_1[4][0]                  
__________________________________________________________________________________________________
reshape (Reshape)               (None, None, 4)      0           box_net/box-predict[0][0]        
                                                                 box_net/box-predict[1][0]        
                                                                 box_net/box-predict[2][0]        
                                                                 box_net/box-predict[3][0]        
                                                                 box_net/box-predict[4][0]        
__________________________________________________________________________________________________
rotation (Concatenate)          (None, None, 3)      0           reshape_2[0][0]                  
                                                                 reshape_2[1][0]                  
                                                                 reshape_2[2][0]                  
                                                                 reshape_2[3][0]                  
                                                                 reshape_2[4][0]                  
__________________________________________________________________________________________________
translation (CalculateTxTy)     (None, 49104, 3)     0           tf_op_layer_translation_regressio
__________________________________________________________________________________________________
classification (Concatenate)    (None, None, 1)      0           activation_24[0][0]              
                                                                 activation_24[1][0]              
                                                                 activation_24[2][0]              
                                                                 activation_24[3][0]              
                                                                 activation_24[4][0]              
__________________________________________________________________________________________________
regression (Concatenate)        (None, None, 4)      0           reshape[0][0]                    
                                                                 reshape[1][0]                    
                                                                 reshape[2][0]                    
                                                                 reshape[3][0]                    
                                                                 reshape[4][0]                    
__________________________________________________________________________________________________
transformation (Lambda)         (None, 49104, 6)     0           rotation[0][0]                   
                                                                 translation[0][0]                
==================================================================================================
Total params: 3,943,316
Trainable params: 3,852,116
Non-trainable params: 91,200
__________________________________________________________________________________________________






Model: "box_net"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
box_net/box-0 (SeparableConv multiple                  4736      
_________________________________________________________________
box_net/box-1 (SeparableConv multiple                  4736      
_________________________________________________________________
box_net/box-2 (SeparableConv multiple                  4736      
_________________________________________________________________
box_net/box-predict (Separab multiple                  2916      
_________________________________________________________________
box_net/box-0-bn-3 (BatchNor (None, 64, 64, 64)        256       
_________________________________________________________________
box_net/box-0-bn-4 (BatchNor (None, 32, 32, 64)        256       
_________________________________________________________________
box_net/box-0-bn-5 (BatchNor (None, 16, 16, 64)        256       
_________________________________________________________________
box_net/box-0-bn-6 (BatchNor (None, 8, 8, 64)          256       
_________________________________________________________________
box_net/box-0-bn-7 (BatchNor (None, 4, 4, 64)          256       
_________________________________________________________________
box_net/box-1-bn-3 (BatchNor (None, 64, 64, 64)        256       
_________________________________________________________________
box_net/box-1-bn-4 (BatchNor (None, 32, 32, 64)        256       
_________________________________________________________________
box_net/box-1-bn-5 (BatchNor (None, 16, 16, 64)        256       
_________________________________________________________________
box_net/box-1-bn-6 (BatchNor (None, 8, 8, 64)          256       
_________________________________________________________________
box_net/box-1-bn-7 (BatchNor (None, 4, 4, 64)          256       
_________________________________________________________________
box_net/box-2-bn-3 (BatchNor (None, 64, 64, 64)        256       
_________________________________________________________________
box_net/box-2-bn-4 (BatchNor (None, 32, 32, 64)        256       
_________________________________________________________________
box_net/box-2-bn-5 (BatchNor (None, 16, 16, 64)        256       
_________________________________________________________________
box_net/box-2-bn-6 (BatchNor (None, 8, 8, 64)          256       
_________________________________________________________________
box_net/box-2-bn-7 (BatchNor (None, 4, 4, 64)          256       
_________________________________________________________________
lambda (Lambda)              multiple                  0         
_________________________________________________________________
reshape (Reshape)            (None, None, 4)           0         
=================================================================
Total params: 20,964
Trainable params: 17,124
Non-trainable params: 3,840
_________________________________________________________________






Model: "class_net"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
class_net/class-0 (Separable multiple                  4736      
_________________________________________________________________
class_net/class-1 (Separable multiple                  4736      
_________________________________________________________________
class_net/class-2 (Separable multiple                  4736      
_________________________________________________________________
class_net/class-predict (Sep multiple                  1161      
_________________________________________________________________
class_net/class-0-bn-3 (Batc (None, 64, 64, 64)        256       
_________________________________________________________________
class_net/class-0-bn-4 (Batc (None, 32, 32, 64)        256       
_________________________________________________________________
class_net/class-0-bn-5 (Batc (None, 16, 16, 64)        256       
_________________________________________________________________
class_net/class-0-bn-6 (Batc (None, 8, 8, 64)          256       
_________________________________________________________________
class_net/class-0-bn-7 (Batc (None, 4, 4, 64)          256       
_________________________________________________________________
class_net/class-1-bn-3 (Batc (None, 64, 64, 64)        256       
_________________________________________________________________
class_net/class-1-bn-4 (Batc (None, 32, 32, 64)        256       
_________________________________________________________________
class_net/class-1-bn-5 (Batc (None, 16, 16, 64)        256       
_________________________________________________________________
class_net/class-1-bn-6 (Batc (None, 8, 8, 64)          256       
_________________________________________________________________
class_net/class-1-bn-7 (Batc (None, 4, 4, 64)          256       
_________________________________________________________________
class_net/class-2-bn-3 (Batc (None, 64, 64, 64)        256       
_________________________________________________________________
class_net/class-2-bn-4 (Batc (None, 32, 32, 64)        256       
_________________________________________________________________
class_net/class-2-bn-5 (Batc (None, 16, 16, 64)        256       
_________________________________________________________________
class_net/class-2-bn-6 (Batc (None, 8, 8, 64)          256       
_________________________________________________________________
class_net/class-2-bn-7 (Batc (None, 4, 4, 64)          256       
_________________________________________________________________
lambda_1 (Lambda)            multiple                  0         
_________________________________________________________________
reshape_1 (Reshape)          (None, None, 1)           0         
_________________________________________________________________
activation_24 (Activation)   (None, None, 1)           0         2021-04-01 02:06:46.980639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-01 02:06:47.503224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-04-01 02:06:49.212855: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.
2021-04-01 02:06:49.213530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.0

=================================================================
Total params: 19,209
Trainable params: 15,369
Non-trainable params: 3,840
_________________________________________________________________






Model: "rotation_net"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
rotation_net/rotation-0 (Sep multiple                  4736      
_________________________________________________________________
rotation_net/rotation-1 (Sep multiple                  4736      
_________________________________________________________________
rotation_net/rotation-2 (Sep multiple                  4736      
_________________________________________________________________
rotation_net/rotation-init-p multiple                  2331      
_________________________________________________________________
rotation_net/rotation-0-gn-3 (None, 64, 64, 64)        128       
_________________________________________________________________
rotation_net/rotation-0-gn-4 (None, 32, 32, 64)        128       
_________________________________________________________________
rotation_net/rotation-0-gn-5 (None, 16, 16, 64)        128       
_________________________________________________________________
rotation_net/rotation-0-gn-6 (None, 8, 8, 64)          128       
_________________________________________________________________
rotation_net/rotation-0-gn-7 (None, 4, 4, 64)          128       
_________________________________________________________________
rotation_net/rotation-1-gn-3 (None, 64, 64, 64)        128       
_________________________________________________________________
rotation_net/rotation-1-gn-4 (None, 32, 32, 64)        128       
_________________________________________________________________
rotation_net/rotation-1-gn-5 (None, 16, 16, 64)        128       
_________________________________________________________________
rotation_net/rotation-1-gn-6 (None, 8, 8, 64)          128       
_________________________________________________________________
rotation_net/rotation-1-gn-7 (None, 4, 4, 64)          128       
_________________________________________________________________
rotation_net/rotation-2-gn-3 (None, 64, 64, 64)        128       
_________________________________________________________________
rotation_net/rotation-2-gn-4 (None, 32, 32, 64)        128       
_________________________________________________________________
rotation_net/rotation-2-gn-5 (None, 16, 16, 64)        128       
_________________________________________________________________
rotation_net/rotation-2-gn-6 (None, 8, 8, 64)          128       
_________________________________________________________________
rotation_net/rotation-2-gn-7 (None, 4, 4, 64)          128       
_________________________________________________________________
iterative_rotation_subnet (I multiple                  15054     
_________________________________________________________________
lambda_3 (Lambda)            multiple                  0         
_________________________________________________________________
reshape_2 (Reshape)          (None, None, 3)           0         
_________________________________________________________________
add (Add)                    multiple                  0         
_________________________________________________________________
concatenate (Concatenate)    multiple                  0         
=================================================================
Total params: 33,513
Trainable params: 33,513
Non-trainable params: 0
_________________________________________________________________






Model: "translation_net"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
translation_net/translation- multiple                  4736      
_________________________________________________________________
translation_net/translation- multiple                  4736      
_________________________________________________________________
translation_net/translation- multiple                  4736      
_________________________________________________________________
translation_net/translation- multiple                  1746      
_________________________________________________________________
translation_net/translation- multiple                  1161      
_________________________________________________________________
translation_net/translation- (None, 64, 64, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 32, 32, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 16, 16, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 8, 8, 64)          128       
_________________________________________________________________
translation_net/translation- (None, 4, 4, 64)          128       
_________________________________________________________________
translation_net/translation- (None, 64, 64, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 32, 32, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 16, 16, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 8, 8, 64)          128       
_________________________________________________________________
translation_net/translation- (None, 4, 4, 64)          128       
_________________________________________________________________
translation_net/translation- (None, 64, 64, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 32, 32, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 16, 16, 64)        128       
_________________________________________________________________
translation_net/translation- (None, 8, 8, 64)          128       
_________________________________________________________________
translation_net/translation- (None, 4, 4, 64)          128       
_________________________________________________________________
iterative_translation_subnet multiple                  15630     
_________________________________________________________________
lambda_5 (Lambda)            multiple                  0         
_________________________________________________________________
reshape_3 (Reshape)          (None, None, 2)           0         
_________________________________________________________________
reshape_4 (Reshape)          (None, None, 1)           0         
_________________________________________________________________
add_1 (Add)                  multiple                  0         
_________________________________________________________________
concatenate_1 (Concatenate)  multiple                  0         
_________________________________________________________________
concatenate_2 (Concatenate)  (None, None, 3)           0         
=================================================================
Total params: 34,665
Trainable params: 34,665
Non-trainable params: 0
_________________________________________________________________



Done!
Loading model, this may take a second...
Skipping loading of weights for layer class_net/class-predict due to mismatch in shape ((1, 1, 64, 9) vs (1, 1, 64, 810)).
Skipping loading of weights for layer class_net/class-predict due to mismatch in shape ((9,) vs (810,)).

Done!
Epoch 1/500
   1/1790 [..............................] - ETA: 19:14:48 - loss: 1079.4396 - classification_loss: 1071.2625 - regression_loss: 0.2709 - transformation_loss: 395.31022021-04-01 02:06:49.702687: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 15531 kernel records, 689 memcpy records.
   2/1790 [..............................] - ETA: 9:48:03 - loss: 625.8455 - classification_loss: 613.1633 - regression_loss: 0.2596 - transformation_loss: 621.1261      3/1790 [..............................] - ETA: 6:34:39 - loss: 431.6816 - classification_loss: 418.9242 - regression_loss: 0.2967 - transformation_loss: 623.0334   4/1790 [..............................] - ETA: 4:57:54 - loss: 332.3912 - classification_loss: 319.7003 - regression_loss: 0.3306 - transformation_loss: 618.0118   5/1790 [..............................] - ETA: 3:59:49 - loss: 267.3496 - classification_loss: 256.6122 - regression_loss: 0.3269 - transformation_loss: 520.5231   6/1790 [..............................] - ETA: 3:21:08 - loss: 225.3648 - classification_loss: 214.2608 - regression_loss: 0.3295 - transformation_loss: 538.7267   7/1790 [..............................] - ETA: 2:53:30 - loss: 194.8056 - classification_loss: 183.8578 - regression_loss: 0.2964 - transformation_loss: 532.5682   8/1790 [..............................] - ETA: 2:32:47 - loss: 172.2729 - classification_loss: 161.0769 - regression_loss: 0.2796 - transformation_loss: 545.8156   9/1790 [..............................] - ETA: 2:16:43 - loss: 154.2779 - classification_loss: 143.3432 - regression_loss: 0.2669 - transformation_loss: 533.3882  10/1790 [..............................] - ETA: 2:03:47 - loss: 139.8575 - classification_loss: 129.1437 - regression_loss: 0.2636 - transformation_loss: 522.5091  11/1790 [..............................] - ETA: 1:53:16 - loss: 128.4609 - classification_loss: 117.5414 - regression_loss: 0.2493 - transformation_loss: 533.5172  12/1790 [..............................] - ETA: 1:44:30 - loss: 118.3381 - classification_loss: 107.8634 - regression_loss: 0.2483 - transformation_loss: 511.3184  13/1790 [..............................] - ETA: 1:37:02 - loss: 109.7390 - classification_loss: 99.6545 - regression_loss: 0.2318 - transformation_loss: 492.6351   14/1790 [..............................] - ETA: 1:30:37 - loss: 102.5405 - classification_loss: 92.6244 - regression_loss: 0.2292 - transformation_loss: 484.3447  15/1790 [..............................] - ETA: 1:25:24 - loss: 96.3562 - classification_loss: 86.5258 - regression_loss: 0.2279 - transformation_loss: 480.1250   16/1790 [..............................] - ETA: 1:20:34 - loss: 91.3841 - classification_loss: 81.2000 - regression_loss: 0.2393 - transformation_loss: 497.2410  17/1790 [..............................] - ETA: 1:16:15 - loss: 86.6693 - classification_loss: 76.5006 - regression_loss: 0.2457 - transformation_loss: 496.1528  18/1790 [..............................] - ETA: 1:12:26 - loss: 82.2903 - classification_loss: 72.3250 - regression_loss: 0.2430 - transformation_loss: 486.1147  19/1790 [..............................] - ETA: 1:09:00 - loss: 78.3509 - classification_loss: 68.5753 - regression_loss: 0.2386 - transformation_loss: 476.8497  20/1790 [..............................] - ETA: 1:05:56 - loss: 75.0006 - classification_loss: 65.2152 - regression_loss: 0.2435 - transformation_loss: 477.0974  21/1790 [..............................] - ETA: 1:03:11 - loss: 71.9785 - classification_loss: 62.1695 - regression_loss: 0.2445 - transformation_loss: 478.2271  22/1790 [..............................] - ETA: 1:00:40 - loss: 68.8568 - classification_loss: 59.3941 - regression_loss: 0.2507 - transformation_loss: 460.6009  23/1790 [..............................] - ETA: 58:20 - loss: 66.0834 - classification_loss: 56.8664 - regression_loss: 0.2466 - transformation_loss: 448.5185    24/1790 [..............................] - ETA: 56:14 - loss: 63.8118 - classification_loss: 54.5562 - regression_loss: 0.2525 - transformation_loss: 450.1587  25/1790 [..............................] - ETA: 54:15 - loss: 62.3282 - classification_loss: 52.4629 - regression_loss: 0.2986 - transformation_loss: 478.3353  26/1790 [..............................] - ETA: 52:28 - loss: 60.3877 - classification_loss: 50.4968 - regression_loss: 0.2943 - transformation_loss: 479.8271  27/1790 [..............................] - ETA: 50:50 - loss: 58.5681 - classification_loss: 48.6722 - regression_loss: 0.2971 - transformation_loss: 479.9413  28/1790 [..............................] - ETA: 49:18 - loss: 56.7406 - classification_loss: 46.9783 - regression_loss: 0.2979 - transformation_loss: 473.2173  29/1790 [..............................] - ETA: 47:52 - loss: 54.9752 - classification_loss: 45.4022 - regression_loss: 0.2958 - transformation_loss: 463.8604  30/1790 [..............................] - ETA: 46:31 - loss: 53.3003 - classification_loss: 43.9284 - regression_loss: 0.2991 - transformation_loss: 453.6391  31/1790 [..............................] - ETA: 45:15 - loss: 51.9742 - classification_loss: 42.5494 - regression_loss: 0.3039 - transformation_loss: 456.0453  32/1790 [..............................] - ETA: 44:05 - loss: 50.4869 - classification_loss: 41.2538 - regression_loss: 0.3015 - transformation_loss: 446.5840  33/1790 [..............................] - ETA: 43:00 - loss: 49.1721 - classification_loss: 40.0404 - regression_loss: 0.3031 - transformation_loss: 441.4309  34/1790 [..............................] - ETA: 41:57 - loss: 47.9434 - classification_loss: 38.8978 - regression_loss: 0.3030 - transformation_loss: 437.1325  35/1790 [..............................] - ETA: 40:57 - loss: 46.7320 - classification_loss: 37.8193 - regression_loss: 0.3002 - transformation_loss: 430.6199  36/1790 [..............................] - ETA: 40:00 - loss: 45.9193 - classification_loss: 36.8495 - regression_loss: 0.3095 - transformation_loss: 438.0118  37/1790 [..............................] - ETA: 39:08 - loss: 44.8564 - classification_loss: 35.8870 - regression_loss: 0.3060 - transformation_loss: 433.1696  38/1790 [..............................] - ETA: 38:18 - loss: 43.7553 - classification_loss: 34.9715 - regression_loss: 0.3022 - transformation_loss: 424.0764  39/1790 [..............................] - ETA: 37:30 - loss: 42.7286 - classification_loss: 34.1006 - regression_loss: 0.3001 - transformation_loss: 416.3930  40/1790 [..............................] - ETA: 36:45 - loss: 41.7458 - classification_loss: 33.2695 - regression_loss: 0.2974 - transformation_loss: 408.9464  41/1790 [..............................] - ETA: 36:03 - loss: 40.8612 - classification_loss: 32.4867 - regression_loss: 0.2944 - transformation_loss: 404.0063  42/1790 [..............................] - ETA: 35:22 - loss: 40.0045 - classification_loss: 31.7392 - regression_loss: 0.2913 - transformation_loss: 398.7028  43/1790 [..............................] - ETA: 34:42 - loss: 39.2003 - classification_loss: 31.0264 - regression_loss: 0.2927 - transformation_loss: 394.0639  44/1790 [..............................] - ETA: 34:05 - loss: 38.5889 - classification_loss: 30.3482 - regression_loss: 0.2953 - transformation_loss: 397.2683  45/1790 [..............................] - ETA: 33:30 - loss: 37.7937 - classification_loss: 29.6974 - regression_loss: 0.2948 - transformation_loss: 390.0731  46/1790 [..............................] - ETA: 32:56 - loss: 37.1361 - classification_loss: 29.0753 - regression_loss: 0.2966 - transformation_loss: 388.2051  47/1790 [..............................] - ETA: 32:24 - loss: 36.4200 - classification_loss: 28.4776 - regression_loss: 0.2980 - transformation_loss: 382.2154  48/1790 [..............................] - ETA: 31:52 - loss: 35.7492 - classification_loss: 27.9057 - regression_loss: 0.2952 - transformation_loss: 377.4136  49/1790 [..............................] - ETA: 31:22 - loss: 35.0805 - classification_loss: 27.3548 - regression_loss: 0.2954 - transformation_loss: 371.5141  50/1790 [..............................] - ETA: 30:54 - loss: 34.4411 - classification_loss: 26.8275 - regression_loss: 0.2928 - transformation_loss: 366.0413  51/1790 [..............................] - ETA: 30:25 - loss: 33.8827 - classification_loss: 26.3309 - regression_loss: 0.2930 - transformation_loss: 362.9396  52/1790 [..............................] - ETA: 29:58 - loss: 33.3118 - classification_loss: 25.8451 - regression_loss: 0.2917 - transformation_loss: 358.7501  53/1790 [..............................] - ETA: 29:32 - loss: 32.8029 - classification_loss: 25.3761 - regression_loss: 0.2952 - transformation_loss: 356.5797  54/1790 [..............................] - ETA: 29:07 - loss: 32.2789 - classification_loss: 24.9279 - regression_loss: 0.2917 - transformation_loss: 352.9649  55/1790 [..............................] - ETA: 28:43 - loss: 31.7549 - classification_loss: 24.4901 - regression_loss: 0.2901 - transformation_loss: 348.7327  56/1790 [..............................] - ETA: 28:19 - loss: 31.2468 - classification_loss: 24.0682 - regression_loss: 0.2890 - transformation_loss: 344.4805  57/1790 [..............................] - ETA: 27:57 - loss: 30.7595 - classification_loss: 23.6637 - regression_loss: 0.2878 - transformation_loss: 340.3993  58/1790 [..............................] - ETA: 27:36 - loss: 30.2794 - classification_loss: 23.2697 - regression_loss: 0.2889 - transformation_loss: 336.0432  59/1790 [..............................] - ETA: 27:14 - loss: 29.9713 - classification_loss: 22.8964 - regression_loss: 0.2923 - transformation_loss: 339.1304  60/1790 [>.............................] - ETA: 26:55 - loss: 29.5206 - classification_loss: 22.5289 - regression_loss: 0.2902 - transformation_loss: 335.0790  61/1790 [>.............................] - ETA: 26:35 - loss: 29.1924 - classification_loss: 22.1775 - regression_loss: 0.2892 - transformation_loss: 336.2865  62/1790 [>.............................] - ETA: 26:17 - loss: 28.7880 - classification_loss: 21.8363 - regression_loss: 0.2890 - transformation_loss: 333.1360  63/1790 [>.............................] - ETA: 25:58 - loss: 28.3868 - classification_loss: 21.5070 - regression_loss: 0.2868 - transformation_loss: 329.6518  64/1790 [>.............................] - ETA: 25:41 - loss: 27.9880 - classification_loss: 21.1845 - regression_loss: 0.2843 - transformation_loss: 325.9572  65/1790 [>.............................] - ETA: 25:24 - loss: 27.6001 - classification_loss: 20.8781 - regression_loss: 0.2884 - transformation_loss: 321.6773  66/1790 [>.............................] - ETA: 25:07 - loss: 27.3799 - classification_loss: 20.5828 - regression_loss: 0.2931 - transformation_loss: 325.2015  67/1790 [>.............................] - ETA: 24:50 - loss: 27.0244 - classification_loss: 20.2906 - regression_loss: 0.2937 - transformation_loss: 322.0075  68/1790 [>.............................] - ETA: 24:35 - loss: 26.7600 - classification_loss: 20.0095 - regression_loss: 0.2931 - transformation_loss: 322.8664  69/1790 [>.............................] - ETA: 24:19 - loss: 26.5012 - classification_loss: 19.7344 - regression_loss: 0.2954 - transformation_loss: 323.5701  70/1790 [>.............................] - ETA: 24:04 - loss: 26.1642 - classification_loss: 19.4684 - regression_loss: 0.2957 - transformation_loss: 320.0016  71/1790 [>.............................] - ETA: 23:50 - loss: 25.8529 - classification_loss: 19.2085 - regression_loss: 0.2977 - transformation_loss: 317.3383  72/1790 [>.............................] - ETA: 23:37 - loss: 25.5285 - classification_loss: 18.9539 - regression_loss: 0.3004 - transformation_loss: 313.7080  73/1790 [>.............................] - ETA: 23:23 - loss: 25.2257 - classification_loss: 18.7072 - regression_loss: 0.2980 - transformation_loss: 311.0216  74/1790 [>.............................] - ETA: 23:10 - loss: 24.9160 - classification_loss: 18.4663 - regression_loss: 0.2980 - transformation_loss: 307.5806  75/1790 [>.............................] - ETA: 22:56 - loss: 24.7164 - classification_loss: 18.2852 - regression_loss: 0.3344 - transformation_loss: 304.8408  76/1790 [>.............................] - ETA: 22:43 - loss: 24.5341 - classification_loss: 18.0609 - regression_loss: 0.3354 - transformation_loss: 306.8891  77/1790 [>.............................] - ETA: 22:31 - loss: 24.2555 - classification_loss: 17.8389 - regression_loss: 0.3374 - transformation_loss: 303.9615  78/1790 [>.............................] - ETA: 22:19 - loss: 23.9897 - classification_loss: 17.6253 - regression_loss: 0.3361 - transformation_loss: 301.4169  79/1790 [>.............................] - ETA: 22:08 - loss: 23.7469 - classification_loss: 17.4158 - regression_loss: 0.3334 - transformation_loss: 299.8874  80/1790 [>.............................] - ETA: 21:57 - loss: 23.5167 - classification_loss: 17.2111 - regression_loss: 0.3332 - transformation_loss: 298.6185  81/1790 [>.............................] - ETA: 21:45 - loss: 23.2720 - classification_loss: 17.0118 - regression_loss: 0.3336 - transformation_loss: 296.3324  82/1790 [>.............................] - ETA: 21:34 - loss: 23.1494 - classification_loss: 16.8210 - regression_loss: 0.3347 - transformation_loss: 299.6866  83/1790 [>.............................] - ETA: 21:24 - loss: 22.8979 - classification_loss: 16.6285 - regression_loss: 0.3340 - transformation_loss: 296.7750  84/1790 [>.............................] - ETA: 21:13 - loss: 22.6517 - classification_loss: 16.4410 - regression_loss: 0.3321 - transformation_loss: 293.9282  85/1790 [>.............................] - ETA: 21:03 - loss: 22.4229 - classification_loss: 16.2564 - regression_loss: 0.3317 - transformation_loss: 291.7402  86/1790 [>.............................] - ETA: 20:53 - loss: 22.1876 - classification_loss: 16.0774 - regression_loss: 0.3319 - transformation_loss: 288.9161  87/1790 [>.............................] - ETA: 20:44 - loss: 21.9672 - classification_loss: 15.9044 - regression_loss: 0.3304 - transformation_loss: 286.6211  88/1790 [>.............................] - ETA: 20:35 - loss: 21.7861 - classification_loss: 15.7359 - regression_loss: 0.3282 - transformation_loss: 286.0988  89/1790 [>.............................] - ETA: 20:25 - loss: 21.6905 - classification_loss: 15.5712 - regression_loss: 0.3282 - transformation_loss: 289.5572  90/1790 [>.............................] - ETA: 20:16 - loss: 21.4964 - classification_loss: 15.4082 - regression_loss: 0.3284 - transformation_loss: 287.9859  91/1790 [>.............................] - ETA: 20:08 - loss: 21.2946 - classification_loss: 15.2510 - regression_loss: 0.3274 - transformation_loss: 285.8145  92/1790 [>.............................] - ETA: 19:59 - loss: 21.1173 - classification_loss: 15.0988 - regression_loss: 0.3272 - transformation_loss: 284.5624  93/1790 [>.............................] - ETA: 19:50 - loss: 20.9196 - classification_loss: 14.9479 - regression_loss: 0.3264 - transformation_loss: 282.2639  94/1790 [>.............................] - ETA: 19:42 - loss: 20.7159 - classification_loss: 14.7972 - regression_loss: 0.3251 - transformation_loss: 279.6825  95/1790 [>.............................] - ETA: 19:34 - loss: 20.5193 - classification_loss: 14.6499 - regression_loss: 0.3235 - transformation_loss: 277.2946  96/1790 [>.............................] - ETA: 19:27 - loss: 20.3301 - classification_loss: 14.5087 - regression_loss: 0.3225 - transformation_loss: 274.9455  97/1790 [>.............................] - ETA: 19:19 - loss: 20.1576 - classification_loss: 14.3680 - regression_loss: 0.3202 - transformation_loss: 273.4752  98/1790 [>.............................] - ETA: 19:11 - loss: 19.9728 - classification_loss: 14.2302 - regression_loss: 0.3191 - transformation_loss: 271.1783  99/1790 [>.............................] - ETA: 19:03 - loss: 19.8653 - classification_loss: 14.0982 - regression_loss: 0.3181 - transformation_loss: 272.4491 100/1790 [>.............................] - ETA: 18:56 - loss: 19.7032 - classification_loss: 13.9673 - regression_loss: 0.3179 - transformation_loss: 270.8995 101/1790 [>.............................] - ETA: 18:49 - loss: 19.5738 - classification_loss: 13.8405 - regression_loss: 0.3195 - transformation_loss: 270.6880 102/1790 [>.............................] - ETA: 18:41 - loss: 19.4085 - classification_loss: 13.7119 - regression_loss: 0.3179 - transformation_loss: 268.9366 103/1790 [>.............................] - ETA: 18:35 - loss: 19.2428 - classification_loss: 13.5882 - regression_loss: 0.3163 - transformation_loss: 266.9124 104/1790 [>.............................] - ETA: 18:28 - loss: 19.1177 - classification_loss: 13.4681 - regression_loss: 0.3184 - transformation_loss: 266.5602 105/1790 [>.............................] - ETA: 18:20 - loss: 19.0113 - classification_loss: 13.3520 - regression_loss: 0.3210 - transformation_loss: 266.9144 106/1790 [>.............................] - ETA: 18:14 - loss: 18.8959 - classification_loss: 13.2373 - regression_loss: 0.3207 - transformation_loss: 266.8923 107/1790 [>.............................] - ETA: 18:08 - loss: 18.7366 - classification_loss: 13.1213 - regression_loss: 0.3192 - transformation_loss: 264.8011 108/1790 [>.............................] - ETA: 18:01 - loss: 18.6046 - classification_loss: 13.0105 - regression_loss: 0.3190 - transformation_loss: 263.7563 109/1790 [>.............................] - ETA: 17:54 - loss: 18.6579 - classification_loss: 12.9131 - regression_loss: 0.3233 - transformation_loss: 271.0727 110/1790 [>.............................] - ETA: 17:48 - loss: 18.5081 - classification_loss: 12.8028 - regression_loss: 0.3224 - transformation_loss: 269.1474 111/1790 [>.............................] - ETA: 17:42 - loss: 18.3766 - classification_loss: 12.6953 - regression_loss: 0.3239 - transformation_loss: 267.8702 112/1790 [>.............................] - ETA: 17:36 - loss: 18.2310 - classification_loss: 12.5891 - regression_loss: 0.3240 - transformation_loss: 265.8887 113/1790 [>.............................] - ETA: 17:31 - loss: 18.1147 - classification_loss: 12.4856 - regression_loss: 0.3232 - transformation_loss: 265.2909 114/1790 [>.............................] - ETA: 17:25 - loss: 17.9762 - classification_loss: 12.3826 - regression_loss: 0.3219 - transformation_loss: 263.5857 115/1790 [>.............................] - ETA: 17:20 - loss: 17.8481 - classification_loss: 12.2820 - regression_loss: 0.3207 - transformation_loss: 262.2649 116/1790 [>.............................] - ETA: 17:14 - loss: 17.7226 - classification_loss: 12.1845 - regression_loss: 0.3199 - transformation_loss: 260.9084 117/1790 [>.............................] - ETA: 17:09 - loss: 17.5891 - classification_loss: 12.0869 - regression_loss: 0.3192 - transformation_loss: 259.1517 118/1790 [>.............................] - ETA: 17:04 - loss: 17.4874 - classification_loss: 11.9931 - regression_loss: 0.3193 - transformation_loss: 258.7524 119/1790 [>.............................] - ETA: 16:58 - loss: 17.3748 - classification_loss: 11.9001 - regression_loss: 0.3194 - transformation_loss: 257.7631 120/1790 [=>............................] - ETA: 16:53 - loss: 17.2566 - classification_loss: 11.8079 - regression_loss: 0.3190 - transformation_loss: 256.4835 121/1790 [=>............................] - ETA: 16:48 - loss: 17.1543 - classification_loss: 11.7193 - regression_loss: 0.3184 - transformation_loss: 255.8277 122/1790 [=>............................] - ETA: 16:43 - loss: 17.0338 - classification_loss: 11.6294 - regression_loss: 0.3175 - transformation_loss: 254.3434 123/1790 [=>............................] - ETA: 16:38 - loss: 16.9080 - classification_loss: 11.5404 - regression_loss: 0.3169 - transformation_loss: 252.5374 124/1790 [=>............................] - ETA: 16:33 - loss: 16.7999 - classification_loss: 11.4555 - regression_loss: 0.3172 - transformation_loss: 251.3581 125/1790 [=>............................] - ETA: 16:28 - loss: 16.7223 - classification_loss: 11.3740 - regression_loss: 0.3185 - transformation_loss: 251.4953 126/1790 [=>............................] - ETA: 16:24 - loss: 16.6168 - classification_loss: 11.2910 - regression_loss: 0.3180 - transformation_loss: 250.3939 127/1790 [=>............................] - ETA: 16:19 - loss: 16.5125 - classification_loss: 11.2092 - regression_loss: 0.3198 - transformation_loss: 249.1779 128/1790 [=>............................] - ETA: 16:14 - loss: 16.4044 - classification_loss: 11.1285 - regression_loss: 0.3185 - transformation_loss: 247.8760 129/1790 [=>............................] - ETA: 16:10 - loss: 16.3093 - classification_loss: 11.0476 - regression_loss: 0.3190 - transformation_loss: 247.1336 130/1790 [=>............................] - ETA: 16:06 - loss: 16.2029 - classification_loss: 10.9699 - regression_loss: 0.3191 - transformation_loss: 245.6962 131/1790 [=>............................] - ETA: 16:01 - loss: 16.0948 - classification_loss: 10.8934 - regression_loss: 0.3192 - transformation_loss: 244.1127 132/1790 [=>............................] - ETA: 15:57 - loss: 15.9880 - classification_loss: 10.8170 - regression_loss: 0.3181 - transformation_loss: 242.6461 133/1790 [=>............................] - ETA: 15:52 - loss: 15.8891 - classification_loss: 10.7414 - regression_loss: 0.3174 - transformation_loss: 241.5166 134/1790 [=>............................] - ETA: 15:48 - loss: 15.7930 - classification_loss: 10.6690 - regression_loss: 0.3180 - transformation_loss: 240.3009 135/1790 [=>............................] - ETA: 15:44 - loss: 15.6941 - classification_loss: 10.5959 - regression_loss: 0.3170 - transformation_loss: 239.0658 136/1790 [=>............................] - ETA: 15:40 - loss: 15.5925 - classification_loss: 10.5239 - regression_loss: 0.3167 - transformation_loss: 237.5916 137/1790 [=>............................] - ETA: 15:36 - loss: 15.4943 - classification_loss: 10.4540 - regression_loss: 0.3171 - transformation_loss: 236.1640 138/1790 [=>............................] - ETA: 15:32 - loss: 15.4015 - classification_loss: 10.3845 - regression_loss: 0.3162 - transformation_loss: 235.0352 139/1790 [=>............................] - ETA: 15:28 - loss: 15.3091 - classification_loss: 10.3164 - regression_loss: 0.3149 - transformation_loss: 233.8933 140/1790 [=>............................] - ETA: 15:24 - loss: 15.2164 - classification_loss: 10.2491 - regression_loss: 0.3144 - transformation_loss: 232.6452 141/1790 [=>............................] - ETA: 15:20 - loss: 15.1264 - classification_loss: 10.1828 - regression_loss: 0.3134 - transformation_loss: 231.5135 142/1790 [=>............................] - ETA: 15:17 - loss: 15.0384 - classification_loss: 10.1177 - regression_loss: 0.3123 - transformation_loss: 230.4259 143/1790 [=>............................] - ETA: 15:13 - loss: 14.9483 - classification_loss: 10.0525 - regression_loss: 0.3122 - transformation_loss: 229.1817 144/1790 [=>............................] - ETA: 15:09 - loss: 14.8576 - classification_loss: 9.9884 - regression_loss: 0.3115 - transformation_loss: 227.8812  145/1790 [=>............................] - ETA: 15:06 - loss: 14.7714 - classification_loss: 9.9242 - regression_loss: 0.3107 - transformation_loss: 226.8265 146/1790 [=>............................] - ETA: 15:02 - loss: 14.6862 - classification_loss: 9.8619 - regression_loss: 0.3098 - transformation_loss: 225.7232 147/1790 [=>............................] - ETA: 14:59 - loss: 14.6008 - classification_loss: 9.8009 - regression_loss: 0.3091 - transformation_loss: 224.5411 148/1790 [=>............................] - ETA: 14:55 - loss: 14.5227 - classification_loss: 9.7417 - regression_loss: 0.3086 - transformation_loss: 223.6199 149/1790 [=>............................] - ETA: 14:52 - loss: 14.4471 - classification_loss: 9.6817 - regression_loss: 0.3088 - transformation_loss: 222.8343 150/1790 [=>............................] - ETA: 14:48 - loss: 14.3798 - classification_loss: 9.6242 - regression_loss: 0.3095 - transformation_loss: 222.3022 151/1790 [=>............................] - ETA: 14:45 - loss: 14.2956 - classification_loss: 9.5657 - regression_loss: 0.3085 - transformation_loss: 221.0729 152/1790 [=>............................] - ETA: 14:42 - loss: 14.2144 - classification_loss: 9.5083 - regression_loss: 0.3078 - transformation_loss: 219.9106 153/1790 [=>............................] - ETA: 14:38 - loss: 14.1520 - classification_loss: 9.4519 - regression_loss: 0.3077 - transformation_loss: 219.6170 154/1790 [=>............................] - ETA: 14:35 - loss: 14.0704 - classification_loss: 9.3952 - regression_loss: 0.3062 - transformation_loss: 218.4484 155/1790 [=>............................] - ETA: 14:32 - loss: 13.9975 - classification_loss: 9.3400 - regression_loss: 0.3061 - transformation_loss: 217.5677 156/1790 [=>............................] - ETA: 14:29 - loss: 13.9213 - classification_loss: 9.2853 - regression_loss: 0.3059 - transformation_loss: 216.5064 157/1790 [=>............................] - ETA: 14:25 - loss: 13.8534 - classification_loss: 9.2469 - regression_loss: 0.3040 - transformation_loss: 215.1274 158/1790 [=>............................] - ETA: 14:22 - loss: 13.7787 - classification_loss: 9.1928 - regression_loss: 0.3029 - transformation_loss: 214.1501 159/1790 [=>............................] - ETA: 14:19 - loss: 13.7338 - classification_loss: 9.1408 - regression_loss: 0.3017 - transformation_loss: 214.5674 160/1790 [=>............................] - ETA: 14:16 - loss: 13.6724 - classification_loss: 9.0884 - regression_loss: 0.3004 - transformation_loss: 214.1763 161/1790 [=>............................] - ETA: 14:13 - loss: 13.5988 - classification_loss: 9.0372 - regression_loss: 0.3000 - transformation_loss: 213.0795 162/1790 [=>............................] - ETA: 14:10 - loss: 13.5349 - classification_loss: 8.9861 - regression_loss: 0.2996 - transformation_loss: 212.4582 163/1790 [=>............................] - ETA: 14:07 - loss: 13.4632 - classification_loss: 8.9365 - regression_loss: 0.2986 - transformation_loss: 211.4038 164/1790 [=>............................] - ETA: 14:04 - loss: 13.3936 - classification_loss: 8.8878 - regression_loss: 0.2990 - transformation_loss: 210.3408 165/1790 [=>............................] - ETA: 14:02 - loss: 13.3268 - classification_loss: 8.8392 - regression_loss: 0.2982 - transformation_loss: 209.4717 166/1790 [=>............................] - ETA: 13:59 - loss: 13.2633 - classification_loss: 8.7914 - regression_loss: 0.2982 - transformation_loss: 208.6825 167/1790 [=>............................] - ETA: 13:56 - loss: 13.1929 - classification_loss: 8.7435 - regression_loss: 0.2967 - transformation_loss: 207.6360 168/1790 [=>............................] - ETA: 13:53 - loss: 13.1404 - classification_loss: 8.6972 - regression_loss: 0.2959 - transformation_loss: 207.3629 169/1790 [=>............................] - ETA: 13:51 - loss: 13.0922 - classification_loss: 8.6509 - regression_loss: 0.2957 - transformation_loss: 207.2815 170/1790 [=>............................] - ETA: 13:48 - loss: 13.0285 - classification_loss: 8.6047 - regression_loss: 0.2959 - transformation_loss: 206.3975 171/1790 [=>............................] - ETA: 13:45 - loss: 12.9609 - classification_loss: 8.5585 - regression_loss: 0.2955 - transformation_loss: 205.3403 172/1790 [=>............................] - ETA: 13:42 - loss: 12.9081 - classification_loss: 8.5144 - regression_loss: 0.2969 - transformation_loss: 204.8400 173/1790 [=>............................] - ETA: 13:40 - loss: 12.8440 - classification_loss: 8.4709 - regression_loss: 0.2962 - transformation_loss: 203.8484 174/1790 [=>............................] - ETA: 13:37 - loss: 12.7801 - classification_loss: 8.4267 - regression_loss: 0.2957 - transformation_loss: 202.8875 175/1790 [=>............................] - ETA: 13:34 - loss: 12.7832 - classification_loss: 8.3858 - regression_loss: 0.2967 - transformation_loss: 205.0306 176/1790 [=>............................] - ETA: 13:32 - loss: 12.7251 - classification_loss: 8.3422 - regression_loss: 0.2958 - transformation_loss: 204.3559 177/1790 [=>............................] - ETA: 13:30 - loss: 12.6618 - classification_loss: 8.2997 - regression_loss: 0.2950 - transformation_loss: 203.3555 178/1790 [=>............................] - ETA: 13:27 - loss: 12.6013 - classification_loss: 8.2578 - regression_loss: 0.2949 - transformation_loss: 202.4267 179/1790 [==>...........................] - ETA: 13:25 - loss: 12.5470 - classification_loss: 8.2158 - regression_loss: 0.2939 - transformation_loss: 201.8659 180/1790 [==>...........................] - ETA: 13:22 - loss: 12.4971 - classification_loss: 8.1753 - regression_loss: 0.2944 - transformation_loss: 201.3742 181/1790 [==>...........................] - ETA: 13:20 - loss: 12.4458 - classification_loss: 8.1344 - regression_loss: 0.2945 - transformation_loss: 200.8400 182/1790 [==>...........................] - ETA: 13:17 - loss: 12.3945 - classification_loss: 8.0936 - regression_loss: 0.2934 - transformation_loss: 200.3704 183/1790 [==>...........................] - ETA: 13:15 - loss: 12.3425 - classification_loss: 8.0544 - regression_loss: 0.2934 - transformation_loss: 199.7385 184/1790 [==>...........................] - ETA: 13:13 - loss: 12.2898 - classification_loss: 8.0153 - regression_loss: 0.2932 - transformation_loss: 199.0710 185/1790 [==>...........................] - ETA: 13:10 - loss: 12.2441 - classification_loss: 7.9776 - regression_loss: 0.2936 - transformation_loss: 198.6473 186/1790 [==>...........................] - ETA: 13:08 - loss: 12.1940 - classification_loss: 7.9388 - regression_loss: 0.2943 - transformation_loss: 198.0469 187/1790 [==>...........................] - ETA: 13:06 - loss: 12.1585 - classification_loss: 7.9000 - regression_loss: 0.2951 - transformation_loss: 198.1692 188/1790 [==>...........................] - ETA: 13:04 - loss: 12.1047 - classification_loss: 7.8623 - regression_loss: 0.2950 - transformation_loss: 197.3725 189/1790 [==>...........................] - ETA: 13:01 - loss: 12.0527 - classification_loss: 7.8256 - regression_loss: 0.2962 - transformation_loss: 196.5500 190/1790 [==>...........................] - ETA: 12:59 - loss: 12.0617 - classification_loss: 7.7978 - regression_loss: 0.2993 - transformation_loss: 198.2282 191/1790 [==>...........................] - ETA: 12:57 - loss: 12.0098 - classification_loss: 7.7615 - regression_loss: 0.2990 - transformation_loss: 197.4656 192/1790 [==>...........................] - ETA: 12:54 - loss: 11.9589 - classification_loss: 7.7251 - regression_loss: 0.2988 - transformation_loss: 196.7536 193/1790 [==>...........................] - ETA: 12:52 - loss: 11.9630 - classification_loss: 7.6987 - regression_loss: 0.3203 - transformation_loss: 197.1987 194/1790 [==>...........................] - ETA: 12:50 - loss: 11.9169 - classification_loss: 7.6641 - regression_loss: 0.3202 - transformation_loss: 196.6288 195/1790 [==>...........................] - ETA: 12:47 - loss: 11.8646 - classification_loss: 7.6294 - regression_loss: 0.3199 - transformation_loss: 195.7672 196/1790 [==>...........................] - ETA: 12:45 - loss: 11.8182 - classification_loss: 7.5946 - regression_loss: 0.3198 - transformation_loss: 195.1913 197/1790 [==>...........................] - ETA: 12:44 - loss: 11.7667 - classification_loss: 7.5600 - regression_loss: 0.3193 - transformation_loss: 194.3734 198/1790 [==>...........................] - ETA: 12:42 - loss: 11.7250 - classification_loss: 7.5255 - regression_loss: 0.3193 - transformation_loss: 194.0123 199/1790 [==>...........................] - ETA: 12:39 - loss: 11.6791 - classification_loss: 7.4915 - regression_loss: 0.3193 - transformation_loss: 193.4146 200/1790 [==>...........................] - ETA: 12:37 - loss: 11.6281 - classification_loss: 7.4575 - regression_loss: 0.3188 - transformation_loss: 192.5876 201/1790 [==>...........................] - ETA: 12:35 - loss: 11.5794 - classification_loss: 7.4241 - regression_loss: 0.3187 - transformation_loss: 191.8267 202/1790 [==>...........................] - ETA: 12:33 - loss: 11.5394 - classification_loss: 7.3911 - regression_loss: 0.3184 - transformation_loss: 191.4951 203/1790 [==>...........................] - ETA: 12:31 - loss: 11.5280 - classification_loss: 7.4001 - regression_loss: 0.3169 - transformation_loss: 190.5518 204/1790 [==>...........................] - ETA: 12:29 - loss: 11.4826 - classification_loss: 7.3680 - regression_loss: 0.3161 - transformation_loss: 189.9236 205/1790 [==>...........................] - ETA: 12:27 - loss: 11.4360 - classification_loss: 7.3359 - regression_loss: 0.3152 - transformation_loss: 189.2472 206/1790 [==>...........................] - ETA: 12:25 - loss: 11.3906 - classification_loss: 7.3041 - regression_loss: 0.3147 - transformation_loss: 188.5912 207/1790 [==>...........................] - ETA: 12:23 - loss: 11.3552 - classification_loss: 7.2728 - regression_loss: 0.3152 - transformation_loss: 188.3658 208/1790 [==>...........................] - ETA: 12:22 - loss: 11.3155 - classification_loss: 7.2431 - regression_loss: 0.3149 - transformation_loss: 187.8761 209/1790 [==>...........................] - ETA: 12:20 - loss: 11.2694 - classification_loss: 7.2116 - regression_loss: 0.3143 - transformation_loss: 187.1714 210/1790 [==>...........................] - ETA: 12:18 - loss: 11.2312 - classification_loss: 7.1820 - regression_loss: 0.3138 - transformation_loss: 186.7696 211/1790 [==>...........................] - ETA: 12:16 - loss: 11.1903 - classification_loss: 7.1513 - regression_loss: 0.3133 - transformation_loss: 186.2831 212/1790 [==>...........................] - ETA: 12:14 - loss: 11.1576 - classification_loss: 7.1218 - regression_loss: 0.3128 - transformation_loss: 186.1542 213/1790 [==>...........................] - ETA: 12:13 - loss: 11.1126 - classification_loss: 7.0924 - regression_loss: 0.3120 - transformation_loss: 185.4094 214/1790 [==>...........................] - ETA: 12:11 - loss: 11.0701 - classification_loss: 7.0630 - regression_loss: 0.3118 - transformation_loss: 184.7657 215/1790 [==>...........................] - ETA: 12:09 - loss: 11.0317 - classification_loss: 7.0432 - regression_loss: 0.3104 - transformation_loss: 183.9063 216/1790 [==>...........................] - ETA: 12:07 - loss: 10.9917 - classification_loss: 7.0148 - regression_loss: 0.3107 - transformation_loss: 183.3098 217/1790 [==>...........................] - ETA: 12:05 - loss: 10.9709 - classification_loss: 6.9884 - regression_loss: 0.3105 - transformation_loss: 183.6006 218/1790 [==>...........................] - ETA: 12:04 - loss: 10.9350 - classification_loss: 6.9620 - regression_loss: 0.3100 - transformation_loss: 183.1452 219/1790 [==>...........................] - ETA: 12:02 - loss: 10.9005 - classification_loss: 6.9341 - regression_loss: 0.3099 - transformation_loss: 182.8249 220/1790 [==>...........................] - ETA: 12:00 - loss: 10.8605 - classification_loss: 6.9058 - regression_loss: 0.3090 - transformation_loss: 182.2809 221/1790 [==>...........................] - ETA: 11:58 - loss: 10.8307 - classification_loss: 6.8793 - regression_loss: 0.3094 - transformation_loss: 182.0991 222/1790 [==>...........................] - ETA: 11:57 - loss: 10.7990 - classification_loss: 6.8534 - regression_loss: 0.3098 - transformation_loss: 181.7883 223/1790 [==>...........................] - ETA: 11:55 - loss: 10.7610 - classification_loss: 6.8269 - regression_loss: 0.3103 - transformation_loss: 181.1882 224/1790 [==>...........................] - ETA: 11:53 - loss: 10.7204 - classification_loss: 6.7999 - regression_loss: 0.3098 - transformation_loss: 180.5340 225/1790 [==>...........................] - ETA: 11:52 - loss: 10.6850 - classification_loss: 6.7734 - regression_loss: 0.3100 - transformation_loss: 180.0795 226/1790 [==>...........................] - ETA: 11:50 - loss: 10.6704 - classification_loss: 6.7481 - regression_loss: 0.3107 - transformation_loss: 180.5832 227/1790 [==>...........................] - ETA: 11:48 - loss: 10.7166 - classification_loss: 6.7366 - regression_loss: 0.3140 - transformation_loss: 183.3019 228/1790 [==>...........................] - ETA: 11:47 - loss: 10.6925 - classification_loss: 6.7117 - regression_loss: 0.3145 - transformation_loss: 183.3121 229/1790 [==>...........................] - ETA: 11:45 - loss: 10.6576 - classification_loss: 6.6857 - regression_loss: 0.3142 - transformation_loss: 182.8846 230/1790 [==>...........................] - ETA: 11:43 - loss: 10.6197 - classification_loss: 6.6598 - regression_loss: 0.3135 - transformation_loss: 182.3203 231/1790 [==>...........................] - ETA: 11:42 - loss: 10.5842 - classification_loss: 6.6348 - regression_loss: 0.3140 - transformation_loss: 181.7694 232/1790 [==>...........................] - ETA: 11:40 - loss: 10.5504 - classification_loss: 6.6101 - regression_loss: 0.3136 - transformation_loss: 181.3292 233/1790 [==>...........................] - ETA: 11:39 - loss: 10.5148 - classification_loss: 6.5844 - regression_loss: 0.3132 - transformation_loss: 180.8632 234/1790 [==>...........................] - ETA: 11:37 - loss: 10.4863 - classification_loss: 6.5606 - regression_loss: 0.3136 - transformation_loss: 180.6091 235/1790 [==>...........................] - ETA: 11:36 - loss: 10.4499 - classification_loss: 6.5359 - regression_loss: 0.3126 - transformation_loss: 180.0687 236/1790 [==>...........................] - ETA: 11:34 - loss: 10.4185 - classification_loss: 6.5118 - regression_loss: 0.3132 - transformation_loss: 179.6795 237/1790 [==>...........................] - ETA: 11:33 - loss: 10.3912 - classification_loss: 6.4890 - regression_loss: 0.3135 - transformation_loss: 179.4323 238/1790 [==>...........................] - ETA: 11:31 - loss: 10.3755 - classification_loss: 6.4897 - regression_loss: 0.3122 - transformation_loss: 178.6784 239/1790 [===>..........................] - ETA: 11:29 - loss: 10.3406 - classification_loss: 6.4654 - regression_loss: 0.3117 - transformation_loss: 178.1737 240/1790 [===>..........................] - ETA: 11:28 - loss: 10.3045 - classification_loss: 6.4411 - regression_loss: 0.3108 - transformation_loss: 177.6299 241/1790 [===>..........................] - ETA: 11:26 - loss: 10.2753 - classification_loss: 6.4177 - regression_loss: 0.3107 - transformation_loss: 177.3459 242/1790 [===>..........................] - ETA: 11:25 - loss: 10.2417 - classification_loss: 6.3942 - regression_loss: 0.3102 - transformation_loss: 176.8642 243/1790 [===>..........................] - ETA: 11:23 - loss: 10.2064 - classification_loss: 6.3704 - regression_loss: 0.3097 - transformation_loss: 176.3180 244/1790 [===>..........................] - ETA: 11:22 - loss: 10.1742 - classification_loss: 6.3474 - regression_loss: 0.3095 - transformation_loss: 175.8621 245/1790 [===>..........................] - ETA: 11:21 - loss: 10.1401 - classification_loss: 6.3246 - regression_loss: 0.3088 - transformation_loss: 175.3316 246/1790 [===>..........................] - ETA: 11:19 - loss: 10.1101 - classification_loss: 6.3023 - regression_loss: 0.3093 - transformation_loss: 174.9293 247/1790 [===>..........................] - ETA: 11:18 - loss: 10.0842 - classification_loss: 6.2798 - regression_loss: 0.3091 - transformation_loss: 174.7635 248/1790 [===>..........................] - ETA: 11:16 - loss: 10.0502 - classification_loss: 6.2573 - regression_loss: 0.3085 - transformation_loss: 174.2255 249/1790 [===>..........................] - ETA: 11:15 - loss: 10.0198 - classification_loss: 6.2348 - regression_loss: 0.3078 - transformation_loss: 173.8575 250/1790 [===>..........................] - ETA: 11:13 - loss: 9.9848 - classification_loss: 6.2124 - regression_loss: 0.3069 - transformation_loss: 173.2720  251/1790 [===>..........................] - ETA: 11:12 - loss: 9.9528 - classification_loss: 6.1906 - regression_loss: 0.3069 - transformation_loss: 172.7655 252/1790 [===>..........................] - ETA: 11:11 - loss: 9.9230 - classification_loss: 6.1689 - regression_loss: 0.3061 - transformation_loss: 172.4002 253/1790 [===>..........................] - ETA: 11:09 - loss: 9.9137 - classification_loss: 6.1487 - regression_loss: 0.3069 - transformation_loss: 172.9038 254/1790 [===>..........................] - ETA: 11:08 - loss: 9.9035 - classification_loss: 6.1279 - regression_loss: 0.3073 - transformation_loss: 173.4159 255/1790 [===>..........................] - ETA: 11:06 - loss: 9.8756 - classification_loss: 6.1075 - regression_loss: 0.3076 - transformation_loss: 173.0297 256/1790 [===>..........................] - ETA: 11:05 - loss: 9.8577 - classification_loss: 6.0872 - regression_loss: 0.3081 - transformation_loss: 173.1190 257/1790 [===>..........................] - ETA: 11:04 - loss: 9.8253 - classification_loss: 6.0662 - regression_loss: 0.3074 - transformation_loss: 172.5876 258/1790 [===>..........................] - ETA: 11:02 - loss: 9.8104 - classification_loss: 6.0461 - regression_loss: 0.3073 - transformation_loss: 172.8515 259/1790 [===>..........................] - ETA: 11:01 - loss: 9.8145 - classification_loss: 6.0284 - regression_loss: 0.3085 - transformation_loss: 173.8822 260/1790 [===>..........................] - ETA: 11:00 - loss: 9.7879 - classification_loss: 6.0099 - regression_loss: 0.3095 - transformation_loss: 173.4251 261/1790 [===>..........................] - ETA: 10:58 - loss: 9.7599 - classification_loss: 5.9889 - regression_loss: 0.3087 - transformation_loss: 173.1149 262/1790 [===>..........................] - ETA: 10:57 - loss: 9.7330 - classification_loss: 5.9688 - regression_loss: 0.3088 - transformation_loss: 172.7700 263/1790 [===>..........................] - ETA: 10:56 - loss: 9.7062 - classification_loss: 5.9505 - regression_loss: 0.3094 - transformation_loss: 172.3126 264/1790 [===>..........................] - ETA: 10:54 - loss: 9.6786 - classification_loss: 5.9304 - regression_loss: 0.3087 - transformation_loss: 171.9755 265/1790 [===>..........................] - ETA: 10:53 - loss: 9.6534 - classification_loss: 5.9102 - regression_loss: 0.3081 - transformation_loss: 171.7540 266/1790 [===>..........................] - ETA: 10:52 - loss: 9.6253 - classification_loss: 5.8906 - regression_loss: 0.3076 - transformation_loss: 171.3575 267/1790 [===>..........................] - ETA: 10:50 - loss: 9.5963 - classification_loss: 5.8717 - regression_loss: 0.3075 - transformation_loss: 170.8543 268/1790 [===>..........................] - ETA: 10:49 - loss: 9.5782 - classification_loss: 5.8532 - regression_loss: 0.3070 - transformation_loss: 170.8962 269/1790 [===>..........................] - ETA: 10:48 - loss: 9.5499 - classification_loss: 5.8346 - regression_loss: 0.3063 - transformation_loss: 170.4461 270/1790 [===>..........................] - ETA: 10:47 - loss: 9.5652 - classification_loss: 5.8231 - regression_loss: 0.3214 - transformation_loss: 171.0359 271/1790 [===>..........................] - ETA: 10:46 - loss: 9.5402 - classification_loss: 5.8050 - regression_loss: 0.3211 - transformation_loss: 170.7044 272/1790 [===>..........................] - ETA: 10:44 - loss: 9.5112 - classification_loss: 5.7860 - regression_loss: 0.3206 - transformation_loss: 170.2323 273/1790 [===>..........................] - ETA: 10:43 - loss: 9.4841 - classification_loss: 5.7680 - regression_loss: 0.3206 - transformation_loss: 169.7720 274/1790 [===>..........................] - ETA: 10:42 - loss: 9.4561 - classification_loss: 5.7500 - regression_loss: 0.3201 - transformation_loss: 169.2987 275/1790 [===>..........................] - ETA: 10:40 - loss: 9.4645 - classification_loss: 5.7334 - regression_loss: 0.3198 - transformation_loss: 170.5638 276/1790 [===>..........................] - ETA: 10:39 - loss: 9.4868 - classification_loss: 5.7209 - regression_loss: 0.3222 - transformation_loss: 172.1803 277/1790 [===>..........................] - ETA: 10:38 - loss: 9.4606 - classification_loss: 5.7027 - regression_loss: 0.3217 - transformation_loss: 171.8129 278/1790 [===>..........................] - ETA: 10:37 - loss: 9.4328 - classification_loss: 5.6853 - regression_loss: 0.3214 - transformation_loss: 171.3053 279/1790 [===>..........................] - ETA: 10:36 - loss: 9.4089 - classification_loss: 5.6684 - regression_loss: 0.3219 - transformation_loss: 170.9289 280/1790 [===>..........................] - ETA: 10:34 - loss: 9.3895 - classification_loss: 5.6509 - regression_loss: 0.3221 - transformation_loss: 170.8231 281/1790 [===>..........................] - ETA: 10:33 - loss: 9.3665 - classification_loss: 5.6338 - regression_loss: 0.3214 - transformation_loss: 170.5637 282/1790 [===>..........................] - ETA: 10:32 - loss: 9.3421 - classification_loss: 5.6168 - regression_loss: 0.3214 - transformation_loss: 170.1975 283/1790 [===>..........................] - ETA: 10:31 - loss: 9.3254 - classification_loss: 5.6000 - regression_loss: 0.3223 - transformation_loss: 170.1534 284/1790 [===>..........................] - ETA: 10:30 - loss: 9.3003 - classification_loss: 5.5835 - regression_loss: 0.3230 - transformation_loss: 169.6881 285/1790 [===>..........................] - ETA: 10:29 - loss: 9.2749 - classification_loss: 5.5667 - regression_loss: 0.3231 - transformation_loss: 169.2576 286/1790 [===>..........................] - ETA: 10:28 - loss: 9.2491 - classification_loss: 5.5489 - regression_loss: 0.3221 - transformation_loss: 168.9052 287/1790 [===>..........................] - ETA: 10:26 - loss: 9.2232 - classification_loss: 5.5324 - regression_loss: 0.3217 - transformation_loss: 168.4564 288/1790 [===>..........................] - ETA: 10:25 - loss: 9.1973 - classification_loss: 5.5157 - regression_loss: 0.3210 - transformation_loss: 168.0278 289/1790 [===>..........................] - ETA: 10:24 - loss: 9.1787 - classification_loss: 5.5001 - regression_loss: 0.3205 - transformation_loss: 167.9024 290/1790 [===>..........................] - ETA: 10:23 - loss: 9.1520 - classification_loss: 5.4833 - regression_loss: 0.3200 - transformation_loss: 167.4348 291/1790 [===>..........................] - ETA: 10:22 - loss: 9.1885 - classification_loss: 5.4971 - regression_loss: 0.3353 - transformation_loss: 167.8037 292/1790 [===>..........................] - ETA: 10:21 - loss: 9.1687 - classification_loss: 5.4815 - regression_loss: 0.3347 - transformation_loss: 167.6270 293/1790 [===>..........................] - ETA: 10:20 - loss: 9.1433 - classification_loss: 5.4649 - regression_loss: 0.3341 - transformation_loss: 167.2113 294/1790 [===>..........................] - ETA: 10:19 - loss: 9.1261 - classification_loss: 5.4493 - regression_loss: 0.3336 - transformation_loss: 167.1596 295/1790 [===>..........................] - ETA: 10:17 - loss: 9.1143 - classification_loss: 5.4342 - regression_loss: 0.3335 - transformation_loss: 167.3343 296/1790 [===>..........................] - ETA: 10:16 - loss: 9.0931 - classification_loss: 5.4191 - regression_loss: 0.3342 - transformation_loss: 166.9938 297/1790 [===>..........................] - ETA: 10:15 - loss: 9.0679 - classification_loss: 5.4033 - regression_loss: 0.3335 - transformation_loss: 166.5535 298/1790 [===>..........................] - ETA: 10:14 - loss: 9.0830 - classification_loss: 5.3891 - regression_loss: 0.3334 - transformation_loss: 168.0261 299/1790 [====>.........................] - ETA: 10:13 - loss: 9.0944 - classification_loss: 5.3860 - regression_loss: 0.3348 - transformation_loss: 168.6844 300/1790 [====>.........................] - ETA: 10:12 - loss: 9.0715 - classification_loss: 5.3715 - regression_loss: 0.3346 - transformation_loss: 168.2699 301/1790 [====>.........................] - ETA: 10:11 - loss: 9.0484 - classification_loss: 5.3571 - regression_loss: 0.3344 - transformation_loss: 167.8444 302/1790 [====>.........................] - ETA: 10:10 - loss: 9.0305 - classification_loss: 5.3422 - regression_loss: 0.3338 - transformation_loss: 167.7249 303/1790 [====>.........................] - ETA: 10:09 - loss: 9.0069 - classification_loss: 5.3277 - regression_loss: 0.3334 - transformation_loss: 167.2885 304/1790 [====>.........................] - ETA: 10:08 - loss: 8.9849 - classification_loss: 5.3133 - regression_loss: 0.3334 - transformation_loss: 166.9124 305/1790 [====>.........................] - ETA: 10:07 - loss: 8.9748 - classification_loss: 5.2984 - regression_loss: 0.3328 - transformation_loss: 167.1795 306/1790 [====>.........................] - ETA: 10:06 - loss: 8.9538 - classification_loss: 5.2838 - regression_loss: 0.3326 - transformation_loss: 166.8678 307/1790 [====>.........................] - ETA: 10:05 - loss: 8.9294 - classification_loss: 5.2693 - regression_loss: 0.3319 - transformation_loss: 166.4126 308/1790 [====>.........................] - ETA: 10:04 - loss: 8.9058 - classification_loss: 5.2549 - regression_loss: 0.3314 - transformation_loss: 165.9729 309/1790 [====>.........................] - ETA: 10:03 - loss: 8.8901 - classification_loss: 5.2413 - regression_loss: 0.3320 - transformation_loss: 165.8417 310/1790 [====>.........................] - ETA: 10:02 - loss: 8.8673 - classification_loss: 5.2267 - regression_loss: 0.3313 - transformation_loss: 165.4666 311/1790 [====>.........................] - ETA: 10:01 - loss: 8.8445 - classification_loss: 5.2126 - regression_loss: 0.3311 - transformation_loss: 165.0428 312/1790 [====>.........................] - ETA: 10:00 - loss: 8.8212 - classification_loss: 5.1981 - regression_loss: 0.3304 - transformation_loss: 164.6357 313/1790 [====>.........................] - ETA: 9:59 - loss: 8.8020 - classification_loss: 5.1833 - regression_loss: 0.3296 - transformation_loss: 164.4539  314/1790 [====>.........................] - ETA: 9:58 - loss: 8.7816 - classification_loss: 5.1694 - regression_loss: 0.3295 - transformation_loss: 164.1364 315/1790 [====>.........................] - ETA: 9:57 - loss: 8.7578 - classification_loss: 5.1546 - regression_loss: 0.3287 - transformation_loss: 163.7286 316/1790 [====>.........................] - ETA: 9:56 - loss: 8.7369 - classification_loss: 5.1402 - regression_loss: 0.3279 - transformation_loss: 163.4446 317/1790 [====>.........................] - ETA: 9:55 - loss: 8.7162 - classification_loss: 5.1263 - regression_loss: 0.3280 - transformation_loss: 163.0917 318/1790 [====>.........................] - ETA: 9:54 - loss: 8.6956 - classification_loss: 5.1135 - regression_loss: 0.3279 - transformation_loss: 162.7081 319/1790 [====>.........................] - ETA: 9:53 - loss: 8.6741 - classification_loss: 5.0992 - regression_loss: 0.3277 - transformation_loss: 162.3556 320/1790 [====>.........................] - ETA: 9:52 - loss: 8.6514 - classification_loss: 5.0853 - regression_loss: 0.3271 - transformation_loss: 161.9530 321/1790 [====>.........................] - ETA: 9:52 - loss: 8.6318 - classification_loss: 5.0716 - regression_loss: 0.3264 - transformation_loss: 161.6900 322/1790 [====>.........................] - ETA: 9:51 - loss: 8.6103 - classification_loss: 5.0586 - regression_loss: 0.3259 - transformation_loss: 161.2901 323/1790 [====>.........................] - ETA: 9:50 - loss: 8.5954 - classification_loss: 5.0450 - regression_loss: 0.3256 - transformation_loss: 161.2412 324/1790 [====>.........................] - ETA: 9:49 - loss: 8.5792 - classification_loss: 5.0319 - regression_loss: 0.3254 - transformation_loss: 161.0964 325/1790 [====>.........................] - ETA: 9:48 - loss: 8.5569 - classification_loss: 5.0180 - regression_loss: 0.3245 - transformation_loss: 160.7200 326/1790 [====>.........................] - ETA: 9:47 - loss: 8.5392 - classification_loss: 5.0043 - regression_loss: 0.3237 - transformation_loss: 160.5586 327/1790 [====>.........................] - ETA: 9:46 - loss: 8.5172 - classification_loss: 4.9910 - regression_loss: 0.3232 - transformation_loss: 160.1486 328/1790 [====>.........................] - ETA: 9:45 - loss: 8.4991 - classification_loss: 4.9783 - regression_loss: 0.3229 - transformation_loss: 159.8904 329/1790 [====>.........................] - ETA: 9:44 - loss: 8.4813 - classification_loss: 4.9648 - regression_loss: 0.3222 - transformation_loss: 159.7128 330/1790 [====>.........................] - ETA: 9:43 - loss: 8.4605 - classification_loss: 4.9511 - regression_loss: 0.3217 - transformation_loss: 159.3803 331/1790 [====>.........................] - ETA: 9:42 - loss: 8.4402 - classification_loss: 4.9376 - regression_loss: 0.3210 - transformation_loss: 159.0825 332/1790 [====>.........................] - ETA: 9:41 - loss: 8.4191 - classification_loss: 4.9239 - regression_loss: 0.3205 - transformation_loss: 158.7334 333/1790 [====>.........................] - ETA: 9:40 - loss: 8.4005 - classification_loss: 4.9111 - regression_loss: 0.3199 - transformation_loss: 158.4753 334/1790 [====>.........................] - ETA: 9:39 - loss: 8.3791 - classification_loss: 4.8983 - regression_loss: 0.3191 - transformation_loss: 158.0898 335/1790 [====>.........................] - ETA: 9:38 - loss: 8.3643 - classification_loss: 4.8856 - regression_loss: 0.3196 - transformation_loss: 157.9558TensorBoard caught SIGTERM; exiting...
 336/1790 [====>.........................] - ETA: 9:38 - loss: 8.3497 - classification_loss: 4.8733 - regression_loss: 0.3191 - transformation_loss: 157.8663 337/1790 [====>.........................] - ETA: 9:37 - loss: 8.3288 - classification_loss: 4.8603 - regression_loss: 0.3189 - transformation_loss: 157.4816 338/1790 [====>.........................] - ETA: 9:36 - loss: 8.3081 - classification_loss: 4.8472 - regression_loss: 0.3183 - transformation_loss: 157.1254 339/1790 [====>.........................] - ETA: 9:35 - loss: 8.2891 - classification_loss: 4.8351 - regression_loss: 0.3183 - transformation_loss: 156.7857 340/1790 [====>.........................] - ETA: 9:34 - loss: 8.2715 - classification_loss: 4.8230 - regression_loss: 0.3180 - transformation_loss: 156.5267 341/1790 [====>.........................] - ETA: 9:33 - loss: 8.2529 - classification_loss: 4.8116 - regression_loss: 0.3180 - transformation_loss: 156.1673 342/1790 [====>.........................] - ETA: 9:32 - loss: 8.2357 - classification_loss: 4.7997 - regression_loss: 0.3177 - transformation_loss: 155.9122 343/1790 [====>.........................] - ETA: 9:31 - loss: 8.2167 - classification_loss: 4.7879 - regression_loss: 0.3172 - transformation_loss: 155.5815 344/1790 [====>.........................] - ETA: 9:30 - loss: 8.1965 - classification_loss: 4.7756 - regression_loss: 0.3168 - transformation_loss: 155.2042 345/1790 [====>.........................] - ETA: 9:30 - loss: 8.1761 - classification_loss: 4.7636 - regression_loss: 0.3161 - transformation_loss: 154.8222 346/1790 [====>.........................] - ETA: 9:29 - loss: 8.1560 - classification_loss: 4.7510 - regression_loss: 0.3153 - transformation_loss: 154.4833 347/1790 [====>.........................] - ETA: 9:28 - loss: 8.1366 - classification_loss: 4.7390 - regression_loss: 0.3150 - transformation_loss: 154.1301 348/1790 [====>.........................] - ETA: 9:27 - loss: 8.1312 - classification_loss: 4.7280 - regression_loss: 0.3153 - transformation_loss: 154.3941 349/1790 [====>.........................] - ETA: 9:26 - loss: 8.1131 - classification_loss: 4.7159 - regression_loss: 0.3146 - transformation_loss: 154.1318 350/1790 [====>.........................] - ETA: 9:25 - loss: 8.0946 - classification_loss: 4.7045 - regression_loss: 0.3140 - transformation_loss: 153.8055 351/1790 [====>.........................] - ETA: 9:24 - loss: 8.0756 - classification_loss: 4.6925 - regression_loss: 0.3133 - transformation_loss: 153.4911 352/1790 [====>.........................] - ETA: 9:24 - loss: 8.0558 - classification_loss: 4.6804 - regression_loss: 0.3127 - transformation_loss: 153.1370 353/1790 [====>.........................] - ETA: 9:23 - loss: 8.0376 - classification_loss: 4.6692 - regression_loss: 0.3121 - transformation_loss: 152.8141 354/1790 [====>.........................] - ETA: 9:22 - loss: 8.0231 - classification_loss: 4.6577 - regression_loss: 0.3115 - transformation_loss: 152.6940 355/1790 [====>.........................] - ETA: 9:21 - loss: 8.0070 - classification_loss: 4.6462 - regression_loss: 0.3113 - transformation_loss: 152.4755 356/1790 [====>.........................] - ETA: 9:20 - loss: 7.9905 - classification_loss: 4.6346 - regression_loss: 0.3111 - transformation_loss: 152.2342 357/1790 [====>.........................] - ETA: 9:19 - loss: 7.9727 - classification_loss: 4.6237 - regression_loss: 0.3108 - transformation_loss: 151.9038 358/1790 [=====>........................] - ETA: 9:18 - loss: 7.9545 - classification_loss: 4.6118 - regression_loss: 0.3103 - transformation_loss: 151.6174 359/1790 [=====>........................] - ETA: 9:18 - loss: 7.9407 - classification_loss: 4.6017 - regression_loss: 0.3101 - transformation_loss: 151.4485 360/1790 [=====>........................] - ETA: 9:17 - loss: 7.9284 - classification_loss: 4.5922 - regression_loss: 0.3098 - transformation_loss: 151.3208 361/1790 [=====>........................] - ETA: 9:16 - loss: 7.9133 - classification_loss: 4.5811 - regression_loss: 0.3091 - transformation_loss: 151.1514 362/1790 [=====>........................] - ETA: 9:15 - loss: 7.8982 - classification_loss: 4.5704 - regression_loss: 0.3086 - transformation_loss: 150.9590 363/1790 [=====>........................] - ETA: 9:14 - loss: 7.8874 - classification_loss: 4.5596 - regression_loss: 0.3086 - transformation_loss: 150.9582 364/1790 [=====>........................] - ETA: 9:13 - loss: 7.8692 - classification_loss: 4.5487 - regression_loss: 0.3083 - transformation_loss: 150.6084 365/1790 [=====>........................] - ETA: 9:12 - loss: 7.8517 - classification_loss: 4.5374 - regression_loss: 0.3077 - transformation_loss: 150.3318 366/1790 [=====>........................] - ETA: 9:12 - loss: 7.8332 - classification_loss: 4.5261 - regression_loss: 0.3071 - transformation_loss: 149.9998 367/1790 [=====>........................] - ETA: 9:11 - loss: 7.8314 - classification_loss: 4.5162 - regression_loss: 0.3075 - transformation_loss: 150.3836 368/1790 [=====>........................] - ETA: 9:10 - loss: 7.8175 - classification_loss: 4.5064 - regression_loss: 0.3078 - transformation_loss: 150.1655 369/1790 [=====>........................] - ETA: 9:09 - loss: 7.8005 - classification_loss: 4.4957 - regression_loss: 0.3073 - transformation_loss: 149.8762 370/1790 [=====>........................] - ETA: 9:08 - loss: 7.7875 - classification_loss: 4.4844 - regression_loss: 0.3065 - transformation_loss: 149.8300 371/1790 [=====>........................] - ETA: 9:08 - loss: 7.7746 - classification_loss: 4.4732 - regression_loss: 0.3059 - transformation_loss: 149.7740 372/1790 [=====>........................] - ETA: 9:07 - loss: 7.7606 - classification_loss: 4.4630 - regression_loss: 0.3054 - transformation_loss: 149.6082 373/1790 [=====>........................] - ETA: 9:06 - loss: 7.7494 - classification_loss: 4.4529 - regression_loss: 0.3053 - transformation_loss: 149.5572 374/1790 [=====>........................] - ETA: 9:05 - loss: 7.7434 - classification_loss: 4.4461 - regression_loss: 0.3057 - transformation_loss: 149.5795 375/1790 [=====>........................] - ETA: 9:05 - loss: 7.7291 - classification_loss: 4.4362 - regression_loss: 0.3051 - transformation_loss: 149.3919 376/1790 [=====>........................] - ETA: 9:04 - loss: 7.7146 - classification_loss: 4.4251 - regression_loss: 0.3045 - transformation_loss: 149.2480 377/1790 [=====>........................] - ETA: 9:03 - loss: 7.7023 - classification_loss: 4.4169 - regression_loss: 0.3047 - transformation_loss: 149.0417 378/1790 [=====>........................] - ETA: 9:02 - loss: 7.6871 - classification_loss: 4.4067 - regression_loss: 0.3045 - transformation_loss: 148.7951 379/1790 [=====>........................] - ETA: 9:01 - loss: 7.6735 - classification_loss: 4.3968 - regression_loss: 0.3045 - transformation_loss: 148.6077 380/1790 [=====>........................] - ETA: 9:01 - loss: 7.6569 - classification_loss: 4.3865 - regression_loss: 0.3039 - transformation_loss: 148.3225 381/1790 [=====>........................] - ETA: 9:00 - loss: 7.6416 - classification_loss: 4.3759 - regression_loss: 0.3033 - transformation_loss: 148.1243 382/1790 [=====>........................] - ETA: 8:59 - loss: 7.6262 - classification_loss: 4.3662 - regression_loss: 0.3037 - transformation_loss: 147.8191 383/1790 [=====>........................] - ETA: 8:58 - loss: 7.6128 - classification_loss: 4.3556 - regression_loss: 0.3033 - transformation_loss: 147.6961 384/1790 [=====>........................] - ETA: 8:57 - loss: 7.6053 - classification_loss: 4.3467 - regression_loss: 0.3036 - transformation_loss: 147.7490 385/1790 [=====>........................] - ETA: 8:57 - loss: 7.5903 - classification_loss: 4.3373 - regression_loss: 0.3036 - transformation_loss: 147.4708 386/1790 [=====>........................] - ETA: 8:56 - loss: 7.5783 - classification_loss: 4.3281 - regression_loss: 0.3036 - transformation_loss: 147.3292 387/1790 [=====>........................] - ETA: 8:55 - loss: 7.5623 - classification_loss: 4.3188 - regression_loss: 0.3032 - transformation_loss: 147.0110 388/1790 [=====>........................] - ETA: 8:54 - loss: 7.5525 - classification_loss: 4.3102 - regression_loss: 0.3035 - transformation_loss: 146.9357 389/1790 [=====>........................] - ETA: 8:54 - loss: 7.5414 - classification_loss: 4.3011 - regression_loss: 0.3034 - transformation_loss: 146.8485 390/1790 [=====>........................] - ETA: 8:53 - loss: 7.5277 - classification_loss: 4.2935 - regression_loss: 0.3031 - transformation_loss: 146.5542 391/1790 [=====>........................] - ETA: 8:52 - loss: 7.5112 - classification_loss: 4.2836 - regression_loss: 0.3025 - transformation_loss: 146.2570 392/1790 [=====>........................] - ETA: 8:52 - loss: 7.4973 - classification_loss: 4.2748 - regression_loss: 0.3021 - transformation_loss: 146.0229 393/1790 [=====>........................] - ETA: 8:51 - loss: 7.4821 - classification_loss: 4.2650 - regression_loss: 0.3016 - transformation_loss: 145.7778 394/1790 [=====>........................] - ETA: 8:50 - loss: 7.4923 - classification_loss: 4.2577 - regression_loss: 0.3016 - transformation_loss: 146.6462 395/1790 [=====>........................] - ETA: 8:49 - loss: 7.4759 - classification_loss: 4.2478 - regression_loss: 0.3009 - transformation_loss: 146.3584 396/1790 [=====>........................] - ETA: 8:49 - loss: 7.4615 - classification_loss: 4.2393 - regression_loss: 0.3007 - transformation_loss: 146.0791 397/1790 [=====>........................] - ETA: 8:48 - loss: 7.4470 - classification_loss: 4.2301 - regression_loss: 0.3004 - transformation_loss: 145.8214 398/1790 [=====>........................] - ETA: 8:47 - loss: 7.4329 - classification_loss: 4.2210 - regression_loss: 0.3000 - transformation_loss: 145.5971 399/1790 [=====>........................] - ETA: 8:46 - loss: 7.4259 - classification_loss: 4.2121 - regression_loss: 0.3008 - transformation_loss: 145.6528 400/1790 [=====>........................] - ETA: 8:46 - loss: 7.4283 - classification_loss: 4.2071 - regression_loss: 0.3058 - transformation_loss: 145.7690 401/1790 [=====>........................] - ETA: 8:45 - loss: 7.4146 - classification_loss: 4.1978 - regression_loss: 0.3058 - transformation_loss: 145.5493 402/1790 [=====>........................] - ETA: 8:44 - loss: 7.4062 - classification_loss: 4.1895 - regression_loss: 0.3057 - transformation_loss: 145.5477 403/1790 [=====>........................] - ETA: 8:43 - loss: 7.3971 - classification_loss: 4.1815 - regression_loss: 0.3054 - transformation_loss: 145.5108 404/1790 [=====>........................] - ETA: 8:43 - loss: 7.3826 - classification_loss: 4.1726 - regression_loss: 0.3050 - transformation_loss: 145.2461 405/1790 [=====>........................] - ETA: 8:42 - loss: 7.3704 - classification_loss: 4.1651 - regression_loss: 0.3050 - transformation_loss: 145.0122 406/1790 [=====>........................] - ETA: 8:41 - loss: 7.3548 - classification_loss: 4.1555 - regression_loss: 0.3044 - transformation_loss: 144.7439 407/1790 [=====>........................] - ETA: 8:41 - loss: 7.3407 - classification_loss: 4.1470 - regression_loss: 0.3043 - transformation_loss: 144.4697 408/1790 [=====>........................] - ETA: 8:40 - loss: 7.3255 - classification_loss: 4.1380 - regression_loss: 0.3036 - transformation_loss: 144.1947 409/1790 [=====>........................] - ETA: 8:39 - loss: 7.3115 - classification_loss: 4.1299 - regression_loss: 0.3034 - transformation_loss: 143.9091Error: A logdir or db must be specified. For example `tensorboard --logdir mylogdir` or `tensorboard --db sqlite:~/.tensorboard.db`. Run `tensorboard --helpfull` for details and examples.
 410/1790 [=====>........................] - ETA: 8:39 - loss: 7.3042 - classification_loss: 4.1244 - regression_loss: 0.3038 - transformation_loss: 143.8007 411/1790 [=====>........................] - ETA: 8:38 - loss: 7.2901 - classification_loss: 4.1160 - regression_loss: 0.3032 - transformation_loss: 143.5432 412/1790 [=====>........................] - ETA: 8:37 - loss: 7.2787 - classification_loss: 4.1072 - regression_loss: 0.3029 - transformation_loss: 143.4304 413/1790 [=====>........................] - ETA: 8:37 - loss: 7.2682 - classification_loss: 4.0992 - regression_loss: 0.3031 - transformation_loss: 143.2906 414/1790 [=====>........................] - ETA: 8:36 - loss: 7.2547 - classification_loss: 4.0909 - regression_loss: 0.3031 - transformation_loss: 143.0341 415/1790 [=====>........................] - ETA: 8:35 - loss: 7.2439 - classification_loss: 4.0830 - regression_loss: 0.3026 - transformation_loss: 142.9157 416/1790 [=====>........................] - ETA: 8:35 - loss: 7.2299 - classification_loss: 4.0739 - regression_loss: 0.3022 - transformation_loss: 142.6901 417/1790 [=====>........................] - ETA: 8:34 - loss: 7.2179 - classification_loss: 4.0657 - regression_loss: 0.3020 - transformation_loss: 142.5056 418/1790 [======>.......................] - ETA: 8:33 - loss: 7.2064 - classification_loss: 4.0618 - regression_loss: 0.3013 - transformation_loss: 142.1647 419/1790 [======>.......................] - ETA: 8:33 - loss: 7.1937 - classification_loss: 4.0538 - regression_loss: 0.3011 - transformation_loss: 141.9348 420/1790 [======>.......................] - ETA: 8:32 - loss: 7.1805 - classification_loss: 4.0453 - regression_loss: 0.3008 - transformation_loss: 141.7231 421/1790 [======>.......................] - ETA: 8:31 - loss: 7.1792 - classification_loss: 4.0384 - regression_loss: 0.3008 - transformation_loss: 141.9973 422/1790 [======>.......................] - ETA: 8:31 - loss: 7.1724 - classification_loss: 4.0306 - regression_loss: 0.3004 - transformation_loss: 142.0675 423/1790 [======>.......................] - ETA: 8:30 - loss: 7.1615 - classification_loss: 4.0234 - regression_loss: 0.3005 - transformation_loss: 141.8849 424/1790 [======>.......................] - ETA: 8:29 - loss: 7.1599 - classification_loss: 4.0169 - regression_loss: 0.3015 - transformation_loss: 142.0769 425/1790 [======>.......................] - ETA: 8:29 - loss: 7.1473 - classification_loss: 4.0090 - regression_loss: 0.3012 - transformation_loss: 141.8582 426/1790 [======>.......................] - ETA: 8:28 - loss: 7.1350 - classification_loss: 4.0016 - regression_loss: 0.3009 - transformation_loss: 141.6260 427/1790 [======>.......................] - ETA: 8:27 - loss: 7.1215 - classification_loss: 3.9935 - regression_loss: 0.3006 - transformation_loss: 141.3740 428/1790 [======>.......................] - ETA: 8:27 - loss: 7.1120 - classification_loss: 3.9858 - regression_loss: 0.3006 - transformation_loss: 141.2816 429/1790 [======>.......................] - ETA: 8:26 - loss: 7.1002 - classification_loss: 3.9782 - regression_loss: 0.3001 - transformation_loss: 141.0942 430/1790 [======>.......................] - ETA: 8:26 - loss: 7.0873 - classification_loss: 3.9701 - regression_loss: 0.2997 - transformation_loss: 140.8738 431/1790 [======>.......................] - ETA: 8:25 - loss: 7.0767 - classification_loss: 3.9622 - regression_loss: 0.2994 - transformation_loss: 140.7553 432/1790 [======>.......................] - ETA: 8:24 - loss: 7.0665 - classification_loss: 3.9544 - regression_loss: 0.2991 - transformation_loss: 140.6529 433/1790 [======>.......................] - ETA: 8:23 - loss: 7.0633 - classification_loss: 3.9554 - regression_loss: 0.2995 - transformation_loss: 140.4161 434/1790 [======>.......................] - ETA: 8:23 - loss: 7.0501 - classification_loss: 3.9474 - regression_loss: 0.2993 - transformation_loss: 140.1703 435/1790 [======>.......................] - ETA: 8:22 - loss: 7.0380 - classification_loss: 3.9395 - regression_loss: 0.2991 - transformation_loss: 139.9687 436/1790 [======>.......................] - ETA: 8:21 - loss: 7.0245 - classification_loss: 3.9315 - regression_loss: 0.2987 - transformation_loss: 139.7116 437/1790 [======>.......................] - ETA: 8:21 - loss: 7.0115 - classification_loss: 3.9232 - regression_loss: 0.2984 - transformation_loss: 139.5012 438/1790 [======>.......................] - ETA: 8:20 - loss: 6.9979 - classification_loss: 3.9151 - regression_loss: 0.2979 - transformation_loss: 139.2483 439/1790 [======>.......................] - ETA: 8:20 - loss: 6.9849 - classification_loss: 3.9068 - regression_loss: 0.2973 - transformation_loss: 139.0415 440/1790 [======>.......................] - ETA: 8:19 - loss: 6.9727 - classification_loss: 3.8992 - regression_loss: 0.2971 - transformation_loss: 138.8194 441/1790 [======>.......................] - ETA: 8:18 - loss: 6.9638 - classification_loss: 3.8919 - regression_loss: 0.2973 - transformation_loss: 138.7265 442/1790 [======>.......................] - ETA: 8:18 - loss: 6.9528 - classification_loss: 3.8851 - regression_loss: 0.2976 - transformation_loss: 138.5018 443/1790 [======>.......................] - ETA: 8:17 - loss: 6.9401 - classification_loss: 3.8775 - regression_loss: 0.2973 - transformation_loss: 138.2656 444/1790 [======>.......................] - ETA: 8:16 - loss: 6.9284 - classification_loss: 3.8707 - regression_loss: 0.2970 - transformation_loss: 138.0321 445/1790 [======>.......................] - ETA: 8:16 - loss: 6.9188 - classification_loss: 3.8634 - regression_loss: 0.2969 - transformation_loss: 137.9230 446/1790 [======>.......................] - ETA: 8:15 - loss: 6.9152 - classification_loss: 3.8572 - regression_loss: 0.2973 - transformation_loss: 138.0361 447/1790 [======>.......................] - ETA: 8:15 - loss: 6.9042 - classification_loss: 3.8497 - regression_loss: 0.2969 - transformation_loss: 137.8813 448/1790 [======>.......................] - ETA: 8:14 - loss: 6.8952 - classification_loss: 3.8435 - regression_loss: 0.2969 - transformation_loss: 137.7406 449/1790 [======>.......................] - ETA: 8:13 - loss: 6.8853 - classification_loss: 3.8371 - regression_loss: 0.2969 - transformation_loss: 137.5600 450/1790 [======>.......................] - ETA: 8:13 - loss: 6.8772 - classification_loss: 3.8306 - regression_loss: 0.2971 - transformation_loss: 137.4699 451/1790 [======>.......................] - ETA: 8:12 - loss: 6.8647 - classification_loss: 3.8233 - regression_loss: 0.2969 - transformation_loss: 137.2222 452/1790 [======>.......................] - ETA: 8:11 - loss: 6.8548 - classification_loss: 3.8162 - regression_loss: 0.2971 - transformation_loss: 137.0758 453/1790 [======>.......................] - ETA: 8:11 - loss: 6.8420 - classification_loss: 3.8084 - regression_loss: 0.2965 - transformation_loss: 136.8599 454/1790 [======>.......................] - ETA: 8:10 - loss: 6.8313 - classification_loss: 3.8016 - regression_loss: 0.2963 - transformation_loss: 136.6685 455/1790 [======>.......................] - ETA: 8:10 - loss: 6.8231 - classification_loss: 3.7949 - regression_loss: 0.2964 - transformation_loss: 136.5897 456/1790 [======>.......................] - ETA: 8:09 - loss: 6.8132 - classification_loss: 3.7917 - regression_loss: 0.2957 - transformation_loss: 136.2902 457/1790 [======>.......................] - ETA: 8:08 - loss: 6.8021 - classification_loss: 3.7845 - regression_loss: 0.2952 - transformation_loss: 136.1189 458/1790 [======>.......................] - ETA: 8:08 - loss: 6.7910 - classification_loss: 3.7777 - regression_loss: 0.2949 - transformation_loss: 135.9165 459/1790 [======>.......................] - ETA: 8:07 - loss: 6.7807 - classification_loss: 3.7706 - regression_loss: 0.2947 - transformation_loss: 135.7664 460/1790 [======>.......................] - ETA: 8:06 - loss: 6.7943 - classification_loss: 3.7672 - regression_loss: 0.2959 - transformation_loss: 136.5614 461/1790 [======>.......................] - ETA: 8:06 - loss: 6.7848 - classification_loss: 3.7610 - regression_loss: 0.2959 - transformation_loss: 136.3957 462/1790 [======>.......................] - ETA: 8:05 - loss: 6.7766 - classification_loss: 3.7547 - regression_loss: 0.2960 - transformation_loss: 136.2923 463/1790 [======>.......................] - ETA: 8:05 - loss: 6.7650 - classification_loss: 3.7475 - regression_loss: 0.2958 - transformation_loss: 136.0852 464/1790 [======>.......................] - ETA: 8:04 - loss: 6.7782 - classification_loss: 3.7472 - regression_loss: 0.2963 - transformation_loss: 136.7348 465/1790 [======>.......................] - ETA: 8:03 - loss: 6.7747 - classification_loss: 3.7415 - regression_loss: 0.2966 - transformation_loss: 136.8301 466/1790 [======>.......................] - ETA: 8:03 - loss: 6.7626 - classification_loss: 3.7342 - regression_loss: 0.2962 - transformation_loss: 136.6111 467/1790 [======>.......................] - ETA: 8:02 - loss: 6.7517 - classification_loss: 3.7268 - regression_loss: 0.2956 - transformation_loss: 136.4641 468/1790 [======>.......................] - ETA: 8:01 - loss: 6.7411 - classification_loss: 3.7203 - regression_loss: 0.2956 - transformation_loss: 136.2617 469/1790 [======>.......................] - ETA: 8:01 - loss: 6.7333 - classification_loss: 3.7139 - regression_loss: 0.2960 - transformation_loss: 136.1676 470/1790 [======>.......................] - ETA: 8:00 - loss: 6.7232 - classification_loss: 3.7074 - regression_loss: 0.2958 - transformation_loss: 135.9962 471/1790 [======>.......................] - ETA: 8:00 - loss: 6.7145 - classification_loss: 3.7002 - regression_loss: 0.2953 - transformation_loss: 135.9541 472/1790 [======>.......................] - ETA: 7:59 - loss: 6.7023 - classification_loss: 3.6930 - regression_loss: 0.2948 - transformation_loss: 135.7270 473/1790 [======>.......................] - ETA: 7:58 - loss: 6.6928 - classification_loss: 3.6866 - regression_loss: 0.2944 - transformation_loss: 135.5895 474/1790 [======>.......................] - ETA: 7:58 - loss: 6.6820 - classification_loss: 3.6794 - regression_loss: 0.2944 - transformation_loss: 135.4099 475/1790 [======>.......................] - ETA: 7:57 - loss: 6.6737 - classification_loss: 3.6731 - regression_loss: 0.2942 - transformation_loss: 135.3211 476/1790 [======>.......................] - ETA: 7:57 - loss: 6.6708 - classification_loss: 3.6673 - regression_loss: 0.2944 - transformation_loss: 135.4517 477/1790 [======>.......................] - ETA: 7:56 - loss: 6.6587 - classification_loss: 3.6603 - regression_loss: 0.2939 - transformation_loss: 135.2247 478/1790 [=======>......................] - ETA: 7:55 - loss: 6.6471 - classification_loss: 3.6532 - regression_loss: 0.2935 - transformation_loss: 135.0185 479/1790 [=======>......................] - ETA: 7:55 - loss: 6.6373 - classification_loss: 3.6473 - regression_loss: 0.2930 - transformation_loss: 134.8456 480/1790 [=======>......................] - ETA: 7:54 - loss: 6.6283 - classification_loss: 3.6417 - regression_loss: 0.2929 - transformation_loss: 134.6878 481/1790 [=======>......................] - ETA: 7:54 - loss: 6.6182 - classification_loss: 3.6353 - regression_loss: 0.2925 - transformation_loss: 134.5217 482/1790 [=======>......................] - ETA: 7:53 - loss: 6.6108 - classification_loss: 3.6294 - regression_loss: 0.2925 - transformation_loss: 134.4486 483/1790 [=======>......................] - ETA: 7:52 - loss: 6.6086 - classification_loss: 3.6248 - regression_loss: 0.2922 - transformation_loss: 134.5800 484/1790 [=======>......................] - ETA: 7:52 - loss: 6.5971 - classification_loss: 3.6183 - regression_loss: 0.2917 - transformation_loss: 134.3538 485/1790 [=======>......................] - ETA: 7:51 - loss: 6.5888 - classification_loss: 3.6122 - regression_loss: 0.2913 - transformation_loss: 134.2670 486/1790 [=======>......................] - ETA: 7:51 - loss: 6.5899 - classification_loss: 3.6071 - regression_loss: 0.2915 - transformation_loss: 134.5666 487/1790 [=======>......................] - ETA: 7:50 - loss: 6.5781 - classification_loss: 3.6003 - regression_loss: 0.2911 - transformation_loss: 134.3366 488/1790 [=======>......................] - ETA: 7:50 - loss: 6.5676 - classification_loss: 3.5936 - regression_loss: 0.2907 - transformation_loss: 134.1672 489/1790 [=======>......................] - ETA: 7:49 - loss: 6.5587 - classification_loss: 3.5870 - regression_loss: 0.2903 - transformation_loss: 134.0692 490/1790 [=======>......................] - ETA: 7:48 - loss: 6.5481 - classification_loss: 3.5810 - regression_loss: 0.2901 - transformation_loss: 133.8505 491/1790 [=======>......................] - ETA: 7:48 - loss: 6.5380 - classification_loss: 3.5745 - regression_loss: 0.2897 - transformation_loss: 133.6875 492/1790 [=======>......................] - ETA: 7:47 - loss: 6.5278 - classification_loss: 3.5683 - regression_loss: 0.2896 - transformation_loss: 133.4964 493/1790 [=======>......................] - ETA: 7:47 - loss: 6.5203 - classification_loss: 3.5668 - regression_loss: 0.2890 - transformation_loss: 133.2257 494/1790 [=======>......................] - ETA: 7:46 - loss: 6.5118 - classification_loss: 3.5617 - regression_loss: 0.2891 - transformation_loss: 133.0471 495/1790 [=======>......................] - ETA: 7:46 - loss: 6.5026 - classification_loss: 3.5558 - regression_loss: 0.2888 - transformation_loss: 132.8992 496/1790 [=======>......................] - ETA: 7:45 - loss: 6.4943 - classification_loss: 3.5507 - regression_loss: 0.2891 - transformation_loss: 132.7294 497/1790 [=======>......................] - ETA: 7:44 - loss: 6.4859 - classification_loss: 3.5449 - regression_loss: 0.2887 - transformation_loss: 132.6102 498/1790 [=======>......................] - ETA: 7:44 - loss: 6.4765 - classification_loss: 3.5391 - regression_loss: 0.2886 - transformation_loss: 132.4445 499/1790 [=======>......................] - ETA: 7:43 - loss: 6.4659 - classification_loss: 3.5330 - regression_loss: 0.2883 - transformation_loss: 132.2335 500/1790 [=======>......................] - ETA: 7:43 - loss: 6.4577 - classification_loss: 3.5274 - regression_loss: 0.2881 - transformation_loss: 132.1093 501/1790 [=======>......................] - ETA: 7:42 - loss: 6.4510 - classification_loss: 3.5220 - regression_loss: 0.2881 - transformation_loss: 132.0425 502/1790 [=======>......................] - ETA: 7:42 - loss: 6.4414 - classification_loss: 3.5161 - regression_loss: 0.2880 - transformation_loss: 131.8593 503/1790 [=======>......................] - ETA: 7:41 - loss: 6.4338 - classification_loss: 3.5110 - regression_loss: 0.2879 - transformation_loss: 131.7430 504/1790 [=======>......................] - ETA: 7:41 - loss: 6.4259 - classification_loss: 3.5056 - regression_loss: 0.2879 - transformation_loss: 131.6239 505/1790 [=======>......................] - ETA: 7:40 - loss: 6.4227 - classification_loss: 3.4996 - regression_loss: 0.2874 - transformation_loss: 131.7871 506/1790 [=======>......................] - ETA: 7:39 - loss: 6.4142 - classification_loss: 3.4932 - regression_loss: 0.2871 - transformation_loss: 131.6964 507/1790 [=======>......................] - ETA: 7:39 - loss: 6.4044 - classification_loss: 3.4872 - regression_loss: 0.2867 - transformation_loss: 131.5263 508/1790 [=======>......................] - ETA: 7:38 - loss: 6.3944 - classification_loss: 3.4809 - regression_loss: 0.2863 - transformation_loss: 131.3602 509/1790 [=======>......................] - ETA: 7:38 - loss: 6.3855 - classification_loss: 3.4750 - regression_loss: 0.2859 - transformation_loss: 131.2321 510/1790 [=======>......................] - ETA: 7:37 - loss: 6.3775 - classification_loss: 3.4701 - regression_loss: 0.2858 - transformation_loss: 131.0796 511/1790 [=======>......................] - ETA: 7:37 - loss: 6.3697 - classification_loss: 3.4638 - regression_loss: 0.2854 - transformation_loss: 131.0199 512/1790 [=======>......................] - ETA: 7:36 - loss: 6.3754 - classification_loss: 3.4624 - regression_loss: 0.2878 - transformation_loss: 131.2636 513/1790 [=======>......................] - ETA: 7:36 - loss: 6.3664 - classification_loss: 3.4570 - regression_loss: 0.2874 - transformation_loss: 131.0998 514/1790 [=======>......................] - ETA: 7:35 - loss: 6.3560 - classification_loss: 3.4509 - regression_loss: 0.2871 - transformation_loss: 130.8997 515/1790 [=======>......................] - ETA: 7:35 - loss: 6.3510 - classification_loss: 3.4461 - regression_loss: 0.2876 - transformation_loss: 130.8700 516/1790 [=======>......................] - ETA: 7:34 - loss: 6.3449 - classification_loss: 3.4407 - regression_loss: 0.2872 - transformation_loss: 130.8452 517/1790 [=======>......................] - ETA: 7:34 - loss: 6.3514 - classification_loss: 3.4361 - regression_loss: 0.2875 - transformation_loss: 131.3853 518/1790 [=======>......................] - ETA: 7:33 - loss: 6.3491 - classification_loss: 3.4311 - regression_loss: 0.2875 - transformation_loss: 131.5220 519/1790 [=======>......................] - ETA: 7:32 - loss: 6.3407 - classification_loss: 3.4256 - regression_loss: 0.2872 - transformation_loss: 131.3945 520/1790 [=======>......................] - ETA: 7:32 - loss: 6.3321 - classification_loss: 3.4205 - regression_loss: 0.2873 - transformation_loss: 131.2188 521/1790 [=======>......................] - ETA: 7:31 - loss: 6.3237 - classification_loss: 3.4154 - regression_loss: 0.2874 - transformation_loss: 131.0479 522/1790 [=======>......................] - ETA: 7:31 - loss: 6.3156 - classification_loss: 3.4097 - regression_loss: 0.2870 - transformation_loss: 130.9434 523/1790 [=======>......................] - ETA: 7:30 - loss: 6.3051 - classification_loss: 3.4036 - regression_loss: 0.2866 - transformation_loss: 130.7443 524/1790 [=======>......................] - ETA: 7:30 - loss: 6.2951 - classification_loss: 3.3977 - regression_loss: 0.2864 - transformation_loss: 130.5497 525/1790 [=======>......................] - ETA: 7:29 - loss: 6.2865 - classification_loss: 3.3926 - regression_loss: 0.2861 - transformation_loss: 130.3870 526/1790 [=======>......................] - ETA: 7:29 - loss: 6.2789 - classification_loss: 3.3875 - regression_loss: 0.2861 - transformation_loss: 130.2641 527/1790 [=======>......................] - ETA: 7:28 - loss: 6.2775 - classification_loss: 3.3829 - regression_loss: 0.2863 - transformation_loss: 130.4125 528/1790 [=======>......................] - ETA: 7:27 - loss: 6.2674 - classification_loss: 3.3772 - regression_loss: 0.2859 - transformation_loss: 130.2177 529/1790 [=======>......................] - ETA: 7:27 - loss: 6.2599 - classification_loss: 3.3726 - regression_loss: 0.2859 - transformation_loss: 130.0702 530/1790 [=======>......................] - ETA: 7:26 - loss: 6.2509 - classification_loss: 3.3672 - regression_loss: 0.2858 - transformation_loss: 129.8966 531/1790 [=======>......................] - ETA: 7:26 - loss: 6.2426 - classification_loss: 3.3619 - regression_loss: 0.2853 - transformation_loss: 129.7695 532/1790 [=======>......................] - ETA: 7:25 - loss: 6.2348 - classification_loss: 3.3564 - regression_loss: 0.2852 - transformation_loss: 129.6596 533/1790 [=======>......................] - ETA: 7:25 - loss: 6.2260 - classification_loss: 3.3509 - regression_loss: 0.2849 - transformation_loss: 129.5130 534/1790 [=======>......................] - ETA: 7:24 - loss: 6.2173 - classification_loss: 3.3452 - regression_loss: 0.2845 - transformation_loss: 129.3825 535/1790 [=======>......................] - ETA: 7:24 - loss: 6.2088 - classification_loss: 3.3399 - regression_loss: 0.2843 - transformation_loss: 129.2281 536/1790 [=======>......................] - ETA: 7:23 - loss: 6.2000 - classification_loss: 3.3346 - regression_loss: 0.2841 - transformation_loss: 129.0637 537/1790 [========>.....................] - ETA: 7:23 - loss: 6.1913 - classification_loss: 3.3296 - regression_loss: 0.2839 - transformation_loss: 128.8899 538/1790 [========>.....................] - ETA: 7:22 - loss: 6.1823 - classification_loss: 3.3237 - regression_loss: 0.2836 - transformation_loss: 128.7484 539/1790 [========>.....................] - ETA: 7:22 - loss: 6.1735 - classification_loss: 3.3183 - regression_loss: 0.2832 - transformation_loss: 128.5956 540/1790 [========>.....................] - ETA: 7:21 - loss: 6.1643 - classification_loss: 3.3127 - regression_loss: 0.2830 - transformation_loss: 128.4286 541/1790 [========>.....................] - ETA: 7:21 - loss: 6.1556 - classification_loss: 3.3079 - regression_loss: 0.2828 - transformation_loss: 128.2459 542/1790 [========>.....................] - ETA: 7:20 - loss: 6.1469 - classification_loss: 3.3027 - regression_loss: 0.2824 - transformation_loss: 128.0912 543/1790 [========>.....................] - ETA: 7:20 - loss: 6.1526 - classification_loss: 3.2986 - regression_loss: 0.2824 - transformation_loss: 128.5808 544/1790 [========>.....................] - ETA: 7:19 - loss: 6.1441 - classification_loss: 3.2933 - regression_loss: 0.2821 - transformation_loss: 128.4333 545/1790 [========>.....................] - ETA: 7:19 - loss: 6.1354 - classification_loss: 3.2879 - regression_loss: 0.2818 - transformation_loss: 128.2871 546/1790 [========>.....................] - ETA: 7:18 - loss: 6.1264 - classification_loss: 3.2827 - regression_loss: 0.2815 - transformation_loss: 128.1114 547/1790 [========>.....................] - ETA: 7:18 - loss: 6.1170 - classification_loss: 3.2771 - regression_loss: 0.2812 - transformation_loss: 127.9364 548/1790 [========>.....................] - ETA: 7:17 - loss: 6.1100 - classification_loss: 3.2721 - regression_loss: 0.2809 - transformation_loss: 127.8522 549/1790 [========>.....................] - ETA: 7:17 - loss: 6.1012 - classification_loss: 3.2671 - regression_loss: 0.2807 - transformation_loss: 127.6712 550/1790 [========>.....................] - ETA: 7:16 - loss: 6.0927 - classification_loss: 3.2618 - regression_loss: 0.2802 - transformation_loss: 127.5304 551/1790 [========>.....................] - ETA: 7:16 - loss: 6.0880 - classification_loss: 3.2577 - regression_loss: 0.2805 - transformation_loss: 127.4885 552/1790 [========>.....................] - ETA: 7:15 - loss: 6.0798 - classification_loss: 3.2533 - regression_loss: 0.2803 - transformation_loss: 127.3158 553/1790 [========>.....................] - ETA: 7:15 - loss: 6.0722 - classification_loss: 3.2477 - regression_loss: 0.2799 - transformation_loss: 127.2327 554/1790 [========>.....................] - ETA: 7:14 - loss: 6.0630 - classification_loss: 3.2423 - regression_loss: 0.2794 - transformation_loss: 127.0625 555/1790 [========>.....................] - ETA: 7:14 - loss: 6.0555 - classification_loss: 3.2376 - regression_loss: 0.2796 - transformation_loss: 126.9114 556/1790 [========>.....................] - ETA: 7:13 - loss: 6.0482 - classification_loss: 3.2332 - regression_loss: 0.2797 - transformation_loss: 126.7624 557/1790 [========>.....................] - ETA: 7:12 - loss: 6.0418 - classification_loss: 3.2284 - regression_loss: 0.2796 - transformation_loss: 126.6920 558/1790 [========>.....................] - ETA: 7:12 - loss: 6.0334 - classification_loss: 3.2235 - regression_loss: 0.2795 - transformation_loss: 126.5177 559/1790 [========>.....................] - ETA: 7:12 - loss: 6.0240 - classification_loss: 3.2181 - regression_loss: 0.2791 - transformation_loss: 126.3435 560/1790 [========>.....................] - ETA: 7:11 - loss: 6.0217 - classification_loss: 3.2136 - regression_loss: 0.2796 - transformation_loss: 126.4251 561/1790 [========>.....................] - ETA: 7:10 - loss: 6.0136 - classification_loss: 3.2094 - regression_loss: 0.2792 - transformation_loss: 126.2460 562/1790 [========>.....................] - ETA: 7:10 - loss: 6.0086 - classification_loss: 3.2057 - regression_loss: 0.2792 - transformation_loss: 126.1882 563/1790 [========>.....................] - ETA: 7:09 - loss: 6.0008 - classification_loss: 3.2010 - regression_loss: 0.2788 - transformation_loss: 126.0476 564/1790 [========>.....................] - ETA: 7:09 - loss: 5.9936 - classification_loss: 3.1965 - regression_loss: 0.2786 - transformation_loss: 125.9244 565/1790 [========>.....................] - ETA: 7:08 - loss: 5.9862 - classification_loss: 3.1918 - regression_loss: 0.2782 - transformation_loss: 125.8110 566/1790 [========>.....................] - ETA: 7:08 - loss: 5.9776 - classification_loss: 3.1867 - regression_loss: 0.2779 - transformation_loss: 125.6509 567/1790 [========>.....................] - ETA: 7:07 - loss: 5.9696 - classification_loss: 3.1822 - regression_loss: 0.2778 - transformation_loss: 125.4816 568/1790 [========>.....................] - ETA: 7:07 - loss: 5.9629 - classification_loss: 3.1776 - regression_loss: 0.2776 - transformation_loss: 125.3852 569/1790 [========>.....................] - ETA: 7:06 - loss: 5.9548 - classification_loss: 3.1729 - regression_loss: 0.2774 - transformation_loss: 125.2252 570/1790 [========>.....................] - ETA: 7:06 - loss: 5.9475 - classification_loss: 3.1686 - regression_loss: 0.2773 - transformation_loss: 125.0770 571/1790 [========>.....................] - ETA: 7:05 - loss: 5.9398 - classification_loss: 3.1638 - regression_loss: 0.2772 - transformation_loss: 124.9397 572/1790 [========>.....................] - ETA: 7:05 - loss: 5.9332 - classification_loss: 3.1595 - regression_loss: 0.2775 - transformation_loss: 124.8051 573/1790 [========>.....................] - ETA: 7:04 - loss: 5.9254 - classification_loss: 3.1549 - regression_loss: 0.2773 - transformation_loss: 124.6580 574/1790 [========>.....................] - ETA: 7:04 - loss: 5.9180 - classification_loss: 3.1508 - regression_loss: 0.2773 - transformation_loss: 124.4971 575/1790 [========>.....................] - ETA: 7:03 - loss: 5.9103 - classification_loss: 3.1461 - regression_loss: 0.2772 - transformation_loss: 124.3500 576/1790 [========>.....................] - ETA: 7:03 - loss: 5.9258 - classification_loss: 3.1436 - regression_loss: 0.2775 - transformation_loss: 125.2342 577/1790 [========>.....................] - ETA: 7:03 - loss: 5.9174 - classification_loss: 3.1387 - regression_loss: 0.2773 - transformation_loss: 125.0674 578/1790 [========>.....................] - ETA: 7:02 - loss: 5.9118 - classification_loss: 3.1344 - regression_loss: 0.2775 - transformation_loss: 124.9924 579/1790 [========>.....................] - ETA: 7:02 - loss: 5.9037 - classification_loss: 3.1296 - regression_loss: 0.2772 - transformation_loss: 124.8472 580/1790 [========>.....................] - ETA: 7:01 - loss: 5.8960 - classification_loss: 3.1251 - regression_loss: 0.2768 - transformation_loss: 124.7043 581/1790 [========>.....................] - ETA: 7:01 - loss: 5.8876 - classification_loss: 3.1201 - regression_loss: 0.2765 - transformation_loss: 124.5536 582/1790 [========>.....................] - ETA: 7:00 - loss: 5.8805 - classification_loss: 3.1157 - regression_loss: 0.2765 - transformation_loss: 124.4172 583/1790 [========>.....................] - ETA: 7:00 - loss: 5.8847 - classification_loss: 3.1191 - regression_loss: 0.2770 - transformation_loss: 124.4328 584/1790 [========>.....................] - ETA: 6:59 - loss: 5.8785 - classification_loss: 3.1147 - regression_loss: 0.2769 - transformation_loss: 124.3411 585/1790 [========>.....................] - ETA: 6:59 - loss: 5.8717 - classification_loss: 3.1111 - regression_loss: 0.2768 - transformation_loss: 124.1887 586/1790 [========>.....................] - ETA: 6:58 - loss: 5.8641 - classification_loss: 3.1063 - regression_loss: 0.2765 - transformation_loss: 124.0633 587/1790 [========>.....................] - ETA: 6:58 - loss: 5.8568 - classification_loss: 3.1013 - regression_loss: 0.2761 - transformation_loss: 123.9686 588/1790 [========>.....................] - ETA: 6:57 - loss: 5.8487 - classification_loss: 3.0964 - regression_loss: 0.2757 - transformation_loss: 123.8308 589/1790 [========>.....................] - ETA: 6:57 - loss: 5.8406 - classification_loss: 3.0917 - regression_loss: 0.2755 - transformation_loss: 123.6637 590/1790 [========>.....................] - ETA: 6:56 - loss: 5.8339 - classification_loss: 3.0871 - regression_loss: 0.2754 - transformation_loss: 123.5715 591/1790 [========>.....................] - ETA: 6:56 - loss: 5.8259 - classification_loss: 3.0828 - regression_loss: 0.2751 - transformation_loss: 123.4023 592/1790 [========>.....................] - ETA: 6:55 - loss: 5.8178 - classification_loss: 3.0781 - regression_loss: 0.2747 - transformation_loss: 123.2510 593/1790 [========>.....................] - ETA: 6:55 - loss: 5.8112 - classification_loss: 3.0743 - regression_loss: 0.2746 - transformation_loss: 123.1157 594/1790 [========>.....................] - ETA: 6:54 - loss: 5.8027 - classification_loss: 3.0694 - regression_loss: 0.2743 - transformation_loss: 122.9489 595/1790 [========>.....................] - ETA: 6:54 - loss: 5.7951 - classification_loss: 3.0651 - regression_loss: 0.2740 - transformation_loss: 122.7957 596/1790 [========>.....................] - ETA: 6:53 - loss: 5.7875 - classification_loss: 3.0606 - regression_loss: 0.2738 - transformation_loss: 122.6562 597/1790 [=========>....................] - ETA: 6:53 - loss: 5.8113 - classification_loss: 3.0705 - regression_loss: 0.2744 - transformation_loss: 123.3207 598/1790 [=========>....................] - ETA: 6:52 - loss: 5.8041 - classification_loss: 3.0664 - regression_loss: 0.2742 - transformation_loss: 123.1769 599/1790 [=========>....................] - ETA: 6:52 - loss: 5.7970 - classification_loss: 3.0619 - regression_loss: 0.2741 - transformation_loss: 123.0503 600/1790 [=========>....................] - ETA: 6:51 - loss: 5.8017 - classification_loss: 3.0634 - regression_loss: 0.2758 - transformation_loss: 123.1266 601/1790 [=========>....................] - ETA: 6:51 - loss: 5.8060 - classification_loss: 3.0614 - regression_loss: 0.2763 - transformation_loss: 123.4193 602/1790 [=========>....................] - ETA: 6:50 - loss: 5.8018 - classification_loss: 3.0573 - regression_loss: 0.2762 - transformation_loss: 123.4132 603/1790 [=========>....................] - ETA: 6:50 - loss: 5.7953 - classification_loss: 3.0531 - regression_loss: 0.2759 - transformation_loss: 123.3149 604/1790 [=========>....................] - ETA: 6:49 - loss: 5.7888 - classification_loss: 3.0497 - regression_loss: 0.2757 - transformation_loss: 123.1674 605/1790 [=========>....................] - ETA: 6:49 - loss: 5.7812 - classification_loss: 3.0455 - regression_loss: 0.2754 - transformation_loss: 123.0159 606/1790 [=========>....................] - ETA: 6:48 - loss: 5.7765 - classification_loss: 3.0422 - regression_loss: 0.2754 - transformation_loss: 122.9401 607/1790 [=========>....................] - ETA: 6:48 - loss: 5.7692 - classification_loss: 3.0378 - regression_loss: 0.2750 - transformation_loss: 122.8152 608/1790 [=========>....................] - ETA: 6:48 - loss: 5.7640 - classification_loss: 3.0341 - regression_loss: 0.2753 - transformation_loss: 122.7341 609/1790 [=========>....................] - ETA: 6:47 - loss: 5.7575 - classification_loss: 3.0307 - regression_loss: 0.2753 - transformation_loss: 122.5772 610/1790 [=========>....................] - ETA: 6:47 - loss: 5.7507 - classification_loss: 3.0263 - regression_loss: 0.2750 - transformation_loss: 122.4664 611/1790 [=========>....................] - ETA: 6:46 - loss: 5.7428 - classification_loss: 3.0219 - regression_loss: 0.2746 - transformation_loss: 122.3163 612/1790 [=========>....................] - ETA: 6:46 - loss: 5.7369 - classification_loss: 3.0174 - regression_loss: 0.2743 - transformation_loss: 122.2630 613/1790 [=========>....................] - ETA: 6:45 - loss: 5.7306 - classification_loss: 3.0133 - regression_loss: 0.2740 - transformation_loss: 122.1619 614/1790 [=========>....................] - ETA: 6:45 - loss: 5.7242 - classification_loss: 3.0088 - regression_loss: 0.2736 - transformation_loss: 122.0905 615/1790 [=========>....................] - ETA: 6:44 - loss: 5.7293 - classification_loss: 3.0116 - regression_loss: 0.2740 - transformation_loss: 122.1860 616/1790 [=========>....................] - ETA: 6:44 - loss: 5.7218 - classification_loss: 3.0072 - regression_loss: 0.2736 - transformation_loss: 122.0519 617/1790 [=========>....................] - ETA: 6:43 - loss: 5.7142 - classification_loss: 3.0025 - regression_loss: 0.2732 - transformation_loss: 121.9225 618/1790 [=========>....................] - ETA: 6:43 - loss: 5.7098 - classification_loss: 2.9985 - regression_loss: 0.2733 - transformation_loss: 121.8998 619/1790 [=========>....................] - ETA: 6:42 - loss: 5.7035 - classification_loss: 2.9940 - regression_loss: 0.2730 - transformation_loss: 121.8238 620/1790 [=========>....................] - ETA: 6:42 - loss: 5.6964 - classification_loss: 2.9900 - regression_loss: 0.2729 - transformation_loss: 121.6778 621/1790 [=========>....................] - ETA: 6:41 - loss: 5.6889 - classification_loss: 2.9854 - regression_loss: 0.2725 - transformation_loss: 121.5512 622/1790 [=========>....................] - ETA: 6:41 - loss: 5.6817 - classification_loss: 2.9810 - regression_loss: 0.2723 - transformation_loss: 121.4173 623/1790 [=========>....................] - ETA: 6:41 - loss: 5.6748 - classification_loss: 2.9766 - regression_loss: 0.2720 - transformation_loss: 121.3143 624/1790 [=========>....................] - ETA: 6:40 - loss: 5.6669 - classification_loss: 2.9721 - regression_loss: 0.2716 - transformation_loss: 121.1603 625/1790 [=========>....................] - ETA: 6:40 - loss: 5.6602 - classification_loss: 2.9679 - regression_loss: 0.2714 - transformation_loss: 121.0469 626/1790 [=========>....................] - ETA: 6:39 - loss: 5.6534 - classification_loss: 2.9635 - regression_loss: 0.2710 - transformation_loss: 120.9439 627/1790 [=========>....................] - ETA: 6:39 - loss: 5.6464 - classification_loss: 2.9591 - regression_loss: 0.2708 - transformation_loss: 120.8300 628/1790 [=========>....................] - ETA: 6:38 - loss: 5.6393 - classification_loss: 2.9550 - regression_loss: 0.2704 - transformation_loss: 120.6917 629/1790 [=========>....................] - ETA: 6:38 - loss: 5.6482 - classification_loss: 2.9522 - regression_loss: 0.2703 - transformation_loss: 121.2847 630/1790 [=========>....................] - ETA: 6:37 - loss: 5.6444 - classification_loss: 2.9494 - regression_loss: 0.2706 - transformation_loss: 121.2186 631/1790 [=========>....................] - ETA: 6:37 - loss: 5.6368 - classification_loss: 2.9449 - regression_loss: 0.2703 - transformation_loss: 121.0751 632/1790 [=========>....................] - ETA: 6:37 - loss: 5.6308 - classification_loss: 2.9406 - regression_loss: 0.2701 - transformation_loss: 121.0074 633/1790 [=========>....................] - ETA: 6:36 - loss: 5.6250 - classification_loss: 2.9369 - regression_loss: 0.2698 - transformation_loss: 120.9153 634/1790 [=========>....................] - ETA: 6:36 - loss: 5.6180 - classification_loss: 2.9325 - regression_loss: 0.2695 - transformation_loss: 120.8001 635/1790 [=========>....................] - ETA: 6:35 - loss: 5.6107 - classification_loss: 2.9284 - regression_loss: 0.2692 - transformation_loss: 120.6604 636/1790 [=========>....................] - ETA: 6:35 - loss: 5.6038 - classification_loss: 2.9246 - regression_loss: 0.2689 - transformation_loss: 120.5180 637/1790 [=========>....................] - ETA: 6:34 - loss: 5.5976 - classification_loss: 2.9209 - regression_loss: 0.2687 - transformation_loss: 120.3978 638/1790 [=========>....................] - ETA: 6:34 - loss: 5.5923 - classification_loss: 2.9178 - regression_loss: 0.2686 - transformation_loss: 120.2956 639/1790 [=========>....................] - ETA: 6:33 - loss: 5.6196 - classification_loss: 2.9250 - regression_loss: 0.2700 - transformation_loss: 121.2313 640/1790 [=========>....................] - ETA: 6:33 - loss: 5.6137 - classification_loss: 2.9212 - regression_loss: 0.2700 - transformation_loss: 121.1239 641/1790 [=========>....................] - ETA: 6:33 - loss: 5.6062 - classification_loss: 2.9169 - regression_loss: 0.2697 - transformation_loss: 120.9793 642/1790 [=========>....................] - ETA: 6:32 - loss: 5.5994 - classification_loss: 2.9130 - regression_loss: 0.2695 - transformation_loss: 120.8482 643/1790 [=========>....................] - ETA: 6:32 - loss: 5.5927 - classification_loss: 2.9089 - regression_loss: 0.2691 - transformation_loss: 120.7290 644/1790 [=========>....................] - ETA: 6:31 - loss: 5.5860 - classification_loss: 2.9051 - regression_loss: 0.2689 - transformation_loss: 120.5960 645/1790 [=========>....................] - ETA: 6:31 - loss: 5.5812 - classification_loss: 2.9017 - regression_loss: 0.2690 - transformation_loss: 120.5250 646/1790 [=========>....................] - ETA: 6:30 - loss: 5.5739 - classification_loss: 2.8976 - regression_loss: 0.2686 - transformation_loss: 120.3820 647/1790 [=========>....................] - ETA: 6:30 - loss: 5.5689 - classification_loss: 2.8938 - regression_loss: 0.2684 - transformation_loss: 120.3342 648/1790 [=========>....................] - ETA: 6:29 - loss: 5.5631 - classification_loss: 2.8903 - regression_loss: 0.2681 - transformation_loss: 120.2302 649/1790 [=========>....................] - ETA: 6:29 - loss: 5.5559 - classification_loss: 2.8862 - regression_loss: 0.2679 - transformation_loss: 120.0847 650/1790 [=========>....................] - ETA: 6:29 - loss: 5.5499 - classification_loss: 2.8827 - regression_loss: 0.2679 - transformation_loss: 119.9632 651/1790 [=========>....................] - ETA: 6:28 - loss: 5.5448 - classification_loss: 2.8798 - regression_loss: 0.2678 - transformation_loss: 119.8589 652/1790 [=========>....................] - ETA: 6:28 - loss: 5.5385 - classification_loss: 2.8776 - regression_loss: 0.2674 - transformation_loss: 119.6750 653/1790 [=========>....................] - ETA: 6:27 - loss: 5.5329 - classification_loss: 2.8733 - regression_loss: 0.2671 - transformation_loss: 119.6234 654/1790 [=========>....................] - ETA: 6:27 - loss: 5.5257 - classification_loss: 2.8693 - regression_loss: 0.2668 - transformation_loss: 119.4791 655/1790 [=========>....................] - ETA: 6:26 - loss: 5.5189 - classification_loss: 2.8651 - regression_loss: 0.2665 - transformation_loss: 119.3645 656/1790 [=========>....................] - ETA: 6:26 - loss: 5.5123 - classification_loss: 2.8612 - regression_loss: 0.2664 - transformation_loss: 119.2346 657/1790 [==========>...................] - ETA: 6:25 - loss: 5.5099 - classification_loss: 2.8575 - regression_loss: 0.2665 - transformation_loss: 119.2917 658/1790 [==========>...................] - ETA: 6:25 - loss: 5.5040 - classification_loss: 2.8542 - regression_loss: 0.2663 - transformation_loss: 119.1718 659/1790 [==========>...................] - ETA: 6:25 - loss: 5.4990 - classification_loss: 2.8504 - regression_loss: 0.2660 - transformation_loss: 119.1300 660/1790 [==========>...................] - ETA: 6:24 - loss: 5.4928 - classification_loss: 2.8468 - regression_loss: 0.2657 - transformation_loss: 119.0135 661/1790 [==========>...................] - ETA: 6:24 - loss: 5.4886 - classification_loss: 2.8429 - regression_loss: 0.2656 - transformation_loss: 119.0021 662/1790 [==========>...................] - ETA: 6:23 - loss: 5.4841 - classification_loss: 2.8403 - regression_loss: 0.2656 - transformation_loss: 118.9135 663/1790 [==========>...................] - ETA: 6:23 - loss: 5.4816 - classification_loss: 2.8381 - regression_loss: 0.2662 - transformation_loss: 118.8665 664/1790 [==========>...................] - ETA: 6:22 - loss: 5.4763 - classification_loss: 2.8353 - regression_loss: 0.2660 - transformation_loss: 118.7512 665/1790 [==========>...................] - ETA: 6:22 - loss: 5.4698 - classification_loss: 2.8314 - regression_loss: 0.2657 - transformation_loss: 118.6339 666/1790 [==========>...................] - ETA: 6:22 - loss: 5.4628 - classification_loss: 2.8274 - regression_loss: 0.2653 - transformation_loss: 118.5041 667/1790 [==========>...................] - ETA: 6:21 - loss: 5.4560 - classification_loss: 2.8234 - regression_loss: 0.2651 - transformation_loss: 118.3717 668/1790 [==========>...................] - ETA: 6:21 - loss: 5.4505 - classification_loss: 2.8201 - regression_loss: 0.2649 - transformation_loss: 118.2733 669/1790 [==========>...................] - ETA: 6:20 - loss: 5.4444 - classification_loss: 2.8167 - regression_loss: 0.2647 - transformation_loss: 118.1476 670/1790 [==========>...................] - ETA: 6:20 - loss: 5.4405 - classification_loss: 2.8135 - regression_loss: 0.2647 - transformation_loss: 118.1186 671/1790 [==========>...................] - ETA: 6:19 - loss: 5.4344 - classification_loss: 2.8101 - regression_loss: 0.2645 - transformation_loss: 117.9855 672/1790 [==========>...................] - ETA: 6:19 - loss: 5.4291 - classification_loss: 2.8065 - regression_loss: 0.2644 - transformation_loss: 117.9110 673/1790 [==========>...................] - ETA: 6:18 - loss: 5.4230 - classification_loss: 2.8030 - regression_loss: 0.2641 - transformation_loss: 117.7959 674/1790 [==========>...................] - ETA: 6:18 - loss: 5.4172 - classification_loss: 2.7993 - regression_loss: 0.2639 - transformation_loss: 117.6994 675/1790 [==========>...................] - ETA: 6:18 - loss: 5.4207 - classification_loss: 2.8003 - regression_loss: 0.2679 - transformation_loss: 117.6231 676/1790 [==========>...................] - ETA: 6:17 - loss: 5.4196 - classification_loss: 2.7979 - regression_loss: 0.2679 - transformation_loss: 117.6877 677/1790 [==========>...................] - ETA: 6:17 - loss: 5.4198 - classification_loss: 2.7951 - regression_loss: 0.2678 - transformation_loss: 117.8476 678/1790 [==========>...................] - ETA: 6:16 - loss: 5.4134 - classification_loss: 2.7913 - regression_loss: 0.2676 - transformation_loss: 117.7229 679/1790 [==========>...................] - ETA: 6:16 - loss: 5.4070 - classification_loss: 2.7878 - regression_loss: 0.2673 - transformation_loss: 117.5950 680/1790 [==========>...................] - ETA: 6:15 - loss: 5.4006 - classification_loss: 2.7842 - regression_loss: 0.2671 - transformation_loss: 117.4670 681/1790 [==========>...................] - ETA: 6:15 - loss: 5.3946 - classification_loss: 2.7808 - regression_loss: 0.2670 - transformation_loss: 117.3395 682/1790 [==========>...................] - ETA: 6:15 - loss: 5.3890 - classification_loss: 2.7777 - regression_loss: 0.2667 - transformation_loss: 117.2276 683/1790 [==========>...................] - ETA: 6:14 - loss: 5.3848 - classification_loss: 2.7749 - regression_loss: 0.2667 - transformation_loss: 117.1648 684/1790 [==========>...................] - ETA: 6:14 - loss: 5.3819 - classification_loss: 2.7715 - regression_loss: 0.2664 - transformation_loss: 117.2037 685/1790 [==========>...................] - ETA: 6:13 - loss: 5.3777 - classification_loss: 2.7680 - regression_loss: 0.2662 - transformation_loss: 117.1736 686/1790 [==========>...................] - ETA: 6:13 - loss: 5.3724 - classification_loss: 2.7648 - regression_loss: 0.2660 - transformation_loss: 117.0805 687/1790 [==========>...................] - ETA: 6:12 - loss: 5.3681 - classification_loss: 2.7620 - regression_loss: 0.2660 - transformation_loss: 117.0043 688/1790 [==========>...................] - ETA: 6:12 - loss: 5.3631 - classification_loss: 2.7591 - regression_loss: 0.2659 - transformation_loss: 116.9055 689/1790 [==========>...................] - ETA: 6:11 - loss: 5.3584 - classification_loss: 2.7555 - regression_loss: 0.2657 - transformation_loss: 116.8595 690/1790 [==========>...................] - ETA: 6:11 - loss: 5.3526 - classification_loss: 2.7521 - regression_loss: 0.2654 - transformation_loss: 116.7551 691/1790 [==========>...................] - ETA: 6:11 - loss: 5.3469 - classification_loss: 2.7488 - regression_loss: 0.2653 - transformation_loss: 116.6383 692/1790 [==========>...................] - ETA: 6:10 - loss: 5.3419 - classification_loss: 2.7455 - regression_loss: 0.2652 - transformation_loss: 116.5632 693/1790 [==========>...................] - ETA: 6:10 - loss: 5.3355 - classification_loss: 2.7417 - regression_loss: 0.2650 - transformation_loss: 116.4380 694/1790 [==========>...................] - ETA: 6:09 - loss: 5.3372 - classification_loss: 2.7393 - regression_loss: 0.2650 - transformation_loss: 116.6424 695/1790 [==========>...................] - ETA: 6:09 - loss: 5.3318 - classification_loss: 2.7364 - regression_loss: 0.2649 - transformation_loss: 116.5270 696/1790 [==========>...................] - ETA: 6:09 - loss: 5.3614 - classification_loss: 2.7379 - regression_loss: 0.2953 - transformation_loss: 116.4072 697/1790 [==========>...................] - ETA: 6:08 - loss: 5.3572 - classification_loss: 2.7347 - regression_loss: 0.2950 - transformation_loss: 116.3747 698/1790 [==========>...................] - ETA: 6:08 - loss: 5.3519 - classification_loss: 2.7313 - regression_loss: 0.2947 - transformation_loss: 116.2932 699/1790 [==========>...................] - ETA: 6:07 - loss: 5.3533 - classification_loss: 2.7300 - regression_loss: 0.2978 - transformation_loss: 116.2760 700/1790 [==========>...................] - ETA: 6:07 - loss: 5.3497 - classification_loss: 2.7278 - regression_loss: 0.2979 - transformation_loss: 116.1989 701/1790 [==========>...................] - ETA: 6:06 - loss: 5.3496 - classification_loss: 2.7242 - regression_loss: 0.2976 - transformation_loss: 116.3939 702/1790 [==========>...................] - ETA: 6:06 - loss: 5.3452 - classification_loss: 2.7217 - regression_loss: 0.2976 - transformation_loss: 116.2913 703/1790 [==========>...................] - ETA: 6:06 - loss: 5.3392 - classification_loss: 2.7184 - regression_loss: 0.2973 - transformation_loss: 116.1753 704/1790 [==========>...................] - ETA: 6:05 - loss: 5.3343 - classification_loss: 2.7157 - regression_loss: 0.2971 - transformation_loss: 116.0771 705/1790 [==========>...................] - ETA: 6:05 - loss: 5.3288 - classification_loss: 2.7120 - regression_loss: 0.2968 - transformation_loss: 116.0000 706/1790 [==========>...................] - ETA: 6:04 - loss: 5.3233 - classification_loss: 2.7090 - regression_loss: 0.2965 - transformation_loss: 115.8892 707/1790 [==========>...................] - ETA: 6:04 - loss: 5.3192 - classification_loss: 2.7055 - regression_loss: 0.2962 - transformation_loss: 115.8765 708/1790 [==========>...................] - ETA: 6:03 - loss: 5.3141 - classification_loss: 2.7023 - regression_loss: 0.2959 - transformation_loss: 115.7952 709/1790 [==========>...................] - ETA: 6:03 - loss: 5.3080 - classification_loss: 2.6991 - regression_loss: 0.2956 - transformation_loss: 115.6682 710/1790 [==========>...................] - ETA: 6:03 - loss: 5.3032 - classification_loss: 2.6957 - regression_loss: 0.2954 - transformation_loss: 115.6018 711/1790 [==========>...................] - ETA: 6:02 - loss: 5.3181 - classification_loss: 2.6950 - regression_loss: 0.2963 - transformation_loss: 116.3398 712/1790 [==========>...................] - ETA: 6:02 - loss: 5.3127 - classification_loss: 2.6914 - regression_loss: 0.2961 - transformation_loss: 116.2622 713/1790 [==========>...................] - ETA: 6:01 - loss: 5.3065 - classification_loss: 2.6879 - regression_loss: 0.2958 - transformation_loss: 116.1419 714/1790 [==========>...................] - ETA: 6:01 - loss: 5.3020 - classification_loss: 2.6850 - regression_loss: 0.2956 - transformation_loss: 116.0701 715/1790 [==========>...................] - ETA: 6:01 - loss: 5.2962 - classification_loss: 2.6818 - regression_loss: 0.2954 - transformation_loss: 115.9504 716/1790 [===========>..................] - ETA: 6:00 - loss: 5.2908 - classification_loss: 2.6788 - regression_loss: 0.2950 - transformation_loss: 115.8474 717/1790 [===========>..................] - ETA: 6:00 - loss: 5.2859 - classification_loss: 2.6760 - regression_loss: 0.2950 - transformation_loss: 115.7474 718/1790 [===========>..................] - ETA: 5:59 - loss: 5.2800 - classification_loss: 2.6725 - regression_loss: 0.2946 - transformation_loss: 115.6434 719/1790 [===========>..................] - ETA: 5:59 - loss: 5.2741 - classification_loss: 2.6703 - regression_loss: 0.2942 - transformation_loss: 115.4825 720/1790 [===========>..................] - ETA: 5:58 - loss: 5.2690 - classification_loss: 2.6673 - regression_loss: 0.2939 - transformation_loss: 115.3899 721/1790 [===========>..................] - ETA: 5:58 - loss: 5.2623 - classification_loss: 2.6641 - regression_loss: 0.2935 - transformation_loss: 115.2299 722/1790 [===========>..................] - ETA: 5:57 - loss: 5.2569 - classification_loss: 2.6612 - regression_loss: 0.2933 - transformation_loss: 115.1235 723/1790 [===========>..................] - ETA: 5:57 - loss: 5.2544 - classification_loss: 2.6590 - regression_loss: 0.2936 - transformation_loss: 115.0866 724/1790 [===========>..................] - ETA: 5:57 - loss: 5.2489 - classification_loss: 2.6559 - regression_loss: 0.2933 - transformation_loss: 114.9852 725/1790 [===========>..................] - ETA: 5:56 - loss: 5.2436 - classification_loss: 2.6532 - regression_loss: 0.2931 - transformation_loss: 114.8660 726/1790 [===========>..................] - ETA: 5:56 - loss: 5.2391 - classification_loss: 2.6505 - regression_loss: 0.2931 - transformation_loss: 114.7775 727/1790 [===========>..................] - ETA: 5:55 - loss: 5.2335 - classification_loss: 2.6475 - regression_loss: 0.2928 - transformation_loss: 114.6625 728/1790 [===========>..................] - ETA: 5:55 - loss: 5.2286 - classification_loss: 2.6450 - regression_loss: 0.2927 - transformation_loss: 114.5487 729/1790 [===========>..................] - ETA: 5:55 - loss: 5.2232 - classification_loss: 2.6423 - regression_loss: 0.2923 - transformation_loss: 114.4314 730/1790 [===========>..................] - ETA: 5:54 - loss: 5.2178 - classification_loss: 2.6394 - regression_loss: 0.2920 - transformation_loss: 114.3209 731/1790 [===========>..................] - ETA: 5:54 - loss: 5.2126 - classification_loss: 2.6360 - regression_loss: 0.2918 - transformation_loss: 114.2410 732/1790 [===========>..................] - ETA: 5:53 - loss: 5.2135 - classification_loss: 2.6394 - regression_loss: 0.2916 - transformation_loss: 114.1256 733/1790 [===========>..................] - ETA: 5:53 - loss: 5.2117 - classification_loss: 2.6401 - regression_loss: 0.2912 - transformation_loss: 114.0195 734/1790 [===========>..................] - ETA: 5:52 - loss: 5.2064 - classification_loss: 2.6371 - regression_loss: 0.2909 - transformation_loss: 113.9206 735/1790 [===========>..................] - ETA: 5:52 - loss: 5.2018 - classification_loss: 2.6350 - regression_loss: 0.2906 - transformation_loss: 113.8074 736/1790 [===========>..................] - ETA: 5:52 - loss: 5.1979 - classification_loss: 2.6327 - regression_loss: 0.2904 - transformation_loss: 113.7432 737/1790 [===========>..................] - ETA: 5:51 - loss: 5.1925 - classification_loss: 2.6298 - regression_loss: 0.2904 - transformation_loss: 113.6175 738/1790 [===========>..................] - ETA: 5:51 - loss: 5.1899 - classification_loss: 2.6286 - regression_loss: 0.2912 - transformation_loss: 113.5037 739/1790 [===========>..................] - ETA: 5:50 - loss: 5.1844 - classification_loss: 2.6253 - regression_loss: 0.2909 - transformation_loss: 113.4077 740/1790 [===========>..................] - ETA: 5:50 - loss: 5.1802 - classification_loss: 2.6230 - regression_loss: 0.2910 - transformation_loss: 113.3100 741/1790 [===========>..................] - ETA: 5:50 - loss: 5.1747 - classification_loss: 2.6199 - regression_loss: 0.2908 - transformation_loss: 113.2047 742/1790 [===========>..................] - ETA: 5:49 - loss: 5.1707 - classification_loss: 2.6171 - regression_loss: 0.2906 - transformation_loss: 113.1474 743/1790 [===========>..................] - ETA: 5:49 - loss: 5.1652 - classification_loss: 2.6139 - regression_loss: 0.2904 - transformation_loss: 113.0443 744/1790 [===========>..................] - ETA: 5:48 - loss: 5.1610 - classification_loss: 2.6109 - regression_loss: 0.2902 - transformation_loss: 112.9967 745/1790 [===========>..................] - ETA: 5:48 - loss: 5.1565 - classification_loss: 2.6083 - regression_loss: 0.2902 - transformation_loss: 112.9020 746/1790 [===========>..................] - ETA: 5:48 - loss: 5.1515 - classification_loss: 2.6054 - regression_loss: 0.2902 - transformation_loss: 112.7967 747/1790 [===========>..................] - ETA: 5:47 - loss: 5.1468 - classification_loss: 2.6021 - regression_loss: 0.2900 - transformation_loss: 112.7383 748/1790 [===========>..................] - ETA: 5:47 - loss: 5.1437 - classification_loss: 2.5999 - regression_loss: 0.2900 - transformation_loss: 112.6932 749/1790 [===========>..................] - ETA: 5:46 - loss: 5.1399 - classification_loss: 2.5975 - regression_loss: 0.2897 - transformation_loss: 112.6370 750/1790 [===========>..................] - ETA: 5:46 - loss: 5.1342 - classification_loss: 2.5942 - regression_loss: 0.2895 - transformation_loss: 112.5270 751/1790 [===========>..................] - ETA: 5:46 - loss: 5.1298 - classification_loss: 2.5912 - regression_loss: 0.2895 - transformation_loss: 112.4562 752/1790 [===========>..................] - ETA: 5:45 - loss: 5.1242 - classification_loss: 2.5881 - regression_loss: 0.2892 - transformation_loss: 112.3463 753/1790 [===========>..................] - ETA: 5:45 - loss: 5.1191 - classification_loss: 2.5854 - regression_loss: 0.2889 - transformation_loss: 112.2394 754/1790 [===========>..................] - ETA: 5:44 - loss: 5.1196 - classification_loss: 2.5831 - regression_loss: 0.2892 - transformation_loss: 112.3629 755/1790 [===========>..................] - ETA: 5:44 - loss: 5.1152 - classification_loss: 2.5806 - regression_loss: 0.2892 - transformation_loss: 112.2715 756/1790 [===========>..................] - ETA: 5:44 - loss: 5.1269 - classification_loss: 2.5903 - regression_loss: 0.2908 - transformation_loss: 112.2916 757/1790 [===========>..................] - ETA: 5:43 - loss: 5.1216 - classification_loss: 2.5874 - regression_loss: 0.2907 - transformation_loss: 112.1776 758/1790 [===========>..................] - ETA: 5:43 - loss: 5.1162 - classification_loss: 2.5844 - regression_loss: 0.2904 - transformation_loss: 112.0702 759/1790 [===========>..................] - ETA: 5:42 - loss: 5.1144 - classification_loss: 2.5821 - regression_loss: 0.2904 - transformation_loss: 112.0936 760/1790 [===========>..................] - ETA: 5:42 - loss: 5.1106 - classification_loss: 2.5790 - regression_loss: 0.2901 - transformation_loss: 112.0779 761/1790 [===========>..................] - ETA: 5:42 - loss: 5.1067 - classification_loss: 2.5759 - regression_loss: 0.2899 - transformation_loss: 112.0413 762/1790 [===========>..................] - ETA: 5:41 - loss: 5.1010 - classification_loss: 2.5728 - regression_loss: 0.2897 - transformation_loss: 111.9291 763/1790 [===========>..................] - ETA: 5:41 - loss: 5.1042 - classification_loss: 2.5731 - regression_loss: 0.2913 - transformation_loss: 111.9911 764/1790 [===========>..................] - ETA: 5:40 - loss: 5.0994 - classification_loss: 2.5703 - regression_loss: 0.2912 - transformation_loss: 111.8927 765/1790 [===========>..................] - ETA: 5:40 - loss: 5.0943 - classification_loss: 2.5672 - regression_loss: 0.2909 - transformation_loss: 111.8053 766/1790 [===========>..................] - ETA: 5:39 - loss: 5.0917 - classification_loss: 2.5648 - regression_loss: 0.2909 - transformation_loss: 111.7970 767/1790 [===========>..................] - ETA: 5:39 - loss: 5.0865 - classification_loss: 2.5621 - regression_loss: 0.2906 - transformation_loss: 111.6894 768/1790 [===========>..................] - ETA: 5:39 - loss: 5.0846 - classification_loss: 2.5596 - regression_loss: 0.2906 - transformation_loss: 111.7203 769/1790 [===========>..................] - ETA: 5:38 - loss: 5.0804 - classification_loss: 2.5573 - regression_loss: 0.2905 - transformation_loss: 111.6316 770/1790 [===========>..................] - ETA: 5:38 - loss: 5.0759 - classification_loss: 2.5548 - regression_loss: 0.2902 - transformation_loss: 111.5447 771/1790 [===========>..................] - ETA: 5:37 - loss: 5.0716 - classification_loss: 2.5524 - regression_loss: 0.2902 - transformation_loss: 111.4525 772/1790 [===========>..................] - ETA: 5:37 - loss: 5.0679 - classification_loss: 2.5494 - regression_loss: 0.2899 - transformation_loss: 111.4269 773/1790 [===========>..................] - ETA: 5:37 - loss: 5.0639 - classification_loss: 2.5464 - regression_loss: 0.2897 - transformation_loss: 111.3918 774/1790 [===========>..................] - ETA: 5:36 - loss: 5.0590 - classification_loss: 2.5434 - regression_loss: 0.2894 - transformation_loss: 111.3104 775/1790 [===========>..................] - ETA: 5:36 - loss: 5.0537 - classification_loss: 2.5405 - regression_loss: 0.2891 - transformation_loss: 111.2032 776/1790 [============>.................] - ETA: 5:35 - loss: 5.0490 - classification_loss: 2.5381 - regression_loss: 0.2889 - transformation_loss: 111.1016 777/1790 [============>.................] - ETA: 5:35 - loss: 5.0524 - classification_loss: 2.5360 - regression_loss: 0.2889 - transformation_loss: 111.3781 778/1790 [============>.................] - ETA: 5:35 - loss: 5.0477 - classification_loss: 2.5334 - regression_loss: 0.2886 - transformation_loss: 111.2846 779/1790 [============>.................] - ETA: 5:34 - loss: 5.0456 - classification_loss: 2.5309 - regression_loss: 0.2885 - transformation_loss: 111.3064 780/1790 [============>.................] - ETA: 5:34 - loss: 5.0409 - classification_loss: 2.5283 - regression_loss: 0.2885 - transformation_loss: 111.2066 781/1790 [============>.................] - ETA: 5:33 - loss: 5.0365 - classification_loss: 2.5263 - regression_loss: 0.2883 - transformation_loss: 111.0970 782/1790 [============>.................] - ETA: 5:33 - loss: 5.0312 - classification_loss: 2.5234 - regression_loss: 0.2880 - transformation_loss: 110.9906 783/1790 [============>.................] - ETA: 5:33 - loss: 5.0265 - classification_loss: 2.5207 - regression_loss: 0.2878 - transformation_loss: 110.9043 784/1790 [============>.................] - ETA: 5:32 - loss: 5.0217 - classification_loss: 2.5181 - regression_loss: 0.2877 - transformation_loss: 110.7964 785/1790 [============>.................] - ETA: 5:32 - loss: 5.0226 - classification_loss: 2.5162 - regression_loss: 0.2876 - transformation_loss: 110.9371 786/1790 [============>.................] - ETA: 5:31 - loss: 5.0181 - classification_loss: 2.5135 - regression_loss: 0.2874 - transformation_loss: 110.8582 787/1790 [============>.................] - ETA: 5:31 - loss: 5.0134 - classification_loss: 2.5109 - regression_loss: 0.2873 - transformation_loss: 110.7601 788/1790 [============>.................] - ETA: 5:31 - loss: 5.0095 - classification_loss: 2.5079 - regression_loss: 0.2872 - transformation_loss: 110.7213 789/1790 [============>.................] - ETA: 5:30 - loss: 5.0046 - classification_loss: 2.5051 - regression_loss: 0.2871 - transformation_loss: 110.6247 790/1790 [============>.................] - ETA: 5:30 - loss: 5.0000 - classification_loss: 2.5028 - regression_loss: 0.2868 - transformation_loss: 110.5182 791/1790 [============>.................] - ETA: 5:30 - loss: 4.9954 - classification_loss: 2.5005 - regression_loss: 0.2866 - transformation_loss: 110.4132 792/1790 [============>.................] - ETA: 5:29 - loss: 4.9908 - classification_loss: 2.4976 - regression_loss: 0.2863 - transformation_loss: 110.3484 793/1790 [============>.................] - ETA: 5:29 - loss: 5.0058 - classification_loss: 2.5017 - regression_loss: 0.2866 - transformation_loss: 110.8763 794/1790 [============>.................] - ETA: 5:28 - loss: 5.0085 - classification_loss: 2.4997 - regression_loss: 0.2865 - transformation_loss: 111.1086 795/1790 [============>.................] - ETA: 5:28 - loss: 5.0036 - classification_loss: 2.4971 - regression_loss: 0.2864 - transformation_loss: 111.0051 796/1790 [============>.................] - ETA: 5:28 - loss: 4.9987 - classification_loss: 2.4943 - regression_loss: 0.2862 - transformation_loss: 110.9089 797/1790 [============>.................] - ETA: 5:27 - loss: 4.9935 - classification_loss: 2.4914 - regression_loss: 0.2859 - transformation_loss: 110.8085 798/1790 [============>.................] - ETA: 5:27 - loss: 4.9955 - classification_loss: 2.4895 - regression_loss: 0.2859 - transformation_loss: 111.0073 799/1790 [============>.................] - ETA: 5:26 - loss: 4.9902 - classification_loss: 2.4866 - regression_loss: 0.2856 - transformation_loss: 110.9013 800/1790 [============>.................] - ETA: 5:26 - loss: 4.9865 - classification_loss: 2.4848 - regression_loss: 0.2855 - transformation_loss: 110.8162 801/1790 [============>.................] - ETA: 5:26 - loss: 4.9888 - classification_loss: 2.4838 - regression_loss: 0.2873 - transformation_loss: 110.8828 802/1790 [============>.................] - ETA: 5:25 - loss: 4.9845 - classification_loss: 2.4812 - regression_loss: 0.2872 - transformation_loss: 110.8012 803/1790 [============>.................] - ETA: 5:25 - loss: 4.9812 - classification_loss: 2.4787 - regression_loss: 0.2872 - transformation_loss: 110.7643 804/1790 [============>.................] - ETA: 5:24 - loss: 4.9765 - classification_loss: 2.4759 - regression_loss: 0.2869 - transformation_loss: 110.6884 805/1790 [============>.................] - ETA: 5:24 - loss: 4.9730 - classification_loss: 2.4734 - regression_loss: 0.2868 - transformation_loss: 110.6383 806/1790 [============>.................] - ETA: 5:24 - loss: 4.9694 - classification_loss: 2.4710 - regression_loss: 0.2866 - transformation_loss: 110.5882 807/1790 [============>.................] - ETA: 5:23 - loss: 4.9685 - classification_loss: 2.4702 - regression_loss: 0.2867 - transformation_loss: 110.5749 808/1790 [============>.................] - ETA: 5:23 - loss: 4.9646 - classification_loss: 2.4681 - regression_loss: 0.2867 - transformation_loss: 110.4876 809/1790 [============>.................] - ETA: 5:22 - loss: 4.9633 - classification_loss: 2.4661 - regression_loss: 0.2867 - transformation_loss: 110.5295 810/1790 [============>.................] - ETA: 5:22 - loss: 4.9596 - classification_loss: 2.4640 - regression_loss: 0.2864 - transformation_loss: 110.4577 811/1790 [============>.................] - ETA: 5:22 - loss: 4.9554 - classification_loss: 2.4618 - regression_loss: 0.2862 - transformation_loss: 110.3693 812/1790 [============>.................] - ETA: 5:21 - loss: 4.9507 - classification_loss: 2.4593 - regression_loss: 0.2860 - transformation_loss: 110.2731 813/1790 [============>.................] - ETA: 5:21 - loss: 4.9461 - classification_loss: 2.4569 - regression_loss: 0.2858 - transformation_loss: 110.1682 814/1790 [============>.................] - ETA: 5:20 - loss: 4.9414 - classification_loss: 2.4542 - regression_loss: 0.2857 - transformation_loss: 110.0763 815/1790 [============>.................] - ETA: 5:20 - loss: 4.9368 - classification_loss: 2.4514 - regression_loss: 0.2854 - transformation_loss: 109.9991 816/1790 [============>.................] - ETA: 5:20 - loss: 4.9325 - classification_loss: 2.4489 - regression_loss: 0.2851 - transformation_loss: 109.9283 817/1790 [============>.................] - ETA: 5:19 - loss: 4.9280 - classification_loss: 2.4462 - regression_loss: 0.2849 - transformation_loss: 109.8455 818/1790 [============>.................] - ETA: 5:19 - loss: 4.9259 - classification_loss: 2.4439 - regression_loss: 0.2847 - transformation_loss: 109.8657 819/1790 [============>.................] - ETA: 5:19 - loss: 4.9226 - classification_loss: 2.4414 - regression_loss: 0.2845 - transformation_loss: 109.8335 820/1790 [============>.................] - ETA: 5:18 - loss: 4.9180 - classification_loss: 2.4389 - regression_loss: 0.2843 - transformation_loss: 109.7356 821/1790 [============>.................] - ETA: 5:18 - loss: 4.9145 - classification_loss: 2.4366 - regression_loss: 0.2841 - transformation_loss: 109.6914 822/1790 [============>.................] - ETA: 5:17 - loss: 4.9106 - classification_loss: 2.4342 - regression_loss: 0.2840 - transformation_loss: 109.6195 823/1790 [============>.................] - ETA: 5:17 - loss: 4.9063 - classification_loss: 2.4317 - regression_loss: 0.2837 - transformation_loss: 109.5413 824/1790 [============>.................] - ETA: 5:17 - loss: 4.9071 - classification_loss: 2.4305 - regression_loss: 0.2838 - transformation_loss: 109.6382 825/1790 [============>.................] - ETA: 5:16 - loss: 4.9080 - classification_loss: 2.4290 - regression_loss: 0.2839 - transformation_loss: 109.7507 826/1790 [============>.................] - ETA: 5:16 - loss: 4.9032 - classification_loss: 2.4263 - regression_loss: 0.2837 - transformation_loss: 109.6653 827/1790 [============>.................] - ETA: 5:15 - loss: 4.8985 - classification_loss: 2.4245 - regression_loss: 0.2833 - transformation_loss: 109.5327 828/1790 [============>.................] - ETA: 5:15 - loss: 4.8961 - classification_loss: 2.4234 - regression_loss: 0.2843 - transformation_loss: 109.4213 829/1790 [============>.................] - ETA: 5:15 - loss: 4.8913 - classification_loss: 2.4208 - regression_loss: 0.2840 - transformation_loss: 109.3244 830/1790 [============>.................] - ETA: 5:14 - loss: 4.8872 - classification_loss: 2.4186 - regression_loss: 0.2838 - transformation_loss: 109.2417 831/1790 [============>.................] - ETA: 5:14 - loss: 4.8827 - classification_loss: 2.4160 - regression_loss: 0.2835 - transformation_loss: 109.1561 832/1790 [============>.................] - ETA: 5:13 - loss: 4.8866 - classification_loss: 2.4140 - regression_loss: 0.2836 - transformation_loss: 109.4486 833/1790 [============>.................] - ETA: 5:13 - loss: 4.8825 - classification_loss: 2.4118 - regression_loss: 0.2835 - transformation_loss: 109.3597 834/1790 [============>.................] - ETA: 5:13 - loss: 4.8778 - classification_loss: 2.4094 - regression_loss: 0.2832 - transformation_loss: 109.2631 835/1790 [============>.................] - ETA: 5:12 - loss: 4.8734 - classification_loss: 2.4072 - regression_loss: 0.2829 - transformation_loss: 109.1648 836/1790 [=============>................] - ETA: 5:12 - loss: 4.8692 - classification_loss: 2.4046 - regression_loss: 0.2829 - transformation_loss: 109.0892 837/1790 [=============>................] - ETA: 5:12 - loss: 4.8654 - classification_loss: 2.4020 - regression_loss: 0.2827 - transformation_loss: 109.0341 838/1790 [=============>................] - ETA: 5:11 - loss: 4.8622 - classification_loss: 2.3994 - regression_loss: 0.2825 - transformation_loss: 109.0157 839/1790 [=============>................] - ETA: 5:11 - loss: 4.8593 - classification_loss: 2.3972 - regression_loss: 0.2825 - transformation_loss: 108.9819 840/1790 [=============>................] - ETA: 5:10 - loss: 4.8552 - classification_loss: 2.3946 - regression_loss: 0.2823 - transformation_loss: 108.9131 841/1790 [=============>................] - ETA: 5:10 - loss: 4.8607 - classification_loss: 2.3945 - regression_loss: 0.2830 - transformation_loss: 109.1586 842/1790 [=============>................] - ETA: 5:10 - loss: 4.8581 - classification_loss: 2.3933 - regression_loss: 0.2829 - transformation_loss: 109.0943 843/1790 [=============>................] - ETA: 5:09 - loss: 4.8555 - classification_loss: 2.3914 - regression_loss: 0.2831 - transformation_loss: 109.0500 844/1790 [=============>................] - ETA: 5:09 - loss: 4.8514 - classification_loss: 2.3889 - regression_loss: 0.2829 - transformation_loss: 108.9811 845/1790 [=============>................] - ETA: 5:09 - loss: 4.8494 - classification_loss: 2.3870 - regression_loss: 0.2830 - transformation_loss: 108.9668 846/1790 [=============>................] - ETA: 5:08 - loss: 4.8456 - classification_loss: 2.3845 - regression_loss: 0.2828 - transformation_loss: 108.9091 847/1790 [=============>................] - ETA: 5:08 - loss: 4.8409 - classification_loss: 2.3821 - regression_loss: 0.2826 - transformation_loss: 108.8078 848/1790 [=============>................] - ETA: 5:07 - loss: 4.8362 - classification_loss: 2.3795 - regression_loss: 0.2823 - transformation_loss: 108.7159 849/1790 [=============>................] - ETA: 5:07 - loss: 4.8315 - classification_loss: 2.3770 - regression_loss: 0.2821 - transformation_loss: 108.6231 850/1790 [=============>................] - ETA: 5:07 - loss: 4.8271 - classification_loss: 2.3743 - regression_loss: 0.2818 - transformation_loss: 108.5529 851/1790 [=============>................] - ETA: 5:06 - loss: 4.8232 - classification_loss: 2.3720 - regression_loss: 0.2816 - transformation_loss: 108.4802 852/1790 [=============>................] - ETA: 5:06 - loss: 4.8203 - classification_loss: 2.3706 - regression_loss: 0.2816 - transformation_loss: 108.4017 853/1790 [=============>................] - ETA: 5:06 - loss: 4.8162 - classification_loss: 2.3685 - regression_loss: 0.2815 - transformation_loss: 108.3101 854/1790 [=============>................] - ETA: 5:05 - loss: 4.8121 - classification_loss: 2.3660 - regression_loss: 0.2813 - transformation_loss: 108.2391 855/1790 [=============>................] - ETA: 5:05 - loss: 4.8083 - classification_loss: 2.3634 - regression_loss: 0.2811 - transformation_loss: 108.1859 856/1790 [=============>................] - ETA: 5:04 - loss: 4.8038 - classification_loss: 2.3611 - regression_loss: 0.2809 - transformation_loss: 108.0958 857/1790 [=============>................] - ETA: 5:04 - loss: 4.7996 - classification_loss: 2.3585 - regression_loss: 0.2806 - transformation_loss: 108.0261 858/1790 [=============>................] - ETA: 5:04 - loss: 4.7961 - classification_loss: 2.3565 - regression_loss: 0.2805 - transformation_loss: 107.9579 859/1790 [=============>................] - ETA: 5:03 - loss: 4.7993 - classification_loss: 2.3552 - regression_loss: 0.2806 - transformation_loss: 108.1726 860/1790 [=============>................] - ETA: 5:03 - loss: 4.7989 - classification_loss: 2.3534 - regression_loss: 0.2807 - transformation_loss: 108.2384 861/1790 [=============>................] - ETA: 5:03 - loss: 4.7964 - classification_loss: 2.3519 - regression_loss: 0.2808 - transformation_loss: 108.1852 862/1790 [=============>................] - ETA: 5:02 - loss: 4.7935 - classification_loss: 2.3501 - regression_loss: 0.2810 - transformation_loss: 108.1217 863/1790 [=============>................] - ETA: 5:02 - loss: 4.7895 - classification_loss: 2.3478 - regression_loss: 0.2808 - transformation_loss: 108.0461 864/1790 [=============>................] - ETA: 5:01 - loss: 4.7882 - classification_loss: 2.3461 - regression_loss: 0.2810 - transformation_loss: 108.0570 865/1790 [=============>................] - ETA: 5:01 - loss: 4.7864 - classification_loss: 2.3442 - regression_loss: 0.2812 - transformation_loss: 108.0539 866/1790 [=============>................] - ETA: 5:01 - loss: 4.7826 - classification_loss: 2.3416 - regression_loss: 0.2809 - transformation_loss: 108.0040 867/1790 [=============>................] - ETA: 5:00 - loss: 4.7801 - classification_loss: 2.3403 - regression_loss: 0.2809 - transformation_loss: 107.9452 868/1790 [=============>................] - ETA: 5:00 - loss: 4.7774 - classification_loss: 2.3384 - regression_loss: 0.2808 - transformation_loss: 107.9118 869/1790 [=============>................] - ETA: 5:00 - loss: 4.7743 - classification_loss: 2.3363 - regression_loss: 0.2807 - transformation_loss: 107.8706 870/1790 [=============>................] - ETA: 4:59 - loss: 4.7707 - classification_loss: 2.3339 - regression_loss: 0.2805 - transformation_loss: 107.8185 871/1790 [=============>................] - ETA: 4:59 - loss: 4.7667 - classification_loss: 2.3316 - regression_loss: 0.2803 - transformation_loss: 107.7401 872/1790 [=============>................] - ETA: 4:58 - loss: 4.7627 - classification_loss: 2.3295 - regression_loss: 0.2801 - transformation_loss: 107.6566 873/1790 [=============>................] - ETA: 4:58 - loss: 4.7601 - classification_loss: 2.3276 - regression_loss: 0.2799 - transformation_loss: 107.6318 874/1790 [=============>................] - ETA: 4:58 - loss: 4.7580 - classification_loss: 2.3251 - regression_loss: 0.2797 - transformation_loss: 107.6642 875/1790 [=============>................] - ETA: 4:57 - loss: 4.7540 - classification_loss: 2.3229 - regression_loss: 0.2796 - transformation_loss: 107.5757 876/1790 [=============>................] - ETA: 4:57 - loss: 4.7604 - classification_loss: 2.3238 - regression_loss: 0.2803 - transformation_loss: 107.8170 877/1790 [=============>................] - ETA: 4:56 - loss: 4.7566 - classification_loss: 2.3217 - regression_loss: 0.2802 - transformation_loss: 107.7367 878/1790 [=============>................] - ETA: 4:56 - loss: 4.7530 - classification_loss: 2.3200 - regression_loss: 0.2799 - transformation_loss: 107.6569 879/1790 [=============>................] - ETA: 4:56 - loss: 4.7490 - classification_loss: 2.3175 - regression_loss: 0.2797 - transformation_loss: 107.5929 880/1790 [=============>................] - ETA: 4:55 - loss: 4.7463 - classification_loss: 2.3163 - regression_loss: 0.2798 - transformation_loss: 107.5100 881/1790 [=============>................] - ETA: 4:55 - loss: 4.7529 - classification_loss: 2.3151 - regression_loss: 0.2798 - transformation_loss: 107.8997 882/1790 [=============>................] - ETA: 4:55 - loss: 4.7495 - classification_loss: 2.3132 - regression_loss: 0.2796 - transformation_loss: 107.8366 883/1790 [=============>................] - ETA: 4:54 - loss: 4.7460 - classification_loss: 2.3110 - regression_loss: 0.2794 - transformation_loss: 107.7761 884/1790 [=============>................] - ETA: 4:54 - loss: 4.7409 - classification_loss: 2.3087 - regression_loss: 0.2791 - transformation_loss: 107.6542 885/1790 [=============>................] - ETA: 4:53 - loss: 4.7377 - classification_loss: 2.3063 - regression_loss: 0.2789 - transformation_loss: 107.6255 886/1790 [=============>................] - ETA: 4:53 - loss: 4.7335 - classification_loss: 2.3039 - regression_loss: 0.2786 - transformation_loss: 107.5473 887/1790 [=============>................] - ETA: 4:53 - loss: 4.7292 - classification_loss: 2.3016 - regression_loss: 0.2784 - transformation_loss: 107.4582 888/1790 [=============>................] - ETA: 4:52 - loss: 4.7275 - classification_loss: 2.2996 - regression_loss: 0.2782 - transformation_loss: 107.4871 889/1790 [=============>................] - ETA: 4:52 - loss: 4.7254 - classification_loss: 2.2982 - regression_loss: 0.2782 - transformation_loss: 107.4496 890/1790 [=============>................] - ETA: 4:52 - loss: 4.7222 - classification_loss: 2.2965 - regression_loss: 0.2781 - transformation_loss: 107.3774 891/1790 [=============>................] - ETA: 4:51 - loss: 4.7183 - classification_loss: 2.2944 - regression_loss: 0.2780 - transformation_loss: 107.2982 892/1790 [=============>................] - ETA: 4:51 - loss: 4.7146 - classification_loss: 2.2922 - regression_loss: 0.2777 - transformation_loss: 107.2357 893/1790 [=============>................] - ETA: 4:51 - loss: 4.7113 - classification_loss: 2.2904 - regression_loss: 0.2776 - transformation_loss: 107.1630 894/1790 [=============>................] - ETA: 4:50 - loss: 4.7072 - classification_loss: 2.2880 - regression_loss: 0.2774 - transformation_loss: 107.0904 895/1790 [==============>...............] - ETA: 4:50 - loss: 4.7050 - classification_loss: 2.2862 - regression_loss: 0.2773 - transformation_loss: 107.0706 896/1790 [==============>...............] - ETA: 4:49 - loss: 4.7006 - classification_loss: 2.2838 - regression_loss: 0.2771 - transformation_loss: 106.9858 897/1790 [==============>...............] - ETA: 4:49 - loss: 4.6967 - classification_loss: 2.2814 - regression_loss: 0.2769 - transformation_loss: 106.9184 898/1790 [==============>...............] - ETA: 4:49 - loss: 4.6940 - classification_loss: 2.2791 - regression_loss: 0.2767 - transformation_loss: 106.9115 899/1790 [==============>...............] - ETA: 4:48 - loss: 4.6902 - classification_loss: 2.2769 - regression_loss: 0.2766 - transformation_loss: 106.8335 900/1790 [==============>...............] - ETA: 4:48 - loss: 4.6873 - classification_loss: 2.2747 - regression_loss: 0.2764 - transformation_loss: 106.8100 901/1790 [==============>...............] - ETA: 4:48 - loss: 4.6839 - classification_loss: 2.2733 - regression_loss: 0.2762 - transformation_loss: 106.7204 902/1790 [==============>...............] - ETA: 4:47 - loss: 4.6807 - classification_loss: 2.2717 - regression_loss: 0.2761 - transformation_loss: 106.6473 903/1790 [==============>...............] - ETA: 4:47 - loss: 4.6782 - classification_loss: 2.2702 - regression_loss: 0.2759 - transformation_loss: 106.6096 904/1790 [==============>...............] - ETA: 4:47 - loss: 4.6741 - classification_loss: 2.2679 - regression_loss: 0.2757 - transformation_loss: 106.5235 905/1790 [==============>...............] - ETA: 4:46 - loss: 4.6700 - classification_loss: 2.2657 - regression_loss: 0.2756 - transformation_loss: 106.4375 906/1790 [==============>...............] - ETA: 4:46 - loss: 4.6660 - classification_loss: 2.2633 - regression_loss: 0.2754 - transformation_loss: 106.3682 907/1790 [==============>...............] - ETA: 4:46 - loss: 4.6619 - classification_loss: 2.2610 - regression_loss: 0.2752 - transformation_loss: 106.2852 908/1790 [==============>...............] - ETA: 4:45 - loss: 4.6579 - classification_loss: 2.2589 - regression_loss: 0.2750 - transformation_loss: 106.2016 909/1790 [==============>...............] - ETA: 4:45 - loss: 4.6536 - classification_loss: 2.2565 - regression_loss: 0.2747 - transformation_loss: 106.1188 910/1790 [==============>...............] - ETA: 4:45 - loss: 4.6519 - classification_loss: 2.2547 - regression_loss: 0.2746 - transformation_loss: 106.1295 911/1790 [==============>...............] - ETA: 4:44 - loss: 4.6482 - classification_loss: 2.2528 - regression_loss: 0.2744 - transformation_loss: 106.0543 912/1790 [==============>...............] - ETA: 4:44 - loss: 4.6443 - classification_loss: 2.2506 - regression_loss: 0.2742 - transformation_loss: 105.9782 913/1790 [==============>...............] - ETA: 4:43 - loss: 4.6404 - classification_loss: 2.2484 - regression_loss: 0.2740 - transformation_loss: 105.8996 914/1790 [==============>...............] - ETA: 4:43 - loss: 4.6372 - classification_loss: 2.2468 - regression_loss: 0.2739 - transformation_loss: 105.8235 915/1790 [==============>...............] - ETA: 4:43 - loss: 4.6333 - classification_loss: 2.2446 - regression_loss: 0.2738 - transformation_loss: 105.7437 916/1790 [==============>...............] - ETA: 4:42 - loss: 4.6295 - classification_loss: 2.2425 - regression_loss: 0.2735 - transformation_loss: 105.6717 917/1790 [==============>...............] - ETA: 4:42 - loss: 4.6290 - classification_loss: 2.2409 - regression_loss: 0.2735 - transformation_loss: 105.7323 918/1790 [==============>...............] - ETA: 4:42 - loss: 4.6259 - classification_loss: 2.2389 - regression_loss: 0.2733 - transformation_loss: 105.6859 919/1790 [==============>...............] - ETA: 4:41 - loss: 4.6266 - classification_loss: 2.2392 - regression_loss: 0.2734 - transformation_loss: 105.7004 920/1790 [==============>...............] - ETA: 4:41 - loss: 4.6240 - classification_loss: 2.2379 - regression_loss: 0.2734 - transformation_loss: 105.6327 921/1790 [==============>...............] - ETA: 4:41 - loss: 4.6212 - classification_loss: 2.2363 - regression_loss: 0.2734 - transformation_loss: 105.5744 922/1790 [==============>...............] - ETA: 4:40 - loss: 4.6185 - classification_loss: 2.2355 - regression_loss: 0.2732 - transformation_loss: 105.4917 923/1790 [==============>...............] - ETA: 4:40 - loss: 4.6154 - classification_loss: 2.2334 - regression_loss: 0.2732 - transformation_loss: 105.4417 924/1790 [==============>...............] - ETA: 4:39 - loss: 4.6119 - classification_loss: 2.2312 - regression_loss: 0.2730 - transformation_loss: 105.3854 925/1790 [==============>...............] - ETA: 4:39 - loss: 4.6086 - classification_loss: 2.2294 - regression_loss: 0.2730 - transformation_loss: 105.3103 926/1790 [==============>...............] - ETA: 4:39 - loss: 4.6061 - classification_loss: 2.2279 - regression_loss: 0.2730 - transformation_loss: 105.2643 927/1790 [==============>...............] - ETA: 4:38 - loss: 4.6050 - classification_loss: 2.2263 - regression_loss: 0.2729 - transformation_loss: 105.2890 928/1790 [==============>...............] - ETA: 4:38 - loss: 4.6014 - classification_loss: 2.2242 - regression_loss: 0.2727 - transformation_loss: 105.2262 929/1790 [==============>...............] - ETA: 4:38 - loss: 4.5978 - classification_loss: 2.2223 - regression_loss: 0.2724 - transformation_loss: 105.1513 930/1790 [==============>...............] - ETA: 4:37 - loss: 4.5955 - classification_loss: 2.2203 - regression_loss: 0.2723 - transformation_loss: 105.1423 931/1790 [==============>...............] - ETA: 4:37 - loss: 4.5933 - classification_loss: 2.2190 - regression_loss: 0.2726 - transformation_loss: 105.0832 932/1790 [==============>...............] - ETA: 4:37 - loss: 4.5901 - classification_loss: 2.2168 - regression_loss: 0.2724 - transformation_loss: 105.0441 933/1790 [==============>...............] - ETA: 4:36 - loss: 4.5872 - classification_loss: 2.2146 - regression_loss: 0.2721 - transformation_loss: 105.0209 934/1790 [==============>...............] - ETA: 4:36 - loss: 4.5830 - classification_loss: 2.2124 - regression_loss: 0.2719 - transformation_loss: 104.9393 935/1790 [==============>...............] - ETA: 4:35 - loss: 4.5825 - classification_loss: 2.2117 - regression_loss: 0.2731 - transformation_loss: 104.8876 936/1790 [==============>...............] - ETA: 4:35 - loss: 4.5796 - classification_loss: 2.2098 - regression_loss: 0.2729 - transformation_loss: 104.8434 937/1790 [==============>...............] - ETA: 4:35 - loss: 4.5757 - classification_loss: 2.2078 - regression_loss: 0.2727 - transformation_loss: 104.7598 938/1790 [==============>...............] - ETA: 4:34 - loss: 4.5735 - classification_loss: 2.2065 - regression_loss: 0.2726 - transformation_loss: 104.7196 939/1790 [==============>...............] - ETA: 4:34 - loss: 4.5716 - classification_loss: 2.2058 - regression_loss: 0.2726 - transformation_loss: 104.6596 940/1790 [==============>...............] - ETA: 4:34 - loss: 4.5687 - classification_loss: 2.2037 - regression_loss: 0.2724 - transformation_loss: 104.6350 941/1790 [==============>...............] - ETA: 4:33 - loss: 4.5647 - classification_loss: 2.2016 - regression_loss: 0.2721 - transformation_loss: 104.5517 942/1790 [==============>...............] - ETA: 4:33 - loss: 4.5621 - classification_loss: 2.2004 - regression_loss: 0.2722 - transformation_loss: 104.4739 943/1790 [==============>...............] - ETA: 4:33 - loss: 4.5583 - classification_loss: 2.1983 - regression_loss: 0.2720 - transformation_loss: 104.3979 944/1790 [==============>...............] - ETA: 4:32 - loss: 4.5543 - classification_loss: 2.1961 - regression_loss: 0.2718 - transformation_loss: 104.3174 945/1790 [==============>...............] - ETA: 4:32 - loss: 4.5522 - classification_loss: 2.1949 - regression_loss: 0.2719 - transformation_loss: 104.2711 946/1790 [==============>...............] - ETA: 4:31 - loss: 4.5482 - classification_loss: 2.1927 - regression_loss: 0.2718 - transformation_loss: 104.1856 947/1790 [==============>...............] - ETA: 4:31 - loss: 4.5443 - classification_loss: 2.1907 - regression_loss: 0.2716 - transformation_loss: 104.1044 948/1790 [==============>...............] - ETA: 4:31 - loss: 4.5403 - classification_loss: 2.1885 - regression_loss: 0.2714 - transformation_loss: 104.0226 949/1790 [==============>...............] - ETA: 4:30 - loss: 4.5367 - classification_loss: 2.1864 - regression_loss: 0.2712 - transformation_loss: 103.9571 950/1790 [==============>...............] - ETA: 4:30 - loss: 4.5331 - classification_loss: 2.1845 - regression_loss: 0.2710 - transformation_loss: 103.8765 951/1790 [==============>...............] - ETA: 4:30 - loss: 4.5291 - classification_loss: 2.1824 - regression_loss: 0.2708 - transformation_loss: 103.7981 952/1790 [==============>...............] - ETA: 4:29 - loss: 4.5269 - classification_loss: 2.1815 - regression_loss: 0.2707 - transformation_loss: 103.7314 953/1790 [==============>...............] - ETA: 4:29 - loss: 4.5229 - classification_loss: 2.1793 - regression_loss: 0.2705 - transformation_loss: 103.6531 954/1790 [==============>...............] - ETA: 4:29 - loss: 4.5193 - classification_loss: 2.1772 - regression_loss: 0.2703 - transformation_loss: 103.5941 955/1790 [===============>..............] - ETA: 4:28 - loss: 4.5164 - classification_loss: 2.1761 - regression_loss: 0.2701 - transformation_loss: 103.5106 956/1790 [===============>..............] - ETA: 4:28 - loss: 4.5154 - classification_loss: 2.1752 - regression_loss: 0.2702 - transformation_loss: 103.5006 957/1790 [===============>..............] - ETA: 4:27 - loss: 4.5126 - classification_loss: 2.1731 - regression_loss: 0.2700 - transformation_loss: 103.4766 958/1790 [===============>..............] - ETA: 4:27 - loss: 4.5097 - classification_loss: 2.1716 - regression_loss: 0.2699 - transformation_loss: 103.4073 959/1790 [===============>..............] - ETA: 4:27 - loss: 4.5067 - classification_loss: 2.1698 - regression_loss: 0.2698 - transformation_loss: 103.3574 960/1790 [===============>..............] - ETA: 4:26 - loss: 4.5056 - classification_loss: 2.1687 - regression_loss: 0.2698 - transformation_loss: 103.3537 961/1790 [===============>..............] - ETA: 4:26 - loss: 4.5021 - classification_loss: 2.1667 - regression_loss: 0.2696 - transformation_loss: 103.2922 962/1790 [===============>..............] - ETA: 4:26 - loss: 4.4992 - classification_loss: 2.1648 - regression_loss: 0.2695 - transformation_loss: 103.2429 963/1790 [===============>..............] - ETA: 4:25 - loss: 4.4958 - classification_loss: 2.1630 - regression_loss: 0.2695 - transformation_loss: 103.1645 964/1790 [===============>..............] - ETA: 4:25 - loss: 4.5006 - classification_loss: 2.1618 - regression_loss: 0.2696 - transformation_loss: 103.4611 965/1790 [===============>..............] - ETA: 4:25 - loss: 4.4974 - classification_loss: 2.1599 - regression_loss: 0.2694 - transformation_loss: 103.4025 966/1790 [===============>..............] - ETA: 4:24 - loss: 4.4965 - classification_loss: 2.1586 - regression_loss: 0.2695 - transformation_loss: 103.4219 967/1790 [===============>..............] - ETA: 4:24 - loss: 4.4935 - classification_loss: 2.1566 - regression_loss: 0.2692 - transformation_loss: 103.3833 968/1790 [===============>..............] - ETA: 4:24 - loss: 4.4909 - classification_loss: 2.1548 - regression_loss: 0.2691 - transformation_loss: 103.3502 969/1790 [===============>..............] - ETA: 4:23 - loss: 4.5159 - classification_loss: 2.1721 - regression_loss: 0.2695 - transformation_loss: 103.7169 970/1790 [===============>..............] - ETA: 4:23 - loss: 4.5122 - classification_loss: 2.1700 - regression_loss: 0.2693 - transformation_loss: 103.6410 971/1790 [===============>..............] - ETA: 4:22 - loss: 4.5087 - classification_loss: 2.1683 - regression_loss: 0.2692 - transformation_loss: 103.5632 972/1790 [===============>..............] - ETA: 4:22 - loss: 4.5060 - classification_loss: 2.1669 - regression_loss: 0.2692 - transformation_loss: 103.4982 973/1790 [===============>..............] - ETA: 4:22 - loss: 4.5028 - classification_loss: 2.1648 - regression_loss: 0.2689 - transformation_loss: 103.4507 974/1790 [===============>..............] - ETA: 4:21 - loss: 4.4994 - classification_loss: 2.1629 - regression_loss: 0.2688 - transformation_loss: 103.3842 975/1790 [===============>..............] - ETA: 4:21 - loss: 4.4973 - classification_loss: 2.1617 - regression_loss: 0.2690 - transformation_loss: 103.3340 976/1790 [===============>..............] - ETA: 4:21 - loss: 4.4938 - classification_loss: 2.1598 - regression_loss: 0.2688 - transformation_loss: 103.2604 977/1790 [===============>..............] - ETA: 4:20 - loss: 4.4936 - classification_loss: 2.1584 - regression_loss: 0.2690 - transformation_loss: 103.3120 978/1790 [===============>..............] - ETA: 4:20 - loss: 4.4900 - classification_loss: 2.1566 - regression_loss: 0.2688 - transformation_loss: 103.2312 979/1790 [===============>..............] - ETA: 4:20 - loss: 4.4879 - classification_loss: 2.1555 - regression_loss: 0.2687 - transformation_loss: 103.1865 980/1790 [===============>..............] - ETA: 4:19 - loss: 4.4849 - classification_loss: 2.1536 - regression_loss: 0.2686 - transformation_loss: 103.1376 981/1790 [===============>..............] - ETA: 4:19 - loss: 4.4852 - classification_loss: 2.1532 - regression_loss: 0.2686 - transformation_loss: 103.1670 982/1790 [===============>..............] - ETA: 4:19 - loss: 4.4819 - classification_loss: 2.1513 - regression_loss: 0.2685 - transformation_loss: 103.1058 983/1790 [===============>..............] - ETA: 4:18 - loss: 4.4799 - classification_loss: 2.1506 - regression_loss: 0.2685 - transformation_loss: 103.0404 984/1790 [===============>..............] - ETA: 4:18 - loss: 4.4766 - classification_loss: 2.1488 - regression_loss: 0.2685 - transformation_loss: 102.9664 985/1790 [===============>..............] - ETA: 4:18 - loss: 4.4733 - classification_loss: 2.1472 - regression_loss: 0.2683 - transformation_loss: 102.8846 986/1790 [===============>..............] - ETA: 4:17 - loss: 4.4700 - classification_loss: 2.1452 - regression_loss: 0.2682 - transformation_loss: 102.8259 987/1790 [===============>..............] - ETA: 4:17 - loss: 4.4670 - classification_loss: 2.1433 - regression_loss: 0.2681 - transformation_loss: 102.7781 988/1790 [===============>..............] - ETA: 4:17 - loss: 4.4632 - classification_loss: 2.1414 - regression_loss: 0.2679 - transformation_loss: 102.7012 989/1790 [===============>..............] - ETA: 4:16 - loss: 4.4595 - classification_loss: 2.1393 - regression_loss: 0.2676 - transformation_loss: 102.6264 990/1790 [===============>..............] - ETA: 4:16 - loss: 4.4593 - classification_loss: 2.1380 - regression_loss: 0.2678 - transformation_loss: 102.6770 991/1790 [===============>..............] - ETA: 4:15 - loss: 4.4554 - classification_loss: 2.1364 - regression_loss: 0.2675 - transformation_loss: 102.5734 992/1790 [===============>..............] - ETA: 4:15 - loss: 4.4527 - classification_loss: 2.1346 - regression_loss: 0.2674 - transformation_loss: 102.5374 993/1790 [===============>..............] - ETA: 4:15 - loss: 4.4520 - classification_loss: 2.1336 - regression_loss: 0.2684 - transformation_loss: 102.5011 994/1790 [===============>..............] - ETA: 4:14 - loss: 4.4492 - classification_loss: 2.1320 - regression_loss: 0.2684 - transformation_loss: 102.4450 995/1790 [===============>..............] - ETA: 4:14 - loss: 4.4457 - classification_loss: 2.1300 - regression_loss: 0.2682 - transformation_loss: 102.3764 996/1790 [===============>..............] - ETA: 4:14 - loss: 4.4653 - classification_loss: 2.1292 - regression_loss: 0.2889 - transformation_loss: 102.3593 997/1790 [===============>..............] - ETA: 4:13 - loss: 4.4624 - classification_loss: 2.1276 - regression_loss: 0.2889 - transformation_loss: 102.2928 998/1790 [===============>..............] - ETA: 4:13 - loss: 4.4604 - classification_loss: 2.1261 - regression_loss: 0.2889 - transformation_loss: 102.2707 999/1790 [===============>..............] - ETA: 4:13 - loss: 4.4590 - classification_loss: 2.1252 - regression_loss: 0.2891 - transformation_loss: 102.23681000/1790 [===============>..............] - ETA: 4:12 - loss: 4.4555 - classification_loss: 2.1232 - regression_loss: 0.2888 - transformation_loss: 102.17401001/1790 [===============>..............] - ETA: 4:12 - loss: 4.4529 - classification_loss: 2.1212 - regression_loss: 0.2886 - transformation_loss: 102.15661002/1790 [===============>..............] - ETA: 4:12 - loss: 4.4497 - classification_loss: 2.1196 - regression_loss: 0.2884 - transformation_loss: 102.08331003/1790 [===============>..............] - ETA: 4:11 - loss: 4.4468 - classification_loss: 2.1183 - regression_loss: 0.2884 - transformation_loss: 102.00971004/1790 [===============>..............] - ETA: 4:11 - loss: 4.4445 - classification_loss: 2.1164 - regression_loss: 0.2883 - transformation_loss: 101.99191005/1790 [===============>..............] - ETA: 4:10 - loss: 4.4412 - classification_loss: 2.1144 - regression_loss: 0.2880 - transformation_loss: 101.93791006/1790 [===============>..............] - ETA: 4:10 - loss: 4.4380 - classification_loss: 2.1126 - regression_loss: 0.2880 - transformation_loss: 101.87251007/1790 [===============>..............] - ETA: 4:10 - loss: 4.4342 - classification_loss: 2.1106 - regression_loss: 0.2877 - transformation_loss: 101.79681008/1790 [===============>..............] - ETA: 4:09 - loss: 4.4315 - classification_loss: 2.1092 - regression_loss: 0.2876 - transformation_loss: 101.73701009/1790 [===============>..............] - ETA: 4:09 - loss: 4.4284 - classification_loss: 2.1075 - regression_loss: 0.2874 - transformation_loss: 101.67801010/1790 [===============>..............] - ETA: 4:09 - loss: 4.4251 - classification_loss: 2.1057 - regression_loss: 0.2873 - transformation_loss: 101.60951011/1790 [===============>..............] - ETA: 4:08 - loss: 4.4279 - classification_loss: 2.1066 - regression_loss: 0.2895 - transformation_loss: 101.58821012/1790 [===============>..............] - ETA: 4:08 - loss: 4.4245 - classification_loss: 2.1050 - regression_loss: 0.2893 - transformation_loss: 101.51121013/1790 [===============>..............] - ETA: 4:08 - loss: 4.4223 - classification_loss: 2.1034 - regression_loss: 0.2892 - transformation_loss: 101.49011014/1790 [===============>..............] - ETA: 4:07 - loss: 4.4183 - classification_loss: 2.1016 - regression_loss: 0.2889 - transformation_loss: 101.39001015/1790 [================>.............] - ETA: 4:07 - loss: 4.4150 - classification_loss: 2.0998 - regression_loss: 0.2889 - transformation_loss: 101.31821016/1790 [================>.............] - ETA: 4:07 - loss: 4.4274 - classification_loss: 2.0989 - regression_loss: 0.2893 - transformation_loss: 101.95851017/1790 [================>.............] - ETA: 4:06 - loss: 4.4240 - classification_loss: 2.0970 - regression_loss: 0.2890 - transformation_loss: 101.90301018/1790 [================>.............] - ETA: 4:06 - loss: 4.4206 - classification_loss: 2.0951 - regression_loss: 0.2888 - transformation_loss: 101.83031019/1790 [================>.............] - ETA: 4:06 - loss: 4.4199 - classification_loss: 2.0945 - regression_loss: 0.2890 - transformation_loss: 101.82001020/1790 [================>.............] - ETA: 4:05 - loss: 4.4169 - classification_loss: 2.0931 - regression_loss: 0.2888 - transformation_loss: 101.75171021/1790 [================>.............] - ETA: 4:05 - loss: 4.4135 - classification_loss: 2.0911 - regression_loss: 0.2886 - transformation_loss: 101.68421022/1790 [================>.............] - ETA: 4:04 - loss: 4.4110 - classification_loss: 2.0900 - regression_loss: 0.2885 - transformation_loss: 101.62561023/1790 [================>.............] - ETA: 4:04 - loss: 4.4075 - classification_loss: 2.0881 - regression_loss: 0.2882 - transformation_loss: 101.55401024/1790 [================>.............] - ETA: 4:04 - loss: 4.4038 - classification_loss: 2.0862 - regression_loss: 0.2880 - transformation_loss: 101.48171025/1790 [================>.............] - ETA: 4:03 - loss: 4.4032 - classification_loss: 2.0853 - regression_loss: 0.2879 - transformation_loss: 101.50391026/1790 [================>.............] - ETA: 4:03 - loss: 4.4003 - classification_loss: 2.0836 - regression_loss: 0.2877 - transformation_loss: 101.45101027/1790 [================>.............] - ETA: 4:03 - loss: 4.3973 - classification_loss: 2.0817 - regression_loss: 0.2875 - transformation_loss: 101.40671028/1790 [================>.............] - ETA: 4:02 - loss: 4.3948 - classification_loss: 2.0803 - regression_loss: 0.2873 - transformation_loss: 101.35981029/1790 [================>.............] - ETA: 4:02 - loss: 4.3919 - classification_loss: 2.0787 - regression_loss: 0.2872 - transformation_loss: 101.30031030/1790 [================>.............] - ETA: 4:02 - loss: 4.3886 - classification_loss: 2.0770 - regression_loss: 0.2870 - transformation_loss: 101.23021031/1790 [================>.............] - ETA: 4:01 - loss: 4.3852 - classification_loss: 2.0752 - regression_loss: 0.2867 - transformation_loss: 101.16281032/1790 [================>.............] - ETA: 4:01 - loss: 4.3829 - classification_loss: 2.0738 - regression_loss: 0.2865 - transformation_loss: 101.13121033/1790 [================>.............] - ETA: 4:01 - loss: 4.4007 - classification_loss: 2.0742 - regression_loss: 0.3053 - transformation_loss: 101.06271034/1790 [================>.............] - ETA: 4:00 - loss: 4.4092 - classification_loss: 2.0776 - regression_loss: 0.3091 - transformation_loss: 101.12461035/1790 [================>.............] - ETA: 4:00 - loss: 4.4062 - classification_loss: 2.0760 - regression_loss: 0.3090 - transformation_loss: 101.06281036/1790 [================>.............] - ETA: 4:00 - loss: 4.4044 - classification_loss: 2.0746 - regression_loss: 0.3089 - transformation_loss: 101.04701037/1790 [================>.............] - ETA: 3:59 - loss: 4.4015 - classification_loss: 2.0728 - regression_loss: 0.3086 - transformation_loss: 101.00171038/1790 [================>.............] - ETA: 3:59 - loss: 4.4029 - classification_loss: 2.0716 - regression_loss: 0.3088 - transformation_loss: 101.12581039/1790 [================>.............] - ETA: 3:59 - loss: 4.4000 - classification_loss: 2.0701 - regression_loss: 0.3088 - transformation_loss: 101.05681040/1790 [================>.............] - ETA: 3:58 - loss: 4.3966 - classification_loss: 2.0683 - regression_loss: 0.3086 - transformation_loss: 100.99021041/1790 [================>.............] - ETA: 3:58 - loss: 4.3932 - classification_loss: 2.0664 - regression_loss: 0.3083 - transformation_loss: 100.92081042/1790 [================>.............] - ETA: 3:58 - loss: 4.3900 - classification_loss: 2.0646 - regression_loss: 0.3081 - transformation_loss: 100.86731043/1790 [================>.............] - ETA: 3:57 - loss: 4.3878 - classification_loss: 2.0630 - regression_loss: 0.3080 - transformation_loss: 100.83561044/1790 [================>.............] - ETA: 3:57 - loss: 4.3854 - classification_loss: 2.0621 - regression_loss: 0.3079 - transformation_loss: 100.76971045/1790 [================>.............] - ETA: 3:56 - loss: 4.3827 - classification_loss: 2.0605 - regression_loss: 0.3077 - transformation_loss: 100.72291046/1790 [================>.............] - ETA: 3:56 - loss: 4.3808 - classification_loss: 2.0595 - regression_loss: 0.3077 - transformation_loss: 100.68421047/1790 [================>.............] - ETA: 3:56 - loss: 4.3777 - classification_loss: 2.0579 - regression_loss: 0.3075 - transformation_loss: 100.61751048/1790 [================>.............] - ETA: 3:55 - loss: 4.3758 - classification_loss: 2.0566 - regression_loss: 0.3074 - transformation_loss: 100.5898